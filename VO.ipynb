{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VO.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jboehm1/VisualOdometry/blob/master/VO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7V7Ph383ICVU",
        "colab_type": "text"
      },
      "source": [
        "# Odometry\n",
        " Construct list of random index **k** and **k+s** where **s** is the stride < **max_stride** (used for image and R T training)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YO5NrQMMv3AL",
        "colab_type": "code",
        "outputId": "1a4e71d4-3e31-4c44-c654-c4a06c7a8c53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        }
      },
      "source": [
        "!pip install tensorflow-gpu==2.0.0-alpha0\n",
        "%load_ext tensorboard\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.0.0-alpha0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/66/32cffad095253219d53f6b6c2a436637bbe45ac4e7be0244557210dc3918/tensorflow_gpu-2.0.0a0-cp36-cp36m-manylinux1_x86_64.whl (332.1MB)\n",
            "\u001b[K     |████████████████████████████████| 332.1MB 136kB/s \n",
            "\u001b[?25hCollecting tb-nightly<1.14.0a20190302,>=1.14.0a20190301 (from tensorflow-gpu==2.0.0-alpha0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/51/aa1d756644bf4624c03844115e4ac4058eff77acd786b26315f051a4b195/tb_nightly-1.14.0a20190301-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 27.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (3.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.1.7)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.2.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.8.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.0.8)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 (from tensorflow-gpu==2.0.0-alpha0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/82/f16063b4eed210dc2ab057930ac1da4fbe1e91b7b051a6c8370b401e6ae7/tf_estimator_nightly-1.14.0.dev2019030115-py2.py3-none-any.whl (411kB)\n",
            "\u001b[K     |████████████████████████████████| 419kB 42.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.33.6)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.16.5)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.8.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (0.16.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (3.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0-alpha0) (41.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-alpha0) (2.8.0)\n",
            "Installing collected packages: tb-nightly, tf-estimator-nightly, tensorflow-gpu\n",
            "Successfully installed tb-nightly-1.14.0a20190301 tensorflow-gpu-2.0.0a0 tf-estimator-nightly-1.14.0.dev2019030115\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZmvbcR7s74F",
        "colab_type": "code",
        "outputId": "11ebe687-7107-46f4-faa8-ad828758867b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# Install TensorFlow\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8ZYfaWnQuzB",
        "colab_type": "code",
        "outputId": "748340eb-5271-4f99-a889-a0906eb49179",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device=tf.test.gpu_device_name()\n",
        "device"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haXhUAYFpEYt",
        "colab_type": "code",
        "outputId": "1913a3d5-acd4-45d2-a246-ab2baa93ecc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wohdtEpm-sZ",
        "colab_type": "text"
      },
      "source": [
        "## Data loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHlwGs1iIbKX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import cv2\n",
        "import math\n",
        "import datetime \n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import Sequential, Model\n",
        "from tensorflow.python.keras.layers import Conv2D, Flatten, Dense, Concatenate,Input, MaxPooling2D,BatchNormalization, Activation, GlobalAveragePooling2D\n",
        "# example of saving an image with the Keras API\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import save_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "\n",
        "# https://medium.com/@oribarel/getting-the-most-out-of-your-google-colab-2b0585f82403\n",
        "import h5py\n",
        "from PIL import Image\n",
        "\n",
        "path = \"/content/drive/My Drive/Colab Notebooks/VO/\"\n",
        "liste_folder = ['00','01','02','03','04']\n",
        "\n",
        "# num_poses = 2000 #TO DO : deal with end of liste\n",
        "# num_folder=1\n",
        "# # for folder in list_folders:\n",
        "# liste=[[k, k+random.randint(1,max_stride)] for k in range((num_poses)) ]\n",
        "\n",
        "# #Shuffle list !\n",
        "# np.random.shuffle(liste)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaJQfh-MmBxo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fileName = path+'x_train_all.h5'\n",
        "# with h5py.File(fileName, \"w\") as out:\n",
        "#   for k in range len(num_folder):\n",
        "#     out.create_dataset(\"x_train_\"+k, np.shape(x_train) )\n",
        "#     out.create_dataset(\"R_train_\"+k, np.shape(  ) )\n",
        "#     out.create_dataset(\"T_train_\"+k, np.shape(  ) )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzZQE2tHwkZ0",
        "colab_type": "code",
        "outputId": "f6b5a923-52c8-497b-8670-42d33197fa97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-alpha0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1izLfXaFZOe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print iterations progress\n",
        "def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = '█', printEnd = \"\\r\"):\n",
        "    \"\"\"\n",
        "    Call in a loop to create terminal progress bar\n",
        "    @params:\n",
        "        iteration   - Required  : current iteration (Int)\n",
        "        total       - Required  : total iterations (Int)\n",
        "        prefix      - Optional  : prefix string (Str)\n",
        "        suffix      - Optional  : suffix string (Str)\n",
        "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
        "        length      - Optional  : character length of bar (Int)\n",
        "        fill        - Optional  : bar fill character (Str)\n",
        "        printEnd    - Optional  : end character (e.g. \"\\r\", \"\\r\\n\") (Str)\n",
        "    \"\"\"\n",
        "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
        "    filledLength = int(length * iteration // total)\n",
        "    bar = fill * filledLength + '-' * (length - filledLength)\n",
        "    print('\\r%s |%s| %s%% %s' % (prefix, bar, percent, suffix), end = printEnd)\n",
        "    # Print New Line on Complete\n",
        "    if iteration == total: \n",
        "        print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjQ837Nc-OCQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load data, to do : print number of loads / total \n",
        "def load_data(train_or_test):\n",
        "  if train_or_test == 'train':\n",
        "    data =  [[ np.dstack( (cv2.imread(path+'image_0/{:06}.png'.format(k*2), 0),\n",
        "                                       cv2.imread(path+'image_0/{:06}.png'.format(l), 0) ) ) ] for k,l in index_train]\n",
        "  if train_or_test == 'test':\n",
        "    data =  [[ np.dstack( (cv2.imread(path+'image_0/{:06}.png'.format(k*2), 0),\n",
        "                                       cv2.imread(path+'image_0/{:06}.png'.format(l), 0) ) ) ] for k,l in index_test]                            \n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcRZDSsYEk7d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load data, to do : print number of loads / total \n",
        "from tqdm import tqdm\n",
        "def load_data_disp(train_or_test):\n",
        "  data=[]\n",
        "  length0 = len(eval(\"index_\"+train_or_test) )\n",
        "  pbar = tqdm(total=length0)\n",
        "  mem=0\n",
        "\n",
        "  for k,l in eval(\"index_\"+train_or_test):\n",
        "    try:\n",
        "      data.append ( [ np.dstack( (cv2.imread(path+'image_0/{:06}.png'.format(k*2), 0),\n",
        "                                      cv2.imread(path+'image_0/{:06}.png'.format(l*2), 0) ) ) ]  )\n",
        "      if k%100==0:\n",
        "        \n",
        "        # printProgressBar(k, length0, prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
        "        pbar.update(100)\n",
        "        pass\n",
        "    except:\n",
        "      print (k)\n",
        "      mem=mem+1\n",
        "  \n",
        "  print(train_or_test+\"dataset loaded successfully yeah\")\n",
        "  pbar.close()\n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cxqQ6QNpSHE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load data, to do : print number of loads / total \n",
        "from tqdm import tqdm\n",
        "def load_data_folder(folder, liste):\n",
        "  data=[]\n",
        "  # liste=index_list_list[int(folder[1])]\n",
        "\n",
        "  length0 = len(liste)\n",
        "  pbar = tqdm(total=length0)\n",
        "  mem=0\n",
        "\n",
        "  for k,l in liste:\n",
        "    try:\n",
        "      data.append ( [ np.dstack( ( img_to_array( load_img(path+folder+'/image_0/{:06}.png'.format(k), color_mode='grayscale', target_size = (188,620) ) ) / 255,\n",
        "                                       img_to_array (load_img(path+folder+'/image_0/{:06}.png'.format(l), color_mode = 'grayscale', target_size = (188,620)  ) )/255 ) ) ]  )\n",
        "      if k%100==0:\n",
        "        \n",
        "        # printProgressBar(k, length0, prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
        "        pbar.update(100)\n",
        "        pass\n",
        "    except:\n",
        "      print(k)\n",
        "      print(\"________!!!!!!!!!!!!!!!!!!!!!!!!!!_________\")\n",
        "      mem=mem+1\n",
        "      break\n",
        "  print(folder+\"dataset loaded successfully yeah\")\n",
        "  pbar.close()\n",
        "  \n",
        "  return np.reshape(data, (len(data), 188,620,2 ) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5jox9Uc4oap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load data, to do : print number of loads / total \n",
        "from tqdm import tqdm\n",
        "def load_data_folder_1(folder, liste):\n",
        "  data=[]\n",
        "  # liste=index_list_list[int(folder[1])]\n",
        "\n",
        "  length0 = len(liste)\n",
        "  pbar = tqdm(total=length0)\n",
        "  mem=0\n",
        "\n",
        "  [[cv2.imread(path+folder+'/image_0/{:06}.png'.format(k), 0) , cv2.imread(path+folder+'/image_0/{:06}.png'.format(k), 0)] for k,l in liste]\n",
        "\n",
        "\n",
        "  # for k,l in liste:\n",
        "  #   try:\n",
        "  #     img1=cv2.imread(path+folder+'/image_0/{:06}.png'.format(k), 0)\n",
        "  #     img2=cv2.imread(path+folder+'/image_0/{:06}.png'.format(l), 0)\n",
        "  #     # img1 = load_img(path+folder+'/image_0/{:06}.png'.format(k), color_mode='grayscale', target_size = (188,620) )\n",
        "  #     # img2 = load_img(path+folder+'/image_0/{:06}.png'.format(l), color_mode = 'grayscale', target_size = (188,620)  )\n",
        "  #     data.append ( [ np.dstack( ( img_to_array( img1 )/255 ,\n",
        "  #                                      img_to_array ( img2 ) / 255 ) ) ]  )\n",
        "      \n",
        "  #     if k%100==0:\n",
        "        \n",
        "  #       # printProgressBar(k, length0, prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
        "  #       pbar.update(100)\n",
        "  #       pass\n",
        "  #   except:\n",
        "  #     print(k)\n",
        "  #     print(\"________!!!!!!!!!!!!!!!!!!!!!!!!!!_________\")\n",
        "  #     mem=mem+1\n",
        "  #     break\n",
        "  print(folder+\"dataset loaded successfully yeah\")\n",
        "  pbar.close()\n",
        "  \n",
        "  return np.reshape(data, (len(data), 188,620,2 ) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qkyp6Adi7Wws",
        "colab_type": "code",
        "outputId": "ec180294-d3ff-4a19-c4fc-2b9432f233c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "img1=np.load( (path+'00'+'/image_0/{:06}.png'.format(10) ))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-d98584ab9bcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'00'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/image_0/{:06}.png'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                 raise ValueError(\"Cannot load file containing pickled data \"\n\u001b[0m\u001b[1;32m    452\u001b[0m                                  \"when allow_pickle=False\")\n\u001b[1;32m    453\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot load file containing pickled data when allow_pickle=False"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cH2V7el7aqi",
        "colab_type": "code",
        "outputId": "41cdb9a0-510e-4f56-e689-965bac564231",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.shape(img1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(376, 1241)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1eb7b259-3b25-46a5-b828-55b78d20c661",
        "id": "jswY7oYDVsv1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "if 'x_train_0' in globals():\n",
        "  if len(liste)!=len(x_train_0):\n",
        "    print(\"Data changed\")\n",
        "    print(\"\\n Loading data ...\")\n",
        "    x_test_dstacked=[]\n",
        "    x_train_dstacked=[]\n",
        "    # x_train_dstacked = load_data_disp('train')\n",
        "    x_train_0 = load_data_folder('00')\n",
        "    x_train_1 = load_data_folder('11')\n",
        "\n",
        "\n",
        "    print(\"Data loaded, training data shape = {}\".format(np.shape(x_train_0) ))\n",
        "  else:\n",
        "    print(\"Data already loaded, training data shape = {}\".format(np.shape(x_train_0) ))\n",
        "else:\n",
        "  print(\"\\n Loading data ...\")\n",
        "  # x_train_dstacked =  load_data_disp('train')\n",
        "  x_train_0 =  load_data_folder('00')\n",
        "  x_train_1 = load_data_folder('11')\n",
        "  # x_test_dstacked = load_data_disp('test')\n",
        "\n",
        "  print(\"Data loaded, training data shape = {}\".format(np.shape(x_train_0) ))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/2000 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Data changed\n",
            "\n",
            " Loading data ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2000/2000 [00:29<00:00, 85.79it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "image_0dataset loaded successfully yeah\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Data loaded, training data shape = (2000, 1, 188, 620, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2CSJ7hgBbRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fileName = path+'x_train_image1.h5'\n",
        "with h5py.File(fileName, \"w\") as out:\n",
        "  out.create_dataset(\"x_train\", np.shape(x_train) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3V33f71D_1j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with h5py.File(fileName, \"a\") as out:\n",
        "  out['x_train'] = x_train_image1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiDhfp7U-77X",
        "colab_type": "code",
        "outputId": "91b8615a-cba1-46ff-9571-f4db6f7d29d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "file =h5py.File(path+'x_train_image1.h5', 'r')\n",
        "x_train0 = file['x_train']\n",
        "list(file.keys())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['x_train']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thAxzkTLJV7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# del x_train_dstacked"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkQFEmQlvAyt",
        "colab_type": "code",
        "outputId": "cb8353e8-bb30-47cc-fa84-d990b3035b47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        }
      },
      "source": [
        "np.shape(x_train_dstacked)\n",
        "#  stacked=np.dstack(( cv2.imread(path+'/image_0_cropped/{:06}.png'.format(0), 0), cv2.imread(path+'/image_0_cropped/{:06}.png'.format(1), 0) ) )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-35655240e2bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_dstacked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#  stacked=np.dstack(( cv2.imread(path+'/image_0_cropped/{:06}.png'.format(0), 0), cv2.imread(path+'/image_0_cropped/{:06}.png'.format(1), 0) ) )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x_train_dstacked' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4tfRNSIvTTS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# resh=np.reshape(x_train_dstacked[0], (376,1241,2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQVoStRJR-lK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=[(1,2),(3,4)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vINbYgrK4Lnq",
        "colab_type": "code",
        "outputId": "bab6e775-1315-4fd1-84df-1f062d9c4d9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "source": [
        "plt.imshow(x_train[0][0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-999cc496f4fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLMDcb-OUYzt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x[:][1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lb-6ceMnSV9d",
        "colab_type": "text"
      },
      "source": [
        "# create r t data_full"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RxbW1maU1hz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# img1 = tf.io.read_file(path+'/000000.png') # Try out with TF !!!!\n",
        "def create_R_T(folder):\n",
        "  file='/content/drive/My Drive/Colab Notebooks/VO/poses/'+folder+'.txt'\n",
        "  with open(file,'r') as file:\n",
        "    out=[line.split() for line in file]\n",
        "\n",
        "\n",
        "  out_liste = np.array( [ np.array([float(item) for item in k]) for k in out[:-1] ] ) #remove last element which is empty\n",
        "  # liste_R = out_liste[:,3:] #:-3\n",
        "  print(\"out_liste length = \"+str( np.shape(out) ))\n",
        "  # Create Translation vector \n",
        "  liste_T = np.array( [[a[3], a[7], a[11]] for a in out_liste] )\n",
        "\n",
        "\n",
        "  global liste_R_simple\n",
        "\n",
        "\n",
        "  liste_index= [0,1,2,4,5,6,8,9,10]\n",
        "  liste_R_simple = [out_liste[k][liste_index] for k in range(len(out_liste)) ]  \n",
        "\n",
        "\n",
        "  # Create Rotation vector\n",
        "  x_liste=[]\n",
        "  z_liste=[]\n",
        "  y_liste=[]\n",
        "  liste_R = []\n",
        "  liste_R_degree = []\n",
        "  global liste_quat\n",
        "  liste_quat = np.array( [ quatFromRotMatx(R) for R in liste_R_simple] )\n",
        "\n",
        "\n",
        "  for k in range(len(out_liste)):\n",
        "    R=out_liste[k]\n",
        "    sy = math.sqrt(R[0] * R[0] +  R[4] * R[4])\n",
        "\n",
        "    x = math.atan2(R[9] , R[10])\n",
        "    y = math.atan2(-R[8], sy)\n",
        "    z = math.atan2(R[4], R[0])\n",
        "    liste_R_degree.append([180*x/math.pi, 180*y/math.pi, 180*z/math.pi])\n",
        "    liste_R.append([x, y, z])\n",
        "    # print(180*x/math.pi,180*y/math.pi,180*z/math.pi)\n",
        "    x_liste.append(180*x/math.pi)\n",
        "    z_liste.append(z)\n",
        "    y_liste.append(y)\n",
        "\n",
        "\n",
        "  # Conversion to numpy arry, to be checked \n",
        "  liste_R = np.array(liste_R)\n",
        "  liste_R_degree = np.array(liste_R_degree)\n",
        " \n",
        "  # Stride between images from 1 to max_stride (kitti=10fps)\n",
        "  max_stride=10\n",
        "\n",
        "  \n",
        "  # each folder has its own seed \n",
        "  random.seed(int(folder[1]))\n",
        "\n",
        "  # Create liste of combination\n",
        "  liste=[[k, k+random.randint(1,max_stride)] for k in range( len(out_liste) -max_stride) ]\n",
        "\n",
        "  #Shuffle it !!\n",
        "  random.shuffle(liste)\n",
        "\n",
        "  # Extract the difference between index\n",
        "  T_train = [ liste_T[b] - liste_T[a] for a, b in liste]\n",
        "  # R_train = [ liste_R[b] - liste_R[a] for a, b in liste]\n",
        "  # R_train = [ liste_R_simple[b] - liste_R_simple[a] for a, b in liste]\n",
        "  R_train = [ liste_quat[b] - liste_quat[a] for a, b in liste]\n",
        "\n",
        "# \n",
        "  return R_train, T_train, liste"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCowCcqjSJzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def quatFromRotMatx(R):\n",
        "    \"\"\"Get a quaternion from a given rotation matrix `R`.\"\"\"\n",
        "    # https://xy-python-utils.readthedocs.io/en/latest/_modules/quaternion.html\n",
        "    q = np.zeros(4)\n",
        "\n",
        "    q[0] = ( R[0] + R[4] + R[8] + 1) / 4.0\n",
        "    q[1] = ( R[0] - R[4] - R[8] + 1) / 4.0\n",
        "    q[2] = (-R[0] + R[4] - R[8] + 1) / 4.0\n",
        "    q[3] = (-R[0] - R[4] + R[8] + 1) / 4.0\n",
        "\n",
        "    \n",
        "    # q[0] = ( R[0,0] + R[1,1] + R[2,2] + 1) / 4.0\n",
        "    # q[1] = ( R[0,0] - R[1,1] - R[2,2] + 1) / 4.0\n",
        "    # q[2] = (-R[0,0] + R[1,1] - R[2,2] + 1) / 4.0\n",
        "    # q[3] = (-R[0,0] - R[1,1] + R[2,2] + 1) / 4.0\n",
        "\n",
        "    q[q<0] = 0   # Avoid complex number by numerical error.\n",
        "    q = np.sqrt(q)\n",
        "\n",
        "    q[1] *= np.sign(R[7] - R[5])\n",
        "    q[2] *= np.sign(R[2] - R[6])\n",
        "    q[3] *= np.sign(R[3] - R[1])\n",
        "    \n",
        "    # q[1] *= np.sign(R[2,1] - R[1,2])\n",
        "    # q[2] *= np.sign(R[0,2] - R[2,0])\n",
        "    # q[3] *= np.sign(R[1,0] - R[0,1])\n",
        "\n",
        "    return q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3s-lBHstXU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def quatToRotMatx(q, reshaped=False):\n",
        "    \"\"\"Get a rotation matrix from the given unit quaternion `q`.\"\"\"\n",
        "    R = np.zeros((3,3))\n",
        "\n",
        "    R[0,0] = 1 - 2*(q[2]**2 + q[3]**2)\n",
        "    R[1,1] = 1 - 2*(q[1]**2 + q[3]**2)\n",
        "    R[2,2] = 1 - 2*(q[1]**2 + q[2]**2)\n",
        "\n",
        "    R[0,1] = 2 * (q[1]*q[2] - q[0]*q[3])\n",
        "    R[1,0] = 2 * (q[1]*q[2] + q[0]*q[3])\n",
        "\n",
        "    R[0,2] = 2 * (q[1]*q[3] + q[0]*q[2])\n",
        "    R[2,0] = 2 * (q[1]*q[3] - q[0]*q[2])\n",
        "\n",
        "    R[1,2] = 2 * (q[2]*q[3] - q[0]*q[1])\n",
        "    R[2,1] = 2 * (q[2]*q[3] + q[0]*q[1])\n",
        "\n",
        "    if reshaped:\n",
        "      R = np.reshape(R, (1,9))\n",
        "\n",
        "    return R"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90lZQqVATWHz",
        "colab_type": "code",
        "outputId": "6ce69d55-f2cb-450e-9546-21b1d027a9a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "plt.plot(liste_quat[:,3])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f0a0869a860>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAD8CAYAAABkbJM/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsg4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJPKSgV2TXae",
        "colab_type": "code",
        "outputId": "399d14e4-f06b-4c39-8241-776eecd530e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "q"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NZM53zFSpVH",
        "colab_type": "code",
        "outputId": "bf8073db-44d9-4cb1-c85d-bc25a1418fbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "# with tf.device('/gpu:0'):\n",
        "  R_liste=[]\n",
        "  T_liste=[]\n",
        "  index_list_list=[]\n",
        "  for item in liste_folder:\n",
        "    print(item)\n",
        "    R, T, index_list=create_R_T(item)\n",
        "    R_liste.append(R)\n",
        "    T_liste.append(T)\n",
        "    print(\"Data from folder \"+item+\" loaded \\n\")\n",
        "    print(\"_________________\")\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "00\n",
            "out_liste length = (4541, 12)\n",
            "Data from folder 00 loaded \n",
            "\n",
            "_________________\n",
            "01\n",
            "out_liste length = (1101, 12)\n",
            "Data from folder 01 loaded \n",
            "\n",
            "_________________\n",
            "02\n",
            "out_liste length = (4661, 12)\n",
            "Data from folder 02 loaded \n",
            "\n",
            "_________________\n",
            "03\n",
            "out_liste length = (801, 12)\n",
            "Data from folder 03 loaded \n",
            "\n",
            "_________________\n",
            "04\n",
            "out_liste length = (271, 12)\n",
            "Data from folder 04 loaded \n",
            "\n",
            "_________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llJAZFCwol3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # with tf.device('/gpu:0'):\n",
        "#   R_liste=[]\n",
        "#   T_liste=[]\n",
        "#   index_list_list=[]\n",
        "#   data=[]\n",
        "#   for item in liste_folder:\n",
        "#     print(item)\n",
        "#     R, T, index_list=create_R_T(item)\n",
        "#     R_liste.append(R)\n",
        "#     T_liste.append(T)\n",
        "#     index_list_list.append(index_list)\n",
        "#     data_loc=load_data_folder(item, index_list)\n",
        "#     data.append(data_loc)\n",
        "#     print(\"Data from folder \"+item+\" loaded \\n\")\n",
        "#     np.save(path+'data'+str(item[1]), data_loc)\n",
        "#     print(\"_________________\")\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpOZGJYamwtk",
        "colab_type": "code",
        "outputId": "0094121e-a736-491f-a40d-a08a9f6fe1ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        " for item in liste_folder[1:2]:\n",
        "    print(item)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuBo14XXRHvb",
        "colab_type": "code",
        "outputId": "055d067b-ae60-4d99-9245-8593b5ae1308",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "import numpy as np:"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iW8idXzpLc_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_full=[]\n",
        "for k in range(0,5):\n",
        "  data_full.append( np.load(path+'data'+str(k)+'.npy') )\n",
        "  print(k)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-Wbb_f5Si3Z",
        "colab_type": "code",
        "outputId": "fabe16d9-7531-4a16-ef4c-76e86f996b28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "np.shape(data_full[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4530, 188, 620, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2KAiLiaUxfM",
        "colab_type": "code",
        "outputId": "3e4504b1-5b4b-40a4-f606-1296330c3980",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "np.shape(data[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4650, 188, 620, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ihVA-iggMaB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "full_data =np.concatenate(( data[0],data[1], data[2], data[3] ) , axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrkvU1jQiBPv",
        "colab_type": "code",
        "outputId": "a6eee7f0-88e6-4301-fe05-9d31549a433a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.shape(R_liste)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cenuUeRpW4Hf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# full_liste_R = np.concatenate( (R_liste[0], R_liste[1], R_liste[2],R_liste[3], R_liste[4]) , axis=0 )\n",
        "# full_liste_T = np.concatenate( (T_liste[0], T_liste[1], T_liste[2],T_liste[3], T_liste[4]), axis=0 )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZkgX2A1WSr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# np.save(path+'full_liste_R_[y]', full_liste_R)\n",
        "# np.save(path+'full_liste_T', full_liste_T)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqStgkeHV4dY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "full_liste_R=np.concatenate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYAu191CUrsG",
        "colab_type": "code",
        "outputId": "b138b1da-4d8d-4378-b87e-82b3729d552f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "source": [
        "np.shape(Output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-123-037f040f2c97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'Output' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MkA-6OzSOZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nfile='/content/drive/My Drive/Colab Notebooks/VO/poses/'+'01'+'.txt'\n",
        "with open(file,'r') as file:\n",
        "  out=[line.split() for line in file]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KP01vlsnSXab",
        "colab_type": "code",
        "outputId": "c90187a7-4c21-450d-cf5c-7997b37f95b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "\n",
        "np.shape(out)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-9604c33b69be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'out' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bzon5E7BVWmh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(path+'data_0-4', data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_412wjbCFGK",
        "colab_type": "text"
      },
      "source": [
        "# Network architecture\n",
        "With \"decoupeled\" (from \"UnDeepVO\") output to deal with high non linearity of \n",
        "Rotation matrix (using layers.concatenate)\n",
        "\n",
        "TO TRY:\n",
        "* only one output vector, and add weight per hand \n",
        "* divide image: foreground better for translation, background for rotation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0OkuxmsCETL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_vgg(): # to do : loops to create layers\n",
        "  input_shape = Input( (188, 620, 2) )\n",
        "\n",
        "  conv1 = (Conv2D(filters=64, kernel_size=3,  \n",
        "                  padding='valid', activation='relu', name='conv1' ))(input_shape)\n",
        "  conv2 = (Conv2D(64, 3,  activation='relu',name='conv2'))(conv1)\n",
        "  pooling1 = MaxPooling2D(2,name='pooling1')(conv2)\n",
        "\n",
        "  conv3 = (Conv2D(128, 3,  activation='relu',name='conv3'))(pooling1)\n",
        "  conv4 = (Conv2D(128, 3, activation='relu',name='conv4'))(conv3)\n",
        "  pooling2 = MaxPooling2D(2,name='pooling2')(conv4)\n",
        "\n",
        "  conv5 = (Conv2D(256, 3,  activation='relu',name='conv5'))(pooling2)\n",
        "  conv6 = (Conv2D(256, 3,  activation='relu',name='conv6'))(conv5)\n",
        "  conv7 = (Conv2D(256, 3,  activation='relu',name='conv7'))(conv6)\n",
        "  pooling3 = MaxPooling2D(2,name='pooling3')(conv7)\n",
        "\n",
        "  conv8 = (Conv2D(512, 3,  activation='relu',name='conv8'))(pooling3)\n",
        "  conv9 = (Conv2D(512, 3,  activation='relu',name='conv9'))(conv8)\n",
        "  conv10 = (Conv2D(512, 3,  activation='relu',name='conv10'))(conv9)\n",
        "  pooling4 = MaxPooling2D(2,name='pooling4')(conv10)\n",
        "\n",
        "  # conv11 = (Conv2D(512, 3,  activation='relu',name='conv11'))(pooling4)\n",
        "  # conv12 = (Conv2D(512, 3,  activation='relu',name='conv12'))(conv11)\n",
        "  # conv13 = (Conv2D(512, 3,  activation='relu',name='conv13'))(conv12)\n",
        "  # pooling5 = MaxPooling2D(4,name='pooling5')(conv13)\n",
        "\n",
        "  flatten1 = Flatten(name='flatten')(pooling4)\n",
        "  dense1 = Dense(512, activation='relu',name='dense1')(flatten1)\n",
        "  # dense2 = Dense(1024, activation = 'relu',name='dense2')(dense1)\n",
        "  T_network = Dense(3 , name='T')(dense1)\n",
        "  R_network = Dense(9 , name='R')(dense1)\n",
        "\n",
        "  \n",
        "  model = Model(input_shape, [T_network, R_network])\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam', \n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hg14akVxrCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_pooling():\n",
        "  input_shape = Input( ( 188, 620, 2) )\n",
        "\n",
        "  conv1 = (Conv2D(filters=64, kernel_size=3,  \n",
        "                  padding='valid', activation='relu', name='conv1' ))(input_shape)\n",
        "  pooling1 = MaxPooling2D(2,name='pooling1')(conv1)\n",
        "\n",
        "  conv2 = (Conv2D(128, 3,  activation='relu',name='conv3'))(pooling1)\n",
        "  pooling2 = MaxPooling2D(2,name='pooling2')(conv2)\n",
        "\n",
        "  conv3 = (Conv2D(256, 3,  activation='relu',name='conv5'))(pooling2)\n",
        "  pooling3 = MaxPooling2D(2,name='pooling3')(conv3)\n",
        "\n",
        "  conv4 = (Conv2D(512, 3,  activation='relu',name='conv10'))(pooling3)\n",
        "  pooling4 = MaxPooling2D(2,name='pooling4')(conv4)\n",
        "\n",
        "  conv5 = (Conv2D(512, 3,  activation='relu',name='conv13'))(pooling4)\n",
        "  # pooling5 = MaxPooling2D(2,name='pooling5')(conv5)\n",
        "\n",
        "  # flatten1 = Flatten(name='flatten')(pooling5)\n",
        "  # dense1 = Dense(512, activation='relu',name='dense1')(flatten1)\n",
        "\n",
        "  conv6 = (Conv2D(512, 3,  activation='relu',name='conv6'))(conv5)\n",
        "  conv7 = (Conv2D(512, 3,  activation='relu',name='conv7'))(conv5)\n",
        "\n",
        "  flattenT = Flatten()(conv6)\n",
        "  flattenR = Flatten()(conv7)\n",
        "  T_network = Dense(3 , name='T')(flattenT)\n",
        "  R_network = Dense(9 , name='R')(flattenR)\n",
        "\n",
        "  \n",
        "  model = Model(input_shape, [T_network, R_network])\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam', \n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLkeQTtt1A-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_pooling_BN():\n",
        "  input_shape = Input( ( 188, 620, 2) )\n",
        "\n",
        "  conv1 = (Conv2D(filters=64, kernel_size=3,  \n",
        "                  padding='valid', activation='relu', name='conv1' ))(input_shape)\n",
        "  pooling1 = MaxPooling2D(2,name='pooling1')(conv1)\n",
        "\n",
        "  conv2 = (Conv2D(128, 3,  activation='relu',name='conv3'))(pooling1)\n",
        "  pooling2 = MaxPooling2D(2,name='pooling2')(conv2)\n",
        "\n",
        "  conv3 = (Conv2D(256, 3,  activation='relu',name='conv5'))(pooling2)\n",
        "  pooling3 = MaxPooling2D(2,name='pooling3')(conv3)\n",
        "\n",
        "  conv4 = (Conv2D(512, 3,  activation='relu',name='conv10'))(pooling3)\n",
        "  pooling4 = MaxPooling2D(2,name='pooling4')(conv4)\n",
        "\n",
        "  conv5 = (Conv2D(512, 3,  activation='relu',name='conv13'))(pooling4)\n",
        "  # pooling5 = MaxPooling2D(2,name='pooling5')(conv5)\n",
        "\n",
        "  # flatten1 = Flatten(name='flatten')(pooling5)\n",
        "  # dense1 = Dense(512, activation='relu',name='dense1')(flatten1)\n",
        "\n",
        "  conv6 = (Conv2D(512, 3,  activation='relu',name='conv6'))(conv5)\n",
        "  conv7 = (Conv2D(512, 3,  activation='relu',name='conv7'))(conv5)\n",
        "\n",
        "  flattenT = Flatten()(conv6)\n",
        "  flattenR = Flatten()(conv7)\n",
        "  T_network = Dense(3 , name='T')(flattenT)\n",
        "  R_network = Dense(9 , name='R')(flattenR)\n",
        "\n",
        "  \n",
        "  model = Model(input_shape, [T_network, R_network])\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam', \n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJZhHdqV5gjm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_strides():\n",
        "  input_shape = Input( (188, 620, 2) )\n",
        "\n",
        "  conv1 = (Conv2D(filters=64, kernel_size=3,   strides=2,\n",
        "                  padding='valid', activation='relu', name='conv1' ))(input_shape)\n",
        "  # pooling1 = MaxPooling2D(2,name='pooling1')(conv1)\n",
        "\n",
        "  conv2 = (Conv2D(128, 3,  strides=2, activation='relu',name='conv3'))(conv1)\n",
        "\n",
        "  conv3 = (Conv2D(256, 3,  strides = 2, activation='relu',name='conv5'))(conv2)\n",
        "\n",
        "  conv4 = (Conv2D(512, 3, strides=2, activation='relu',name='conv10'))(conv3)\n",
        "\n",
        "  conv5 = (Conv2D(512, 3, strides = 2,  activation='relu',name='conv13'))(conv4)\n",
        "  # pooling = MaxPooling2D(2,name='pooling4')(conv5)\n",
        "\n",
        "  flatten1 = Flatten(name='flatten')(conv5)\n",
        "  dense1 = Dense(1024, activation='relu',name='dense1')(flatten1)\n",
        "\n",
        "  # dense2=Dense(1024, activation='relu',name='dense2')(dense1)\n",
        "\n",
        "  pre_output_R1 = Dense(512, activation='relu')(dense1)\n",
        "  pre_output_T1 = Dense(512, activation='relu')(dense1)\n",
        "\n",
        "  T_network = Dense(3 , name='T')(pre_output_T1)\n",
        "  R_network = Dense(4 , name='R')(pre_output_R1)\n",
        "\n",
        "  \n",
        "  model = Model(input_shape, [T_network, R_network])\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam', \n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCeZbrKP9PUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_strides_BN():\n",
        "  input_shape = Input( (188, 620, 2) )\n",
        "\n",
        "  conv1 = (Conv2D(filters=64, kernel_size=3,   strides=2,\n",
        "                  padding='valid', name='conv1' , use_bias=False))(input_shape)\n",
        "  # pooling1 = MaxPooling2D(2,name='pooling1')(conv1)\n",
        "  bn1 = BatchNormalization()(conv1)\n",
        "  a1 = Activation('relu')(bn1)\n",
        "\n",
        "  conv2 = (Conv2D(128, 3,  strides=2,name='conv3',use_bias=False))(a1)\n",
        "  bn2 = BatchNormalization()(conv2)\n",
        "  a2 = Activation('relu')(bn2)\n",
        "\n",
        "\n",
        "  conv3 = (Conv2D(256, 3,  strides = 2,name='conv5',use_bias=False))(a2)\n",
        "  bn3 = BatchNormalization()(conv3)\n",
        "  a3 = Activation('relu')(bn3)\n",
        "\n",
        "  conv5 = (Conv2D(512, 3, strides = 2, name='conv13',use_bias=False))(bn3)\n",
        "  bn5 = BatchNormalization()(conv5)\n",
        "  a4 = Activation('relu')(bn5)\n",
        "\n",
        "  flatten1 = Flatten(name='flatten')(a4)\n",
        "  dense1 = Dense(256,name='dense1',use_bias=False)(flatten1)\n",
        "  bn6 = BatchNormalization()(dense1)\n",
        "  a5 = Activation('relu')(bn6)\n",
        "\n",
        "  pre_output_R1 = Dense(512, activation='relu')(a5)\n",
        "  pre_output_T1 = Dense(512, activation='relu')(a5)\n",
        "  \n",
        "  bnR = BatchNormalization()(pre_output_R1)\n",
        "  bnT = BatchNormalization()(pre_output_T1)\n",
        "  \n",
        "  T_network = Dense(3 , name='T')(bnT)\n",
        "  R_network = Dense(4 , name='R')(bnR)\n",
        "\n",
        "  \n",
        "  model = Model(input_shape, [T_network, R_network])\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam', \n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfH58eQmSiXP",
        "colab_type": "text"
      },
      "source": [
        "# Execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1FihTz2GAtv",
        "colab_type": "code",
        "outputId": "bb2a0409-cfd7-450d-f05c-fc7c16387693",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        }
      },
      "source": [
        "model_strides_BN=create_strides()\n",
        "model_strides_BN.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, 188, 620, 2) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 93, 309, 64)  1216        input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv3 (Conv2D)                  (None, 46, 154, 128) 73856       conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv5 (Conv2D)                  (None, 22, 76, 256)  295168      conv3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv10 (Conv2D)                 (None, 10, 37, 512)  1180160     conv5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv13 (Conv2D)                 (None, 4, 18, 512)   2359808     conv10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 36864)        0           conv13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense1 (Dense)                  (None, 1024)         37749760    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 512)          524800      dense1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 512)          524800      dense1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "T (Dense)                       (None, 3)            1539        dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "R (Dense)                       (None, 4)            2052        dense_6[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 42,713,159\n",
            "Trainable params: 42,713,159\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rv9rUaBlKa0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x_train_0 = np.load(path+'x_train.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZE93YdqkA5o",
        "colab_type": "code",
        "outputId": "5200418a-168e-4bce-903c-c357678de14b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "epoch = 100\n",
        "k=0\n",
        "history = model_strides_BN.fit(x = data_full[k], \n",
        "            y=[full_liste_T, full_liste_R], \n",
        "            batch_size = 32,\n",
        "            epochs = epoch,\n",
        "            validation_split=0.05 )\n",
        "            # batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-6e4bb1c3c874>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m history = model_strides_BN.fit(x = data_full[k], \n\u001b[0;32m----> 4\u001b[0;31m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfull_liste_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_liste_R\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m             \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'full_liste_T' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNpErOP0ZoBk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mmodel.save(path+'model_strides_100epochs.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLgFVSTFZXPV",
        "colab_type": "code",
        "outputId": "eae7c22b-37b6-489b-e4c8-c036f69a416a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-135-27cffc40c879>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_vgg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'create_vgg' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHm2xKMHjGJ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data= np.load(path+'data0.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-am15ovjxOX",
        "colab_type": "code",
        "outputId": "996932ba-dec5-4398-a015-29dee94791db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "for k in [0,1,2,3,4]*2:\n",
        "  print(k)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmypxxbWZYok",
        "colab_type": "code",
        "outputId": "d7e340fb-458d-4283-8afc-7f7a03af5bf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for k in [0,1,2,3,4]*2:\n",
        "  epoch = 50\n",
        "  history1 = model_strides_BN.fit(x = data_full[k], \n",
        "              y=[T_liste[k], R_liste[k]], \n",
        "              batch_size = 32,\n",
        "              epochs = epoch,\n",
        "              validation_split=0.05 ,\n",
        "              callbacks=[tensorboard_callback])\n",
        "              # batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4303 samples, validate on 227 samples\n",
            "Epoch 1/50\n",
            "4303/4303 [==============================] - 37s 9ms/sample - loss: 4.7029 - T_loss: 4.6828 - R_loss: 0.0200 - T_accuracy: 0.7021 - R_accuracy: 0.2452 - val_loss: 3.3388 - val_T_loss: 3.3347 - val_R_loss: 0.0041 - val_T_accuracy: 0.7709 - val_R_accuracy: 0.2599\n",
            "Epoch 2/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 2.3700 - T_loss: 2.3608 - R_loss: 0.0092 - T_accuracy: 0.8120 - R_accuracy: 0.2624 - val_loss: 2.0462 - val_T_loss: 2.0425 - val_R_loss: 0.0037 - val_T_accuracy: 0.8458 - val_R_accuracy: 0.2115\n",
            "Epoch 3/50\n",
            "4303/4303 [==============================] - 37s 8ms/sample - loss: 1.6124 - T_loss: 1.6046 - R_loss: 0.0078 - T_accuracy: 0.8608 - R_accuracy: 0.2610 - val_loss: 1.6023 - val_T_loss: 1.5996 - val_R_loss: 0.0027 - val_T_accuracy: 0.8546 - val_R_accuracy: 0.2379\n",
            "Epoch 4/50\n",
            "4303/4303 [==============================] - 37s 8ms/sample - loss: 1.1004 - T_loss: 1.0942 - R_loss: 0.0061 - T_accuracy: 0.8857 - R_accuracy: 0.2919 - val_loss: 1.1986 - val_T_loss: 1.1950 - val_R_loss: 0.0036 - val_T_accuracy: 0.9031 - val_R_accuracy: 0.2863\n",
            "Epoch 5/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.7350 - T_loss: 0.7292 - R_loss: 0.0058 - T_accuracy: 0.9045 - R_accuracy: 0.2998 - val_loss: 0.9287 - val_T_loss: 0.9268 - val_R_loss: 0.0018 - val_T_accuracy: 0.8899 - val_R_accuracy: 0.2863\n",
            "Epoch 6/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.4775 - T_loss: 0.4731 - R_loss: 0.0044 - T_accuracy: 0.9166 - R_accuracy: 0.3244 - val_loss: 0.7515 - val_T_loss: 0.7492 - val_R_loss: 0.0023 - val_T_accuracy: 0.8238 - val_R_accuracy: 0.3260\n",
            "Epoch 7/50\n",
            "4303/4303 [==============================] - 37s 9ms/sample - loss: 0.3248 - T_loss: 0.3211 - R_loss: 0.0037 - T_accuracy: 0.9210 - R_accuracy: 0.3426 - val_loss: 0.7288 - val_T_loss: 0.7274 - val_R_loss: 0.0014 - val_T_accuracy: 0.9031 - val_R_accuracy: 0.3524\n",
            "Epoch 8/50\n",
            "4303/4303 [==============================] - 37s 8ms/sample - loss: 0.2356 - T_loss: 0.2323 - R_loss: 0.0032 - T_accuracy: 0.9340 - R_accuracy: 0.3549 - val_loss: 0.6433 - val_T_loss: 0.6420 - val_R_loss: 0.0013 - val_T_accuracy: 0.9207 - val_R_accuracy: 0.3084\n",
            "Epoch 9/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.1723 - T_loss: 0.1697 - R_loss: 0.0027 - T_accuracy: 0.9398 - R_accuracy: 0.3532 - val_loss: 0.5679 - val_T_loss: 0.5668 - val_R_loss: 0.0012 - val_T_accuracy: 0.9031 - val_R_accuracy: 0.3304\n",
            "Epoch 10/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.1558 - T_loss: 0.1535 - R_loss: 0.0023 - T_accuracy: 0.9507 - R_accuracy: 0.3790 - val_loss: 0.6073 - val_T_loss: 0.6059 - val_R_loss: 0.0014 - val_T_accuracy: 0.8987 - val_R_accuracy: 0.3260\n",
            "Epoch 11/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.1409 - T_loss: 0.1389 - R_loss: 0.0020 - T_accuracy: 0.9491 - R_accuracy: 0.3842 - val_loss: 0.5589 - val_T_loss: 0.5577 - val_R_loss: 0.0012 - val_T_accuracy: 0.9295 - val_R_accuracy: 0.3304\n",
            "Epoch 12/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.1156 - T_loss: 0.1140 - R_loss: 0.0016 - T_accuracy: 0.9535 - R_accuracy: 0.3944 - val_loss: 0.5263 - val_T_loss: 0.5251 - val_R_loss: 0.0011 - val_T_accuracy: 0.9207 - val_R_accuracy: 0.3304\n",
            "Epoch 13/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0928 - T_loss: 0.0914 - R_loss: 0.0015 - T_accuracy: 0.9565 - R_accuracy: 0.3965 - val_loss: 0.5648 - val_T_loss: 0.5635 - val_R_loss: 0.0012 - val_T_accuracy: 0.9295 - val_R_accuracy: 0.3744\n",
            "Epoch 14/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0856 - T_loss: 0.0846 - R_loss: 0.0010 - T_accuracy: 0.9642 - R_accuracy: 0.4020 - val_loss: 0.7082 - val_T_loss: 0.7074 - val_R_loss: 7.3680e-04 - val_T_accuracy: 0.8899 - val_R_accuracy: 0.4141\n",
            "Epoch 15/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.1299 - T_loss: 0.1289 - R_loss: 0.0011 - T_accuracy: 0.9510 - R_accuracy: 0.4065 - val_loss: 0.6024 - val_T_loss: 0.6017 - val_R_loss: 6.8814e-04 - val_T_accuracy: 0.9119 - val_R_accuracy: 0.4009\n",
            "Epoch 16/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.1118 - T_loss: 0.1109 - R_loss: 8.8723e-04 - T_accuracy: 0.9591 - R_accuracy: 0.4139 - val_loss: 0.5981 - val_T_loss: 0.5972 - val_R_loss: 8.8621e-04 - val_T_accuracy: 0.9031 - val_R_accuracy: 0.3304\n",
            "Epoch 17/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0800 - T_loss: 0.0790 - R_loss: 9.6090e-04 - T_accuracy: 0.9614 - R_accuracy: 0.4148 - val_loss: 0.6236 - val_T_loss: 0.6229 - val_R_loss: 7.0826e-04 - val_T_accuracy: 0.9163 - val_R_accuracy: 0.3833\n",
            "Epoch 18/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.1258 - T_loss: 0.1252 - R_loss: 5.6205e-04 - T_accuracy: 0.9605 - R_accuracy: 0.4269 - val_loss: 0.6037 - val_T_loss: 0.6030 - val_R_loss: 7.0589e-04 - val_T_accuracy: 0.9339 - val_R_accuracy: 0.4097\n",
            "Epoch 19/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.1233 - T_loss: 0.1226 - R_loss: 6.9735e-04 - T_accuracy: 0.9647 - R_accuracy: 0.4323 - val_loss: 0.7493 - val_T_loss: 0.7485 - val_R_loss: 8.3040e-04 - val_T_accuracy: 0.9119 - val_R_accuracy: 0.3965\n",
            "Epoch 20/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.1073 - T_loss: 0.1065 - R_loss: 7.9852e-04 - T_accuracy: 0.9593 - R_accuracy: 0.4288 - val_loss: 0.5367 - val_T_loss: 0.5360 - val_R_loss: 6.5921e-04 - val_T_accuracy: 0.9383 - val_R_accuracy: 0.4317\n",
            "Epoch 21/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0838 - T_loss: 0.0834 - R_loss: 4.9853e-04 - T_accuracy: 0.9658 - R_accuracy: 0.4348 - val_loss: 0.5140 - val_T_loss: 0.5134 - val_R_loss: 6.0342e-04 - val_T_accuracy: 0.9251 - val_R_accuracy: 0.4361\n",
            "Epoch 22/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0590 - T_loss: 0.0587 - R_loss: 3.5418e-04 - T_accuracy: 0.9649 - R_accuracy: 0.4597 - val_loss: 0.5423 - val_T_loss: 0.5417 - val_R_loss: 5.7580e-04 - val_T_accuracy: 0.9119 - val_R_accuracy: 0.4185\n",
            "Epoch 23/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0907 - T_loss: 0.0903 - R_loss: 4.0490e-04 - T_accuracy: 0.9647 - R_accuracy: 0.4622 - val_loss: 0.5576 - val_T_loss: 0.5571 - val_R_loss: 5.7003e-04 - val_T_accuracy: 0.9163 - val_R_accuracy: 0.4493\n",
            "Epoch 24/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0736 - T_loss: 0.0732 - R_loss: 4.0501e-04 - T_accuracy: 0.9672 - R_accuracy: 0.4664 - val_loss: 0.5408 - val_T_loss: 0.5403 - val_R_loss: 5.3785e-04 - val_T_accuracy: 0.9207 - val_R_accuracy: 0.4581\n",
            "Epoch 25/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0746 - T_loss: 0.0742 - R_loss: 3.6603e-04 - T_accuracy: 0.9637 - R_accuracy: 0.4611 - val_loss: 0.5510 - val_T_loss: 0.5503 - val_R_loss: 6.0917e-04 - val_T_accuracy: 0.9383 - val_R_accuracy: 0.4141\n",
            "Epoch 26/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.1263 - T_loss: 0.1255 - R_loss: 7.2960e-04 - T_accuracy: 0.9614 - R_accuracy: 0.4518 - val_loss: 0.6237 - val_T_loss: 0.6229 - val_R_loss: 7.9231e-04 - val_T_accuracy: 0.9163 - val_R_accuracy: 0.4493\n",
            "Epoch 27/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.1100 - T_loss: 0.1089 - R_loss: 0.0011 - T_accuracy: 0.9603 - R_accuracy: 0.4583 - val_loss: 0.5587 - val_T_loss: 0.5582 - val_R_loss: 5.3094e-04 - val_T_accuracy: 0.9383 - val_R_accuracy: 0.4537\n",
            "Epoch 28/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0722 - T_loss: 0.0718 - R_loss: 4.3494e-04 - T_accuracy: 0.9689 - R_accuracy: 0.4825 - val_loss: 0.5434 - val_T_loss: 0.5429 - val_R_loss: 4.6226e-04 - val_T_accuracy: 0.9471 - val_R_accuracy: 0.4361\n",
            "Epoch 29/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0721 - T_loss: 0.0717 - R_loss: 3.9012e-04 - T_accuracy: 0.9689 - R_accuracy: 0.4801 - val_loss: 0.5879 - val_T_loss: 0.5874 - val_R_loss: 4.4557e-04 - val_T_accuracy: 0.9075 - val_R_accuracy: 0.4581\n",
            "Epoch 30/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0860 - T_loss: 0.0856 - R_loss: 3.7997e-04 - T_accuracy: 0.9628 - R_accuracy: 0.4818 - val_loss: 0.5343 - val_T_loss: 0.5336 - val_R_loss: 6.9445e-04 - val_T_accuracy: 0.9471 - val_R_accuracy: 0.4537\n",
            "Epoch 31/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0629 - T_loss: 0.0624 - R_loss: 4.2325e-04 - T_accuracy: 0.9675 - R_accuracy: 0.4911 - val_loss: 0.5103 - val_T_loss: 0.5098 - val_R_loss: 5.3351e-04 - val_T_accuracy: 0.9383 - val_R_accuracy: 0.4185\n",
            "Epoch 32/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0500 - T_loss: 0.0496 - R_loss: 4.3436e-04 - T_accuracy: 0.9703 - R_accuracy: 0.4997 - val_loss: 0.5221 - val_T_loss: 0.5215 - val_R_loss: 6.2398e-04 - val_T_accuracy: 0.9295 - val_R_accuracy: 0.4978\n",
            "Epoch 33/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0397 - T_loss: 0.0394 - R_loss: 3.7105e-04 - T_accuracy: 0.9707 - R_accuracy: 0.4990 - val_loss: 0.6424 - val_T_loss: 0.6419 - val_R_loss: 5.4024e-04 - val_T_accuracy: 0.9339 - val_R_accuracy: 0.4802\n",
            "Epoch 34/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0499 - T_loss: 0.0495 - R_loss: 3.8416e-04 - T_accuracy: 0.9700 - R_accuracy: 0.5024 - val_loss: 0.5406 - val_T_loss: 0.5401 - val_R_loss: 4.8220e-04 - val_T_accuracy: 0.9251 - val_R_accuracy: 0.4581\n",
            "Epoch 35/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0810 - T_loss: 0.0806 - R_loss: 4.2460e-04 - T_accuracy: 0.9686 - R_accuracy: 0.5059 - val_loss: 0.5894 - val_T_loss: 0.5890 - val_R_loss: 4.1681e-04 - val_T_accuracy: 0.9339 - val_R_accuracy: 0.4934\n",
            "Epoch 36/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0771 - T_loss: 0.0768 - R_loss: 3.2900e-04 - T_accuracy: 0.9698 - R_accuracy: 0.5041 - val_loss: 0.5990 - val_T_loss: 0.5986 - val_R_loss: 4.2087e-04 - val_T_accuracy: 0.9383 - val_R_accuracy: 0.4934\n",
            "Epoch 37/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0629 - T_loss: 0.0624 - R_loss: 5.1383e-04 - T_accuracy: 0.9689 - R_accuracy: 0.4850 - val_loss: 0.5700 - val_T_loss: 0.5695 - val_R_loss: 5.0894e-04 - val_T_accuracy: 0.9119 - val_R_accuracy: 0.4714\n",
            "Epoch 38/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0699 - T_loss: 0.0696 - R_loss: 3.2672e-04 - T_accuracy: 0.9670 - R_accuracy: 0.5243 - val_loss: 0.5342 - val_T_loss: 0.5338 - val_R_loss: 4.2477e-04 - val_T_accuracy: 0.9471 - val_R_accuracy: 0.4581\n",
            "Epoch 39/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0886 - T_loss: 0.0882 - R_loss: 3.4224e-04 - T_accuracy: 0.9621 - R_accuracy: 0.5129 - val_loss: 0.6058 - val_T_loss: 0.6054 - val_R_loss: 3.8559e-04 - val_T_accuracy: 0.9383 - val_R_accuracy: 0.4758\n",
            "Epoch 40/50\n",
            "4303/4303 [==============================] - 37s 8ms/sample - loss: 0.0793 - T_loss: 0.0790 - R_loss: 2.9047e-04 - T_accuracy: 0.9658 - R_accuracy: 0.5243 - val_loss: 0.5894 - val_T_loss: 0.5888 - val_R_loss: 6.5818e-04 - val_T_accuracy: 0.9339 - val_R_accuracy: 0.4405\n",
            "Epoch 41/50\n",
            "4303/4303 [==============================] - 37s 9ms/sample - loss: 0.1012 - T_loss: 0.1007 - R_loss: 5.2547e-04 - T_accuracy: 0.9672 - R_accuracy: 0.4987 - val_loss: 0.5108 - val_T_loss: 0.5103 - val_R_loss: 4.8443e-04 - val_T_accuracy: 0.9295 - val_R_accuracy: 0.4449\n",
            "Epoch 42/50\n",
            "4303/4303 [==============================] - 37s 8ms/sample - loss: 0.0804 - T_loss: 0.0801 - R_loss: 3.7147e-04 - T_accuracy: 0.9584 - R_accuracy: 0.5064 - val_loss: 0.5408 - val_T_loss: 0.5405 - val_R_loss: 3.5156e-04 - val_T_accuracy: 0.9339 - val_R_accuracy: 0.4229\n",
            "Epoch 43/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0742 - T_loss: 0.0739 - R_loss: 3.1292e-04 - T_accuracy: 0.9684 - R_accuracy: 0.5210 - val_loss: 0.5893 - val_T_loss: 0.5889 - val_R_loss: 3.7246e-04 - val_T_accuracy: 0.9339 - val_R_accuracy: 0.4714\n",
            "Epoch 44/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0907 - T_loss: 0.0902 - R_loss: 5.1709e-04 - T_accuracy: 0.9677 - R_accuracy: 0.5208 - val_loss: 0.5442 - val_T_loss: 0.5435 - val_R_loss: 6.9570e-04 - val_T_accuracy: 0.9339 - val_R_accuracy: 0.4714\n",
            "Epoch 45/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0586 - T_loss: 0.0583 - R_loss: 3.5809e-04 - T_accuracy: 0.9716 - R_accuracy: 0.5266 - val_loss: 0.5432 - val_T_loss: 0.5428 - val_R_loss: 3.7154e-04 - val_T_accuracy: 0.9427 - val_R_accuracy: 0.4846\n",
            "Epoch 46/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0422 - T_loss: 0.0420 - R_loss: 2.5996e-04 - T_accuracy: 0.9761 - R_accuracy: 0.5468 - val_loss: 0.5489 - val_T_loss: 0.5484 - val_R_loss: 5.2986e-04 - val_T_accuracy: 0.9383 - val_R_accuracy: 0.4978\n",
            "Epoch 47/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0453 - T_loss: 0.0450 - R_loss: 3.0963e-04 - T_accuracy: 0.9772 - R_accuracy: 0.5452 - val_loss: 0.5187 - val_T_loss: 0.5183 - val_R_loss: 3.6289e-04 - val_T_accuracy: 0.9515 - val_R_accuracy: 0.4626\n",
            "Epoch 48/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0379 - T_loss: 0.0376 - R_loss: 2.4922e-04 - T_accuracy: 0.9756 - R_accuracy: 0.5285 - val_loss: 0.5427 - val_T_loss: 0.5423 - val_R_loss: 3.9980e-04 - val_T_accuracy: 0.9427 - val_R_accuracy: 0.4802\n",
            "Epoch 49/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0424 - T_loss: 0.0422 - R_loss: 2.5403e-04 - T_accuracy: 0.9795 - R_accuracy: 0.5659 - val_loss: 0.5587 - val_T_loss: 0.5584 - val_R_loss: 3.6721e-04 - val_T_accuracy: 0.9427 - val_R_accuracy: 0.5110\n",
            "Epoch 50/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0396 - T_loss: 0.0393 - R_loss: 2.9724e-04 - T_accuracy: 0.9761 - R_accuracy: 0.5392 - val_loss: 0.5467 - val_T_loss: 0.5463 - val_R_loss: 4.3213e-04 - val_T_accuracy: 0.9295 - val_R_accuracy: 0.4934\n",
            "Train on 1035 samples, validate on 55 samples\n",
            "Epoch 1/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 37.7316 - T_loss: 37.7250 - R_loss: 0.0066 - T_accuracy: 0.8068 - R_accuracy: 0.2986 - val_loss: 21.9421 - val_T_loss: 21.9414 - val_R_loss: 7.4181e-04 - val_T_accuracy: 0.8000 - val_R_accuracy: 0.3091\n",
            "Epoch 2/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 19.4887 - T_loss: 19.4828 - R_loss: 0.0059 - T_accuracy: 0.8976 - R_accuracy: 0.2396 - val_loss: 14.8155 - val_T_loss: 14.8139 - val_R_loss: 0.0016 - val_T_accuracy: 0.9455 - val_R_accuracy: 0.2182\n",
            "Epoch 3/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 12.4563 - T_loss: 12.4507 - R_loss: 0.0056 - T_accuracy: 0.9623 - R_accuracy: 0.3498 - val_loss: 9.0729 - val_T_loss: 9.0726 - val_R_loss: 3.5894e-04 - val_T_accuracy: 0.9818 - val_R_accuracy: 0.3455\n",
            "Epoch 4/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 9.8134 - T_loss: 9.8085 - R_loss: 0.0048 - T_accuracy: 0.9691 - R_accuracy: 0.3266 - val_loss: 8.9995 - val_T_loss: 8.9984 - val_R_loss: 0.0011 - val_T_accuracy: 0.9091 - val_R_accuracy: 0.3636\n",
            "Epoch 5/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 7.2969 - T_loss: 7.2928 - R_loss: 0.0041 - T_accuracy: 0.9729 - R_accuracy: 0.4261 - val_loss: 6.4591 - val_T_loss: 6.4579 - val_R_loss: 0.0012 - val_T_accuracy: 0.9273 - val_R_accuracy: 0.4182\n",
            "Epoch 6/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 4.4723 - T_loss: 4.4683 - R_loss: 0.0040 - T_accuracy: 0.9710 - R_accuracy: 0.4029 - val_loss: 7.7480 - val_T_loss: 7.7458 - val_R_loss: 0.0022 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.3455\n",
            "Epoch 7/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 3.4278 - T_loss: 3.4246 - R_loss: 0.0033 - T_accuracy: 0.9826 - R_accuracy: 0.3729 - val_loss: 4.9811 - val_T_loss: 4.9797 - val_R_loss: 0.0014 - val_T_accuracy: 0.9273 - val_R_accuracy: 0.4545\n",
            "Epoch 8/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 2.5451 - T_loss: 2.5421 - R_loss: 0.0031 - T_accuracy: 0.9816 - R_accuracy: 0.5082 - val_loss: 4.4466 - val_T_loss: 4.4463 - val_R_loss: 3.3154e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.3273\n",
            "Epoch 9/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 2.0779 - T_loss: 2.0753 - R_loss: 0.0026 - T_accuracy: 0.9836 - R_accuracy: 0.3420 - val_loss: 4.6749 - val_T_loss: 4.6733 - val_R_loss: 0.0016 - val_T_accuracy: 0.9455 - val_R_accuracy: 0.4545\n",
            "Epoch 10/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 1.1215 - T_loss: 1.1192 - R_loss: 0.0023 - T_accuracy: 0.9826 - R_accuracy: 0.4454 - val_loss: 4.4755 - val_T_loss: 4.4740 - val_R_loss: 0.0016 - val_T_accuracy: 0.9455 - val_R_accuracy: 0.6000\n",
            "Epoch 11/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.6822 - T_loss: 0.6802 - R_loss: 0.0020 - T_accuracy: 0.9865 - R_accuracy: 0.5382 - val_loss: 5.1674 - val_T_loss: 5.1660 - val_R_loss: 0.0014 - val_T_accuracy: 0.9455 - val_R_accuracy: 0.5818\n",
            "Epoch 12/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.5857 - T_loss: 0.5841 - R_loss: 0.0016 - T_accuracy: 0.9855 - R_accuracy: 0.5246 - val_loss: 4.8525 - val_T_loss: 4.8516 - val_R_loss: 9.8168e-04 - val_T_accuracy: 0.9455 - val_R_accuracy: 0.4727\n",
            "Epoch 13/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.3567 - T_loss: 0.3552 - R_loss: 0.0015 - T_accuracy: 0.9903 - R_accuracy: 0.5961 - val_loss: 4.7334 - val_T_loss: 4.7325 - val_R_loss: 8.6526e-04 - val_T_accuracy: 0.9455 - val_R_accuracy: 0.6000\n",
            "Epoch 14/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.2514 - T_loss: 0.2500 - R_loss: 0.0014 - T_accuracy: 0.9884 - R_accuracy: 0.6213 - val_loss: 4.3081 - val_T_loss: 4.3075 - val_R_loss: 6.0335e-04 - val_T_accuracy: 0.9455 - val_R_accuracy: 0.6000\n",
            "Epoch 15/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.2574 - T_loss: 0.2560 - R_loss: 0.0013 - T_accuracy: 0.9932 - R_accuracy: 0.5536 - val_loss: 4.3692 - val_T_loss: 4.3684 - val_R_loss: 7.4527e-04 - val_T_accuracy: 0.9455 - val_R_accuracy: 0.5091\n",
            "Epoch 16/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.1894 - T_loss: 0.1885 - R_loss: 9.5307e-04 - T_accuracy: 0.9932 - R_accuracy: 0.6338 - val_loss: 4.5507 - val_T_loss: 4.5493 - val_R_loss: 0.0014 - val_T_accuracy: 0.9455 - val_R_accuracy: 0.4909\n",
            "Epoch 17/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.1255 - T_loss: 0.1246 - R_loss: 8.7295e-04 - T_accuracy: 0.9903 - R_accuracy: 0.6251 - val_loss: 4.3540 - val_T_loss: 4.3533 - val_R_loss: 6.7175e-04 - val_T_accuracy: 0.9455 - val_R_accuracy: 0.5455\n",
            "Epoch 18/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0852 - T_loss: 0.0845 - R_loss: 7.1197e-04 - T_accuracy: 0.9913 - R_accuracy: 0.6290 - val_loss: 4.3496 - val_T_loss: 4.3487 - val_R_loss: 9.4429e-04 - val_T_accuracy: 0.9455 - val_R_accuracy: 0.4727\n",
            "Epoch 19/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0847 - T_loss: 0.0841 - R_loss: 6.0274e-04 - T_accuracy: 0.9932 - R_accuracy: 0.6232 - val_loss: 4.5671 - val_T_loss: 4.5660 - val_R_loss: 0.0011 - val_T_accuracy: 0.9455 - val_R_accuracy: 0.4909\n",
            "Epoch 20/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0623 - T_loss: 0.0618 - R_loss: 5.4463e-04 - T_accuracy: 0.9932 - R_accuracy: 0.6213 - val_loss: 4.2831 - val_T_loss: 4.2820 - val_R_loss: 0.0011 - val_T_accuracy: 0.9455 - val_R_accuracy: 0.5455\n",
            "Epoch 21/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0585 - T_loss: 0.0580 - R_loss: 4.7305e-04 - T_accuracy: 0.9952 - R_accuracy: 0.6251 - val_loss: 4.3692 - val_T_loss: 4.3682 - val_R_loss: 0.0011 - val_T_accuracy: 0.9455 - val_R_accuracy: 0.3818\n",
            "Epoch 22/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0814 - T_loss: 0.0811 - R_loss: 3.5091e-04 - T_accuracy: 0.9981 - R_accuracy: 0.6367 - val_loss: 4.3198 - val_T_loss: 4.3187 - val_R_loss: 0.0011 - val_T_accuracy: 0.9455 - val_R_accuracy: 0.5455\n",
            "Epoch 23/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0647 - T_loss: 0.0643 - R_loss: 3.3846e-04 - T_accuracy: 0.9932 - R_accuracy: 0.6473 - val_loss: 4.3787 - val_T_loss: 4.3777 - val_R_loss: 0.0010 - val_T_accuracy: 0.9455 - val_R_accuracy: 0.5455\n",
            "Epoch 24/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0581 - T_loss: 0.0578 - R_loss: 2.7251e-04 - T_accuracy: 0.9952 - R_accuracy: 0.6309 - val_loss: 4.2497 - val_T_loss: 4.2489 - val_R_loss: 8.1059e-04 - val_T_accuracy: 0.9455 - val_R_accuracy: 0.5273\n",
            "Epoch 25/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0539 - T_loss: 0.0536 - R_loss: 2.6726e-04 - T_accuracy: 0.9952 - R_accuracy: 0.6531 - val_loss: 4.0659 - val_T_loss: 4.0651 - val_R_loss: 7.6480e-04 - val_T_accuracy: 0.9455 - val_R_accuracy: 0.5091\n",
            "Epoch 26/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0512 - T_loss: 0.0510 - R_loss: 2.3501e-04 - T_accuracy: 0.9952 - R_accuracy: 0.6454 - val_loss: 4.1483 - val_T_loss: 4.1473 - val_R_loss: 9.9982e-04 - val_T_accuracy: 0.9455 - val_R_accuracy: 0.5273\n",
            "Epoch 27/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0400 - T_loss: 0.0397 - R_loss: 2.2621e-04 - T_accuracy: 0.9990 - R_accuracy: 0.6473 - val_loss: 4.1478 - val_T_loss: 4.1470 - val_R_loss: 8.5557e-04 - val_T_accuracy: 0.9455 - val_R_accuracy: 0.5273\n",
            "Epoch 28/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0287 - T_loss: 0.0285 - R_loss: 1.7995e-04 - T_accuracy: 0.9952 - R_accuracy: 0.6454 - val_loss: 4.1860 - val_T_loss: 4.1852 - val_R_loss: 8.3335e-04 - val_T_accuracy: 0.9455 - val_R_accuracy: 0.6000\n",
            "Epoch 29/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0270 - T_loss: 0.0269 - R_loss: 1.5499e-04 - T_accuracy: 0.9981 - R_accuracy: 0.6551 - val_loss: 4.2136 - val_T_loss: 4.2126 - val_R_loss: 0.0010 - val_T_accuracy: 0.9455 - val_R_accuracy: 0.5455\n",
            "Epoch 30/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0210 - T_loss: 0.0209 - R_loss: 1.2305e-04 - T_accuracy: 0.9952 - R_accuracy: 0.6686 - val_loss: 4.1542 - val_T_loss: 4.1533 - val_R_loss: 9.8194e-04 - val_T_accuracy: 0.9455 - val_R_accuracy: 0.5273\n",
            "Epoch 31/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0139 - T_loss: 0.0138 - R_loss: 1.0007e-04 - T_accuracy: 0.9990 - R_accuracy: 0.6647 - val_loss: 4.1302 - val_T_loss: 4.1292 - val_R_loss: 0.0010 - val_T_accuracy: 0.9455 - val_R_accuracy: 0.4727\n",
            "Epoch 32/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0142 - T_loss: 0.0141 - R_loss: 7.9548e-05 - T_accuracy: 0.9961 - R_accuracy: 0.6705 - val_loss: 4.2145 - val_T_loss: 4.2134 - val_R_loss: 0.0011 - val_T_accuracy: 0.9455 - val_R_accuracy: 0.5455\n",
            "Epoch 33/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0116 - T_loss: 0.0115 - R_loss: 9.2581e-05 - T_accuracy: 0.9981 - R_accuracy: 0.6763 - val_loss: 4.0880 - val_T_loss: 4.0870 - val_R_loss: 9.8998e-04 - val_T_accuracy: 0.9455 - val_R_accuracy: 0.4909\n",
            "Epoch 34/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0100 - T_loss: 0.0099 - R_loss: 7.0407e-05 - T_accuracy: 0.9971 - R_accuracy: 0.6580 - val_loss: 4.1719 - val_T_loss: 4.1709 - val_R_loss: 0.0010 - val_T_accuracy: 0.9455 - val_R_accuracy: 0.4909\n",
            "Epoch 35/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0114 - T_loss: 0.0113 - R_loss: 6.0565e-05 - T_accuracy: 0.9981 - R_accuracy: 0.6638 - val_loss: 4.1452 - val_T_loss: 4.1442 - val_R_loss: 0.0010 - val_T_accuracy: 0.9455 - val_R_accuracy: 0.5091\n",
            "Epoch 36/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0121 - T_loss: 0.0120 - R_loss: 4.8391e-05 - T_accuracy: 0.9981 - R_accuracy: 0.6696 - val_loss: 4.2100 - val_T_loss: 4.2089 - val_R_loss: 0.0011 - val_T_accuracy: 0.9455 - val_R_accuracy: 0.5455\n",
            "Epoch 37/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0153 - T_loss: 0.0152 - R_loss: 4.3903e-05 - T_accuracy: 0.9971 - R_accuracy: 0.6802 - val_loss: 4.1306 - val_T_loss: 4.1295 - val_R_loss: 0.0010 - val_T_accuracy: 0.9455 - val_R_accuracy: 0.5091\n",
            "Epoch 38/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0135 - T_loss: 0.0135 - R_loss: 4.2173e-05 - T_accuracy: 0.9981 - R_accuracy: 0.6734 - val_loss: 4.1801 - val_T_loss: 4.1790 - val_R_loss: 0.0011 - val_T_accuracy: 0.9455 - val_R_accuracy: 0.5273\n",
            "Epoch 39/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0131 - T_loss: 0.0130 - R_loss: 3.9770e-05 - T_accuracy: 0.9971 - R_accuracy: 0.6715 - val_loss: 4.1100 - val_T_loss: 4.1090 - val_R_loss: 0.0010 - val_T_accuracy: 0.9455 - val_R_accuracy: 0.4727\n",
            "Epoch 40/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0157 - T_loss: 0.0157 - R_loss: 2.7182e-05 - T_accuracy: 0.9981 - R_accuracy: 0.6715 - val_loss: 4.1967 - val_T_loss: 4.1957 - val_R_loss: 9.9049e-04 - val_T_accuracy: 0.9455 - val_R_accuracy: 0.4909\n",
            "Epoch 41/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0162 - T_loss: 0.0162 - R_loss: 2.4083e-05 - T_accuracy: 0.9990 - R_accuracy: 0.6763 - val_loss: 4.0856 - val_T_loss: 4.0845 - val_R_loss: 0.0011 - val_T_accuracy: 0.9455 - val_R_accuracy: 0.5455\n",
            "Epoch 42/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0205 - T_loss: 0.0205 - R_loss: 2.2726e-05 - T_accuracy: 0.9981 - R_accuracy: 0.6860 - val_loss: 4.0643 - val_T_loss: 4.0634 - val_R_loss: 9.6683e-04 - val_T_accuracy: 0.9455 - val_R_accuracy: 0.5091\n",
            "Epoch 43/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0319 - T_loss: 0.0319 - R_loss: 3.7696e-05 - T_accuracy: 0.9923 - R_accuracy: 0.6754 - val_loss: 4.0101 - val_T_loss: 4.0092 - val_R_loss: 9.1681e-04 - val_T_accuracy: 0.9455 - val_R_accuracy: 0.4909\n",
            "Epoch 44/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0416 - T_loss: 0.0415 - R_loss: 4.8231e-05 - T_accuracy: 0.9981 - R_accuracy: 0.6744 - val_loss: 4.1950 - val_T_loss: 4.1940 - val_R_loss: 9.3382e-04 - val_T_accuracy: 0.9455 - val_R_accuracy: 0.5091\n",
            "Epoch 45/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0540 - T_loss: 0.0540 - R_loss: 2.5293e-05 - T_accuracy: 0.9971 - R_accuracy: 0.6725 - val_loss: 4.1272 - val_T_loss: 4.1264 - val_R_loss: 8.5193e-04 - val_T_accuracy: 0.9455 - val_R_accuracy: 0.5273\n",
            "Epoch 46/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.1068 - T_loss: 0.1067 - R_loss: 2.9567e-05 - T_accuracy: 0.9961 - R_accuracy: 0.6889 - val_loss: 4.4141 - val_T_loss: 4.4130 - val_R_loss: 0.0012 - val_T_accuracy: 0.9455 - val_R_accuracy: 0.5091\n",
            "Epoch 47/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.1900 - T_loss: 0.1899 - R_loss: 4.0146e-05 - T_accuracy: 0.9952 - R_accuracy: 0.6870 - val_loss: 4.5024 - val_T_loss: 4.5018 - val_R_loss: 6.3840e-04 - val_T_accuracy: 0.9455 - val_R_accuracy: 0.5091\n",
            "Epoch 48/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.2535 - T_loss: 0.2533 - R_loss: 1.6311e-04 - T_accuracy: 0.9932 - R_accuracy: 0.6638 - val_loss: 4.0885 - val_T_loss: 4.0876 - val_R_loss: 8.4909e-04 - val_T_accuracy: 0.9455 - val_R_accuracy: 0.4909\n",
            "Epoch 49/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.5589 - T_loss: 0.5588 - R_loss: 1.6369e-04 - T_accuracy: 0.9923 - R_accuracy: 0.6628 - val_loss: 4.7975 - val_T_loss: 4.7968 - val_R_loss: 6.7233e-04 - val_T_accuracy: 0.9455 - val_R_accuracy: 0.5273\n",
            "Epoch 50/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.8369 - T_loss: 0.8368 - R_loss: 1.4359e-04 - T_accuracy: 0.9913 - R_accuracy: 0.6106 - val_loss: 4.0340 - val_T_loss: 4.0336 - val_R_loss: 4.4557e-04 - val_T_accuracy: 0.9818 - val_R_accuracy: 0.5455\n",
            "Train on 4417 samples, validate on 233 samples\n",
            "Epoch 1/50\n",
            "4417/4417 [==============================] - 37s 8ms/sample - loss: 8.9577 - T_loss: 8.9532 - R_loss: 0.0046 - T_accuracy: 0.7107 - R_accuracy: 0.3194 - val_loss: 6.1263 - val_T_loss: 6.1181 - val_R_loss: 0.0083 - val_T_accuracy: 0.8369 - val_R_accuracy: 0.3691\n",
            "Epoch 2/50\n",
            "4417/4417 [==============================] - 37s 8ms/sample - loss: 3.1502 - T_loss: 3.1462 - R_loss: 0.0040 - T_accuracy: 0.8710 - R_accuracy: 0.3751 - val_loss: 2.9767 - val_T_loss: 2.9699 - val_R_loss: 0.0068 - val_T_accuracy: 0.8841 - val_R_accuracy: 0.3391\n",
            "Epoch 3/50\n",
            "4417/4417 [==============================] - 37s 8ms/sample - loss: 1.2745 - T_loss: 1.2716 - R_loss: 0.0029 - T_accuracy: 0.9160 - R_accuracy: 0.3656 - val_loss: 2.2199 - val_T_loss: 2.2143 - val_R_loss: 0.0056 - val_T_accuracy: 0.9142 - val_R_accuracy: 0.3605\n",
            "Epoch 4/50\n",
            "4417/4417 [==============================] - 37s 8ms/sample - loss: 0.6533 - T_loss: 0.6511 - R_loss: 0.0022 - T_accuracy: 0.9368 - R_accuracy: 0.3672 - val_loss: 1.7574 - val_T_loss: 1.7511 - val_R_loss: 0.0063 - val_T_accuracy: 0.9056 - val_R_accuracy: 0.3519\n",
            "Epoch 5/50\n",
            "4417/4417 [==============================] - 38s 8ms/sample - loss: 0.3023 - T_loss: 0.3004 - R_loss: 0.0019 - T_accuracy: 0.9615 - R_accuracy: 0.3971 - val_loss: 1.6107 - val_T_loss: 1.6055 - val_R_loss: 0.0052 - val_T_accuracy: 0.9270 - val_R_accuracy: 0.3820\n",
            "Epoch 6/50\n",
            "4417/4417 [==============================] - 37s 8ms/sample - loss: 0.1771 - T_loss: 0.1756 - R_loss: 0.0015 - T_accuracy: 0.9712 - R_accuracy: 0.4025 - val_loss: 1.8301 - val_T_loss: 1.8259 - val_R_loss: 0.0041 - val_T_accuracy: 0.9185 - val_R_accuracy: 0.3691\n",
            "Epoch 7/50\n",
            "4417/4417 [==============================] - 38s 8ms/sample - loss: 0.1363 - T_loss: 0.1353 - R_loss: 9.8916e-04 - T_accuracy: 0.9769 - R_accuracy: 0.4338 - val_loss: 1.5644 - val_T_loss: 1.5601 - val_R_loss: 0.0042 - val_T_accuracy: 0.9313 - val_R_accuracy: 0.4335\n",
            "Epoch 8/50\n",
            "4417/4417 [==============================] - 37s 8ms/sample - loss: 0.0806 - T_loss: 0.0796 - R_loss: 9.3512e-04 - T_accuracy: 0.9821 - R_accuracy: 0.4428 - val_loss: 1.6119 - val_T_loss: 1.6069 - val_R_loss: 0.0050 - val_T_accuracy: 0.9142 - val_R_accuracy: 0.4335\n",
            "Epoch 9/50\n",
            "4417/4417 [==============================] - 38s 8ms/sample - loss: 0.0720 - T_loss: 0.0714 - R_loss: 6.3261e-04 - T_accuracy: 0.9817 - R_accuracy: 0.4446 - val_loss: 1.5247 - val_T_loss: 1.5184 - val_R_loss: 0.0063 - val_T_accuracy: 0.9356 - val_R_accuracy: 0.4764\n",
            "Epoch 10/50\n",
            "4417/4417 [==============================] - 38s 8ms/sample - loss: 0.0501 - T_loss: 0.0497 - R_loss: 4.3722e-04 - T_accuracy: 0.9862 - R_accuracy: 0.4582 - val_loss: 1.5506 - val_T_loss: 1.5468 - val_R_loss: 0.0038 - val_T_accuracy: 0.9227 - val_R_accuracy: 0.4421\n",
            "Epoch 11/50\n",
            "4417/4417 [==============================] - 37s 8ms/sample - loss: 0.0499 - T_loss: 0.0495 - R_loss: 4.0248e-04 - T_accuracy: 0.9866 - R_accuracy: 0.4682 - val_loss: 1.5229 - val_T_loss: 1.5189 - val_R_loss: 0.0040 - val_T_accuracy: 0.9356 - val_R_accuracy: 0.4378\n",
            "Epoch 12/50\n",
            "4417/4417 [==============================] - 38s 8ms/sample - loss: 0.0443 - T_loss: 0.0440 - R_loss: 2.8159e-04 - T_accuracy: 0.9882 - R_accuracy: 0.4657 - val_loss: 1.5832 - val_T_loss: 1.5792 - val_R_loss: 0.0040 - val_T_accuracy: 0.9356 - val_R_accuracy: 0.4506\n",
            "Epoch 13/50\n",
            "4417/4417 [==============================] - 38s 8ms/sample - loss: 0.0447 - T_loss: 0.0445 - R_loss: 2.2668e-04 - T_accuracy: 0.9882 - R_accuracy: 0.4752 - val_loss: 1.5379 - val_T_loss: 1.5339 - val_R_loss: 0.0039 - val_T_accuracy: 0.9399 - val_R_accuracy: 0.4206\n",
            "Epoch 14/50\n",
            "4417/4417 [==============================] - 37s 8ms/sample - loss: 0.0463 - T_loss: 0.0461 - R_loss: 2.2239e-04 - T_accuracy: 0.9898 - R_accuracy: 0.4829 - val_loss: 1.5464 - val_T_loss: 1.5420 - val_R_loss: 0.0044 - val_T_accuracy: 0.9313 - val_R_accuracy: 0.4206\n",
            "Epoch 15/50\n",
            "4417/4417 [==============================] - 37s 8ms/sample - loss: 0.1035 - T_loss: 0.1033 - R_loss: 1.9136e-04 - T_accuracy: 0.9848 - R_accuracy: 0.4770 - val_loss: 1.5971 - val_T_loss: 1.5929 - val_R_loss: 0.0042 - val_T_accuracy: 0.9270 - val_R_accuracy: 0.4378\n",
            "Epoch 16/50\n",
            "4417/4417 [==============================] - 37s 8ms/sample - loss: 0.1011 - T_loss: 0.1009 - R_loss: 1.9918e-04 - T_accuracy: 0.9873 - R_accuracy: 0.4739 - val_loss: 1.6057 - val_T_loss: 1.6011 - val_R_loss: 0.0046 - val_T_accuracy: 0.9442 - val_R_accuracy: 0.4292\n",
            "Epoch 17/50\n",
            "4417/4417 [==============================] - 38s 8ms/sample - loss: 0.1336 - T_loss: 0.1334 - R_loss: 2.1645e-04 - T_accuracy: 0.9823 - R_accuracy: 0.4729 - val_loss: 1.5575 - val_T_loss: 1.5538 - val_R_loss: 0.0038 - val_T_accuracy: 0.9356 - val_R_accuracy: 0.4592\n",
            "Epoch 18/50\n",
            "4417/4417 [==============================] - 38s 8ms/sample - loss: 0.1124 - T_loss: 0.1122 - R_loss: 1.9172e-04 - T_accuracy: 0.9857 - R_accuracy: 0.4827 - val_loss: 1.5259 - val_T_loss: 1.5215 - val_R_loss: 0.0044 - val_T_accuracy: 0.9399 - val_R_accuracy: 0.4979\n",
            "Epoch 19/50\n",
            "4417/4417 [==============================] - 38s 8ms/sample - loss: 0.0775 - T_loss: 0.0773 - R_loss: 1.9096e-04 - T_accuracy: 0.9873 - R_accuracy: 0.4695 - val_loss: 1.6163 - val_T_loss: 1.6121 - val_R_loss: 0.0042 - val_T_accuracy: 0.9399 - val_R_accuracy: 0.4807\n",
            "Epoch 20/50\n",
            "4417/4417 [==============================] - 37s 8ms/sample - loss: 0.0638 - T_loss: 0.0637 - R_loss: 1.3950e-04 - T_accuracy: 0.9896 - R_accuracy: 0.4877 - val_loss: 1.6060 - val_T_loss: 1.6017 - val_R_loss: 0.0043 - val_T_accuracy: 0.9270 - val_R_accuracy: 0.4378\n",
            "Epoch 21/50\n",
            "4417/4417 [==============================] - 38s 8ms/sample - loss: 0.0651 - T_loss: 0.0650 - R_loss: 1.2732e-04 - T_accuracy: 0.9882 - R_accuracy: 0.4863 - val_loss: 1.5518 - val_T_loss: 1.5477 - val_R_loss: 0.0040 - val_T_accuracy: 0.9399 - val_R_accuracy: 0.4850\n",
            "Epoch 22/50\n",
            "4417/4417 [==============================] - 38s 8ms/sample - loss: 0.0765 - T_loss: 0.0763 - R_loss: 1.5685e-04 - T_accuracy: 0.9860 - R_accuracy: 0.4915 - val_loss: 1.4934 - val_T_loss: 1.4892 - val_R_loss: 0.0042 - val_T_accuracy: 0.9313 - val_R_accuracy: 0.4893\n",
            "Epoch 23/50\n",
            "4417/4417 [==============================] - 37s 8ms/sample - loss: 0.0782 - T_loss: 0.0781 - R_loss: 1.3140e-04 - T_accuracy: 0.9889 - R_accuracy: 0.4990 - val_loss: 1.5429 - val_T_loss: 1.5379 - val_R_loss: 0.0049 - val_T_accuracy: 0.9399 - val_R_accuracy: 0.4549\n",
            "Epoch 24/50\n",
            "4417/4417 [==============================] - 37s 8ms/sample - loss: 0.0747 - T_loss: 0.0745 - R_loss: 1.6056e-04 - T_accuracy: 0.9853 - R_accuracy: 0.4933 - val_loss: 1.5567 - val_T_loss: 1.5523 - val_R_loss: 0.0044 - val_T_accuracy: 0.9399 - val_R_accuracy: 0.4335\n",
            "Epoch 25/50\n",
            "4417/4417 [==============================] - 38s 8ms/sample - loss: 0.0687 - T_loss: 0.0685 - R_loss: 2.1320e-04 - T_accuracy: 0.9894 - R_accuracy: 0.4874 - val_loss: 1.5402 - val_T_loss: 1.5359 - val_R_loss: 0.0044 - val_T_accuracy: 0.9313 - val_R_accuracy: 0.4936\n",
            "Epoch 26/50\n",
            "4417/4417 [==============================] - 38s 8ms/sample - loss: 0.0877 - T_loss: 0.0875 - R_loss: 1.9267e-04 - T_accuracy: 0.9837 - R_accuracy: 0.4836 - val_loss: 1.5017 - val_T_loss: 1.4977 - val_R_loss: 0.0041 - val_T_accuracy: 0.9399 - val_R_accuracy: 0.4807\n",
            "Epoch 27/50\n",
            "4417/4417 [==============================] - 37s 8ms/sample - loss: 0.0673 - T_loss: 0.0671 - R_loss: 1.6485e-04 - T_accuracy: 0.9889 - R_accuracy: 0.4904 - val_loss: 1.4977 - val_T_loss: 1.4934 - val_R_loss: 0.0042 - val_T_accuracy: 0.9356 - val_R_accuracy: 0.4807\n",
            "Epoch 28/50\n",
            "4417/4417 [==============================] - 37s 8ms/sample - loss: 0.0937 - T_loss: 0.0936 - R_loss: 1.6021e-04 - T_accuracy: 0.9898 - R_accuracy: 0.4947 - val_loss: 1.6876 - val_T_loss: 1.6831 - val_R_loss: 0.0045 - val_T_accuracy: 0.9313 - val_R_accuracy: 0.5021\n",
            "Epoch 29/50\n",
            "4417/4417 [==============================] - 37s 8ms/sample - loss: 0.1315 - T_loss: 0.1313 - R_loss: 1.6241e-04 - T_accuracy: 0.9846 - R_accuracy: 0.5035 - val_loss: 1.7102 - val_T_loss: 1.7061 - val_R_loss: 0.0041 - val_T_accuracy: 0.9442 - val_R_accuracy: 0.4893\n",
            "Epoch 30/50\n",
            "4417/4417 [==============================] - 38s 8ms/sample - loss: 0.2421 - T_loss: 0.2419 - R_loss: 2.2233e-04 - T_accuracy: 0.9751 - R_accuracy: 0.4879 - val_loss: 1.5241 - val_T_loss: 1.5199 - val_R_loss: 0.0042 - val_T_accuracy: 0.9442 - val_R_accuracy: 0.4936\n",
            "Epoch 31/50\n",
            "4417/4417 [==============================] - 38s 8ms/sample - loss: 0.1603 - T_loss: 0.1600 - R_loss: 2.1610e-04 - T_accuracy: 0.9792 - R_accuracy: 0.4804 - val_loss: 1.6106 - val_T_loss: 1.6070 - val_R_loss: 0.0036 - val_T_accuracy: 0.9399 - val_R_accuracy: 0.4850\n",
            "Epoch 32/50\n",
            "4417/4417 [==============================] - 37s 8ms/sample - loss: 0.0939 - T_loss: 0.0936 - R_loss: 2.6526e-04 - T_accuracy: 0.9898 - R_accuracy: 0.4791 - val_loss: 1.6120 - val_T_loss: 1.6067 - val_R_loss: 0.0052 - val_T_accuracy: 0.9399 - val_R_accuracy: 0.4979\n",
            "Epoch 33/50\n",
            "4417/4417 [==============================] - 37s 8ms/sample - loss: 0.1122 - T_loss: 0.1120 - R_loss: 1.6367e-04 - T_accuracy: 0.9862 - R_accuracy: 0.5010 - val_loss: 1.5654 - val_T_loss: 1.5608 - val_R_loss: 0.0045 - val_T_accuracy: 0.9442 - val_R_accuracy: 0.5107\n",
            "Epoch 34/50\n",
            "4417/4417 [==============================] - 37s 8ms/sample - loss: 0.0915 - T_loss: 0.0913 - R_loss: 1.7851e-04 - T_accuracy: 0.9875 - R_accuracy: 0.4999 - val_loss: 1.6146 - val_T_loss: 1.6101 - val_R_loss: 0.0044 - val_T_accuracy: 0.9442 - val_R_accuracy: 0.5107\n",
            "Epoch 35/50\n",
            "4417/4417 [==============================] - 37s 8ms/sample - loss: 0.0802 - T_loss: 0.0800 - R_loss: 1.9885e-04 - T_accuracy: 0.9846 - R_accuracy: 0.4972 - val_loss: 1.5153 - val_T_loss: 1.5111 - val_R_loss: 0.0042 - val_T_accuracy: 0.9442 - val_R_accuracy: 0.4893\n",
            "Epoch 36/50\n",
            "4417/4417 [==============================] - 37s 8ms/sample - loss: 0.0642 - T_loss: 0.0641 - R_loss: 1.1481e-04 - T_accuracy: 0.9905 - R_accuracy: 0.4994 - val_loss: 1.5460 - val_T_loss: 1.5417 - val_R_loss: 0.0044 - val_T_accuracy: 0.9528 - val_R_accuracy: 0.4979\n",
            "Epoch 37/50\n",
            "4417/4417 [==============================] - 37s 8ms/sample - loss: 0.0729 - T_loss: 0.0728 - R_loss: 1.0302e-04 - T_accuracy: 0.9860 - R_accuracy: 0.5051 - val_loss: 1.5035 - val_T_loss: 1.4988 - val_R_loss: 0.0047 - val_T_accuracy: 0.9399 - val_R_accuracy: 0.4678\n",
            "Epoch 38/50\n",
            "4417/4417 [==============================] - 37s 8ms/sample - loss: 0.0527 - T_loss: 0.0526 - R_loss: 9.4785e-05 - T_accuracy: 0.9909 - R_accuracy: 0.5024 - val_loss: 1.4200 - val_T_loss: 1.4154 - val_R_loss: 0.0046 - val_T_accuracy: 0.9399 - val_R_accuracy: 0.4721\n",
            "Epoch 39/50\n",
            "4417/4417 [==============================] - 37s 8ms/sample - loss: 0.0505 - T_loss: 0.0504 - R_loss: 9.7519e-05 - T_accuracy: 0.9900 - R_accuracy: 0.5035 - val_loss: 1.4917 - val_T_loss: 1.4873 - val_R_loss: 0.0044 - val_T_accuracy: 0.9442 - val_R_accuracy: 0.4549\n",
            "Epoch 40/50\n",
            "4417/4417 [==============================] - 37s 8ms/sample - loss: 0.0397 - T_loss: 0.0396 - R_loss: 9.0909e-05 - T_accuracy: 0.9939 - R_accuracy: 0.5069 - val_loss: 1.4639 - val_T_loss: 1.4599 - val_R_loss: 0.0041 - val_T_accuracy: 0.9356 - val_R_accuracy: 0.4807\n",
            "Epoch 41/50\n",
            "4417/4417 [==============================] - 37s 8ms/sample - loss: 0.0398 - T_loss: 0.0397 - R_loss: 1.3566e-04 - T_accuracy: 0.9928 - R_accuracy: 0.5108 - val_loss: 1.5162 - val_T_loss: 1.5118 - val_R_loss: 0.0044 - val_T_accuracy: 0.9356 - val_R_accuracy: 0.4893\n",
            "Epoch 42/50\n",
            "4417/4417 [==============================] - 37s 8ms/sample - loss: 0.1510 - T_loss: 0.1508 - R_loss: 2.1366e-04 - T_accuracy: 0.9844 - R_accuracy: 0.5044 - val_loss: 1.4940 - val_T_loss: 1.4894 - val_R_loss: 0.0046 - val_T_accuracy: 0.9227 - val_R_accuracy: 0.5150\n",
            "Epoch 43/50\n",
            "4417/4417 [==============================] - 37s 8ms/sample - loss: 0.1299 - T_loss: 0.1297 - R_loss: 1.2780e-04 - T_accuracy: 0.9842 - R_accuracy: 0.5028 - val_loss: 1.6094 - val_T_loss: 1.6049 - val_R_loss: 0.0045 - val_T_accuracy: 0.9442 - val_R_accuracy: 0.4850\n",
            "Epoch 44/50\n",
            "4417/4417 [==============================] - 37s 8ms/sample - loss: 0.0862 - T_loss: 0.0860 - R_loss: 1.7478e-04 - T_accuracy: 0.9878 - R_accuracy: 0.5055 - val_loss: 1.4827 - val_T_loss: 1.4781 - val_R_loss: 0.0046 - val_T_accuracy: 0.9442 - val_R_accuracy: 0.4936\n",
            "Epoch 45/50\n",
            "4417/4417 [==============================] - 38s 8ms/sample - loss: 0.0579 - T_loss: 0.0577 - R_loss: 1.9983e-04 - T_accuracy: 0.9909 - R_accuracy: 0.4999 - val_loss: 1.4954 - val_T_loss: 1.4912 - val_R_loss: 0.0042 - val_T_accuracy: 0.9485 - val_R_accuracy: 0.4678\n",
            "Epoch 46/50\n",
            "4417/4417 [==============================] - 37s 8ms/sample - loss: 0.0421 - T_loss: 0.0419 - R_loss: 1.5415e-04 - T_accuracy: 0.9909 - R_accuracy: 0.5196 - val_loss: 1.4360 - val_T_loss: 1.4316 - val_R_loss: 0.0043 - val_T_accuracy: 0.9442 - val_R_accuracy: 0.4936\n",
            "Epoch 47/50\n",
            "4417/4417 [==============================] - 37s 8ms/sample - loss: 0.0303 - T_loss: 0.0302 - R_loss: 9.4230e-05 - T_accuracy: 0.9939 - R_accuracy: 0.5040 - val_loss: 1.4568 - val_T_loss: 1.4523 - val_R_loss: 0.0045 - val_T_accuracy: 0.9571 - val_R_accuracy: 0.4678\n",
            "Epoch 48/50\n",
            "4417/4417 [==============================] - 37s 8ms/sample - loss: 0.0268 - T_loss: 0.0267 - R_loss: 7.7467e-05 - T_accuracy: 0.9932 - R_accuracy: 0.5128 - val_loss: 1.5481 - val_T_loss: 1.5436 - val_R_loss: 0.0045 - val_T_accuracy: 0.9485 - val_R_accuracy: 0.5021\n",
            "Epoch 49/50\n",
            "4417/4417 [==============================] - 37s 8ms/sample - loss: 0.0322 - T_loss: 0.0316 - R_loss: 6.4935e-04 - T_accuracy: 0.9923 - R_accuracy: 0.4931 - val_loss: 1.4866 - val_T_loss: 1.4819 - val_R_loss: 0.0047 - val_T_accuracy: 0.9399 - val_R_accuracy: 0.4850\n",
            "Epoch 50/50\n",
            "4417/4417 [==============================] - 37s 8ms/sample - loss: 0.0358 - T_loss: 0.0356 - R_loss: 1.4741e-04 - T_accuracy: 0.9898 - R_accuracy: 0.5060 - val_loss: 1.4391 - val_T_loss: 1.4346 - val_R_loss: 0.0045 - val_T_accuracy: 0.9485 - val_R_accuracy: 0.4850\n",
            "Train on 750 samples, validate on 40 samples\n",
            "Epoch 1/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 1.8100 - T_loss: 1.8097 - R_loss: 2.5292e-04 - T_accuracy: 0.8733 - R_accuracy: 0.3813 - val_loss: 0.8038 - val_T_loss: 0.8033 - val_R_loss: 4.9409e-04 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.3500\n",
            "Epoch 2/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 0.4733 - T_loss: 0.4731 - R_loss: 1.8569e-04 - T_accuracy: 0.9427 - R_accuracy: 0.4467 - val_loss: 0.6445 - val_T_loss: 0.6441 - val_R_loss: 3.8526e-04 - val_T_accuracy: 0.9000 - val_R_accuracy: 0.3500\n",
            "Epoch 3/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 0.2389 - T_loss: 0.2387 - R_loss: 1.4108e-04 - T_accuracy: 0.9640 - R_accuracy: 0.5027 - val_loss: 0.3919 - val_T_loss: 0.3916 - val_R_loss: 3.0909e-04 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.4000\n",
            "Epoch 4/50\n",
            "750/750 [==============================] - 6s 8ms/sample - loss: 0.1123 - T_loss: 0.1122 - R_loss: 1.1348e-04 - T_accuracy: 0.9800 - R_accuracy: 0.5520 - val_loss: 0.3560 - val_T_loss: 0.3558 - val_R_loss: 2.1936e-04 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.5000\n",
            "Epoch 5/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 0.0646 - T_loss: 0.0645 - R_loss: 9.9875e-05 - T_accuracy: 0.9733 - R_accuracy: 0.5973 - val_loss: 0.3099 - val_T_loss: 0.3097 - val_R_loss: 1.8774e-04 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.6000\n",
            "Epoch 6/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 0.0294 - T_loss: 0.0293 - R_loss: 8.6925e-05 - T_accuracy: 0.9827 - R_accuracy: 0.6173 - val_loss: 0.3120 - val_T_loss: 0.3118 - val_R_loss: 2.2266e-04 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.5750\n",
            "Epoch 7/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 0.0203 - T_loss: 0.0202 - R_loss: 8.2188e-05 - T_accuracy: 0.9813 - R_accuracy: 0.6040 - val_loss: 0.2834 - val_T_loss: 0.2833 - val_R_loss: 1.7697e-04 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.6000\n",
            "Epoch 8/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 0.0138 - T_loss: 0.0137 - R_loss: 7.6132e-05 - T_accuracy: 0.9867 - R_accuracy: 0.6200 - val_loss: 0.2872 - val_T_loss: 0.2870 - val_R_loss: 1.5069e-04 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.6500\n",
            "Epoch 9/50\n",
            "750/750 [==============================] - 6s 8ms/sample - loss: 0.0087 - T_loss: 0.0086 - R_loss: 7.2784e-05 - T_accuracy: 0.9920 - R_accuracy: 0.6253 - val_loss: 0.2811 - val_T_loss: 0.2810 - val_R_loss: 1.4251e-04 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.6000\n",
            "Epoch 10/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 0.0068 - T_loss: 0.0068 - R_loss: 6.7439e-05 - T_accuracy: 0.9920 - R_accuracy: 0.6293 - val_loss: 0.2932 - val_T_loss: 0.2930 - val_R_loss: 1.2289e-04 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.6000\n",
            "Epoch 11/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 0.0048 - T_loss: 0.0047 - R_loss: 6.6761e-05 - T_accuracy: 0.9947 - R_accuracy: 0.6253 - val_loss: 0.2821 - val_T_loss: 0.2819 - val_R_loss: 1.3404e-04 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.6000\n",
            "Epoch 12/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 0.0036 - T_loss: 0.0036 - R_loss: 6.3474e-05 - T_accuracy: 0.9947 - R_accuracy: 0.6373 - val_loss: 0.2837 - val_T_loss: 0.2836 - val_R_loss: 1.1235e-04 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.6250\n",
            "Epoch 13/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 0.0029 - T_loss: 0.0028 - R_loss: 6.0675e-05 - T_accuracy: 0.9947 - R_accuracy: 0.6320 - val_loss: 0.2820 - val_T_loss: 0.2819 - val_R_loss: 1.2371e-04 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.6250\n",
            "Epoch 14/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 0.0024 - T_loss: 0.0023 - R_loss: 6.1511e-05 - T_accuracy: 0.9960 - R_accuracy: 0.6440 - val_loss: 0.2864 - val_T_loss: 0.2863 - val_R_loss: 8.6973e-05 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.6000\n",
            "Epoch 15/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 0.0020 - T_loss: 0.0020 - R_loss: 5.5955e-05 - T_accuracy: 0.9960 - R_accuracy: 0.6373 - val_loss: 0.2834 - val_T_loss: 0.2833 - val_R_loss: 8.8555e-05 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.6000\n",
            "Epoch 16/50\n",
            "750/750 [==============================] - 6s 8ms/sample - loss: 0.0017 - T_loss: 0.0016 - R_loss: 5.2069e-05 - T_accuracy: 0.9960 - R_accuracy: 0.6413 - val_loss: 0.2825 - val_T_loss: 0.2824 - val_R_loss: 8.7851e-05 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.6500\n",
            "Epoch 17/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 0.0015 - T_loss: 0.0015 - R_loss: 4.9754e-05 - T_accuracy: 0.9960 - R_accuracy: 0.6507 - val_loss: 0.2835 - val_T_loss: 0.2834 - val_R_loss: 8.5030e-05 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.6500\n",
            "Epoch 18/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 0.0013 - T_loss: 0.0013 - R_loss: 4.6720e-05 - T_accuracy: 0.9960 - R_accuracy: 0.6453 - val_loss: 0.2834 - val_T_loss: 0.2833 - val_R_loss: 7.9132e-05 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.6250\n",
            "Epoch 19/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 0.0012 - T_loss: 0.0012 - R_loss: 4.4720e-05 - T_accuracy: 0.9973 - R_accuracy: 0.6560 - val_loss: 0.2821 - val_T_loss: 0.2820 - val_R_loss: 7.8816e-05 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.6500\n",
            "Epoch 20/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 0.0012 - T_loss: 0.0011 - R_loss: 4.4701e-05 - T_accuracy: 0.9973 - R_accuracy: 0.6533 - val_loss: 0.2853 - val_T_loss: 0.2853 - val_R_loss: 8.0628e-05 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.6500\n",
            "Epoch 21/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 0.0010 - T_loss: 9.5949e-04 - R_loss: 4.3185e-05 - T_accuracy: 0.9973 - R_accuracy: 0.6587 - val_loss: 0.2853 - val_T_loss: 0.2852 - val_R_loss: 7.3773e-05 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.6250\n",
            "Epoch 22/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 8.7784e-04 - T_loss: 8.3550e-04 - R_loss: 4.2339e-05 - T_accuracy: 0.9973 - R_accuracy: 0.6520 - val_loss: 0.2833 - val_T_loss: 0.2833 - val_R_loss: 7.9885e-05 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.5750\n",
            "Epoch 23/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 8.0334e-04 - T_loss: 7.6178e-04 - R_loss: 4.1561e-05 - T_accuracy: 0.9973 - R_accuracy: 0.6547 - val_loss: 0.2846 - val_T_loss: 0.2846 - val_R_loss: 6.8624e-05 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.6250\n",
            "Epoch 24/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 7.1065e-04 - T_loss: 6.6865e-04 - R_loss: 4.1994e-05 - T_accuracy: 0.9973 - R_accuracy: 0.6627 - val_loss: 0.2844 - val_T_loss: 0.2843 - val_R_loss: 7.2020e-05 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.5750\n",
            "Epoch 25/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 6.2978e-04 - T_loss: 5.8797e-04 - R_loss: 4.1810e-05 - T_accuracy: 0.9973 - R_accuracy: 0.6560 - val_loss: 0.2865 - val_T_loss: 0.2864 - val_R_loss: 7.3637e-05 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.6000\n",
            "Epoch 26/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 6.0223e-04 - T_loss: 5.6201e-04 - R_loss: 4.0229e-05 - T_accuracy: 0.9973 - R_accuracy: 0.6680 - val_loss: 0.2852 - val_T_loss: 0.2851 - val_R_loss: 6.9415e-05 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.6500\n",
            "Epoch 27/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 5.8960e-04 - T_loss: 5.4910e-04 - R_loss: 4.0502e-05 - T_accuracy: 0.9973 - R_accuracy: 0.6587 - val_loss: 0.2858 - val_T_loss: 0.2857 - val_R_loss: 6.8796e-05 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.5750\n",
            "Epoch 28/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 5.1898e-04 - T_loss: 4.8018e-04 - R_loss: 3.8798e-05 - T_accuracy: 0.9973 - R_accuracy: 0.6600 - val_loss: 0.2857 - val_T_loss: 0.2856 - val_R_loss: 6.6845e-05 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.6000\n",
            "Epoch 29/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 4.8827e-04 - T_loss: 4.4997e-04 - R_loss: 3.8303e-05 - T_accuracy: 0.9973 - R_accuracy: 0.6573 - val_loss: 0.2863 - val_T_loss: 0.2863 - val_R_loss: 7.0117e-05 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.6000\n",
            "Epoch 30/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 4.7616e-04 - T_loss: 4.3805e-04 - R_loss: 3.8108e-05 - T_accuracy: 0.9973 - R_accuracy: 0.6627 - val_loss: 0.2876 - val_T_loss: 0.2875 - val_R_loss: 7.0363e-05 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.6000\n",
            "Epoch 31/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 4.4795e-04 - T_loss: 4.0894e-04 - R_loss: 3.9005e-05 - T_accuracy: 0.9973 - R_accuracy: 0.6653 - val_loss: 0.2873 - val_T_loss: 0.2872 - val_R_loss: 6.5302e-05 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.6000\n",
            "Epoch 32/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 4.1153e-04 - T_loss: 3.7395e-04 - R_loss: 3.7578e-05 - T_accuracy: 0.9973 - R_accuracy: 0.6640 - val_loss: 0.2854 - val_T_loss: 0.2854 - val_R_loss: 6.7090e-05 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.6000\n",
            "Epoch 33/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 5.2144e-04 - T_loss: 4.8436e-04 - R_loss: 3.7088e-05 - T_accuracy: 0.9973 - R_accuracy: 0.6720 - val_loss: 0.2867 - val_T_loss: 0.2866 - val_R_loss: 6.7776e-05 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.6000\n",
            "Epoch 34/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 4.9148e-04 - T_loss: 4.5456e-04 - R_loss: 3.6922e-05 - T_accuracy: 0.9973 - R_accuracy: 0.6747 - val_loss: 0.2877 - val_T_loss: 0.2876 - val_R_loss: 6.8256e-05 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.6250\n",
            "Epoch 35/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 4.5237e-04 - T_loss: 4.1560e-04 - R_loss: 3.6776e-05 - T_accuracy: 0.9973 - R_accuracy: 0.6773 - val_loss: 0.2856 - val_T_loss: 0.2855 - val_R_loss: 6.6314e-05 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.6250\n",
            "Epoch 36/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 4.0594e-04 - T_loss: 3.6907e-04 - R_loss: 3.6871e-05 - T_accuracy: 0.9973 - R_accuracy: 0.6733 - val_loss: 0.2871 - val_T_loss: 0.2870 - val_R_loss: 6.6442e-05 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.6250\n",
            "Epoch 37/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 4.3824e-04 - T_loss: 4.0174e-04 - R_loss: 3.6502e-05 - T_accuracy: 0.9973 - R_accuracy: 0.6720 - val_loss: 0.2881 - val_T_loss: 0.2880 - val_R_loss: 6.6329e-05 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.6500\n",
            "Epoch 38/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 5.0405e-04 - T_loss: 4.6802e-04 - R_loss: 3.6025e-05 - T_accuracy: 0.9973 - R_accuracy: 0.6760 - val_loss: 0.2874 - val_T_loss: 0.2873 - val_R_loss: 6.4466e-05 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.6250\n",
            "Epoch 39/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 6.0900e-04 - T_loss: 5.7311e-04 - R_loss: 3.5890e-05 - T_accuracy: 0.9973 - R_accuracy: 0.6733 - val_loss: 0.2881 - val_T_loss: 0.2881 - val_R_loss: 6.5922e-05 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.6500\n",
            "Epoch 40/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 7.3581e-04 - T_loss: 6.9945e-04 - R_loss: 3.6359e-05 - T_accuracy: 0.9973 - R_accuracy: 0.6707 - val_loss: 0.2863 - val_T_loss: 0.2863 - val_R_loss: 6.6513e-05 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.6250\n",
            "Epoch 41/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 7.3208e-04 - T_loss: 6.9642e-04 - R_loss: 3.5656e-05 - T_accuracy: 0.9987 - R_accuracy: 0.6773 - val_loss: 0.2886 - val_T_loss: 0.2886 - val_R_loss: 6.8187e-05 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.6000\n",
            "Epoch 42/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 7.4877e-04 - T_loss: 7.1236e-04 - R_loss: 3.6400e-05 - T_accuracy: 0.9987 - R_accuracy: 0.6680 - val_loss: 0.2874 - val_T_loss: 0.2874 - val_R_loss: 6.4180e-05 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.6500\n",
            "Epoch 43/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 6.3170e-04 - T_loss: 5.9501e-04 - R_loss: 3.6689e-05 - T_accuracy: 0.9987 - R_accuracy: 0.6800 - val_loss: 0.2887 - val_T_loss: 0.2887 - val_R_loss: 6.5595e-05 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.6000\n",
            "Epoch 44/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 6.1299e-04 - T_loss: 5.7677e-04 - R_loss: 3.6220e-05 - T_accuracy: 0.9987 - R_accuracy: 0.6733 - val_loss: 0.2840 - val_T_loss: 0.2839 - val_R_loss: 6.4555e-05 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.6250\n",
            "Epoch 45/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 6.1648e-04 - T_loss: 5.8299e-04 - R_loss: 3.3498e-05 - T_accuracy: 0.9960 - R_accuracy: 0.6720 - val_loss: 0.2901 - val_T_loss: 0.2901 - val_R_loss: 5.6899e-05 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.6500\n",
            "Epoch 46/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 8.2205e-04 - T_loss: 7.8969e-04 - R_loss: 3.2355e-05 - T_accuracy: 0.9987 - R_accuracy: 0.6720 - val_loss: 0.2829 - val_T_loss: 0.2829 - val_R_loss: 6.0954e-05 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.6000\n",
            "Epoch 47/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 0.0014 - T_loss: 0.0014 - R_loss: 3.1751e-05 - T_accuracy: 0.9987 - R_accuracy: 0.6773 - val_loss: 0.2843 - val_T_loss: 0.2843 - val_R_loss: 6.3728e-05 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.6250\n",
            "Epoch 48/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 0.0021 - T_loss: 0.0020 - R_loss: 3.2421e-05 - T_accuracy: 0.9987 - R_accuracy: 0.6733 - val_loss: 0.2935 - val_T_loss: 0.2934 - val_R_loss: 6.5290e-05 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.5750\n",
            "Epoch 49/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 0.0024 - T_loss: 0.0024 - R_loss: 3.1187e-05 - T_accuracy: 0.9987 - R_accuracy: 0.6720 - val_loss: 0.2832 - val_T_loss: 0.2831 - val_R_loss: 6.8324e-05 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.5500\n",
            "Epoch 50/50\n",
            "750/750 [==============================] - 6s 8ms/sample - loss: 0.0022 - T_loss: 0.0021 - R_loss: 3.0755e-05 - T_accuracy: 0.9987 - R_accuracy: 0.6853 - val_loss: 0.2845 - val_T_loss: 0.2844 - val_R_loss: 6.7580e-05 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.5750\n",
            "Train on 247 samples, validate on 13 samples\n",
            "Epoch 1/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 8.6598 - T_loss: 8.6597 - R_loss: 4.9375e-05 - T_accuracy: 0.8785 - R_accuracy: 0.1296 - val_loss: 3.9024 - val_T_loss: 3.9024 - val_R_loss: 1.7197e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.0769\n",
            "Epoch 2/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 2.2421 - T_loss: 2.2421 - R_loss: 5.2337e-05 - T_accuracy: 1.0000 - R_accuracy: 0.3117 - val_loss: 2.1454 - val_T_loss: 2.1453 - val_R_loss: 2.7549e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.1538\n",
            "Epoch 3/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 1.2137 - T_loss: 1.2137 - R_loss: 8.7432e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2551 - val_loss: 3.0545 - val_T_loss: 3.0545 - val_R_loss: 5.7141e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.2308\n",
            "Epoch 4/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 0.8958 - T_loss: 0.8958 - R_loss: 8.7607e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2510 - val_loss: 1.6250 - val_T_loss: 1.6250 - val_R_loss: 4.5625e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.0769\n",
            "Epoch 5/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 0.6082 - T_loss: 0.6082 - R_loss: 4.2462e-06 - T_accuracy: 1.0000 - R_accuracy: 0.1619 - val_loss: 1.7015 - val_T_loss: 1.7015 - val_R_loss: 4.3249e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.1538\n",
            "Epoch 6/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 0.5589 - T_loss: 0.5588 - R_loss: 4.2869e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2470 - val_loss: 1.4422 - val_T_loss: 1.4422 - val_R_loss: 4.0104e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.2308\n",
            "Epoch 7/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 0.3412 - T_loss: 0.3412 - R_loss: 4.4661e-06 - T_accuracy: 1.0000 - R_accuracy: 0.3036 - val_loss: 1.2417 - val_T_loss: 1.2417 - val_R_loss: 4.0607e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.1538\n",
            "Epoch 8/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 0.2385 - T_loss: 0.2384 - R_loss: 4.6387e-06 - T_accuracy: 1.0000 - R_accuracy: 0.1579 - val_loss: 1.2215 - val_T_loss: 1.2215 - val_R_loss: 4.4594e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.2308\n",
            "Epoch 9/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 0.1842 - T_loss: 0.1841 - R_loss: 4.5190e-06 - T_accuracy: 1.0000 - R_accuracy: 0.3239 - val_loss: 1.1079 - val_T_loss: 1.1079 - val_R_loss: 4.7639e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.2308\n",
            "Epoch 10/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 0.1016 - T_loss: 0.1016 - R_loss: 4.2669e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2065 - val_loss: 1.0123 - val_T_loss: 1.0123 - val_R_loss: 4.8664e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.0769\n",
            "Epoch 11/50\n",
            "247/247 [==============================] - 2s 8ms/sample - loss: 0.0647 - T_loss: 0.0647 - R_loss: 4.1506e-06 - T_accuracy: 1.0000 - R_accuracy: 0.1336 - val_loss: 1.0832 - val_T_loss: 1.0832 - val_R_loss: 4.5846e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.4615\n",
            "Epoch 12/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 0.0346 - T_loss: 0.0346 - R_loss: 4.1100e-06 - T_accuracy: 1.0000 - R_accuracy: 0.1579 - val_loss: 1.1090 - val_T_loss: 1.1090 - val_R_loss: 4.4720e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.0769\n",
            "Epoch 13/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 0.0206 - T_loss: 0.0206 - R_loss: 4.0787e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2551 - val_loss: 1.0393 - val_T_loss: 1.0393 - val_R_loss: 4.4384e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.4615\n",
            "Epoch 14/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 0.0118 - T_loss: 0.0118 - R_loss: 4.1061e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2753 - val_loss: 1.0293 - val_T_loss: 1.0293 - val_R_loss: 4.5148e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.0769\n",
            "Epoch 15/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 0.0066 - T_loss: 0.0066 - R_loss: 4.0949e-06 - T_accuracy: 1.0000 - R_accuracy: 0.1255 - val_loss: 1.0665 - val_T_loss: 1.0665 - val_R_loss: 4.4110e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.0769\n",
            "Epoch 16/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 0.0050 - T_loss: 0.0049 - R_loss: 4.0792e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2308 - val_loss: 1.0706 - val_T_loss: 1.0706 - val_R_loss: 4.3013e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.1538\n",
            "Epoch 17/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 0.0034 - T_loss: 0.0034 - R_loss: 4.0661e-06 - T_accuracy: 1.0000 - R_accuracy: 0.1538 - val_loss: 1.0567 - val_T_loss: 1.0567 - val_R_loss: 4.2808e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.0769\n",
            "Epoch 18/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 0.0025 - T_loss: 0.0025 - R_loss: 4.0656e-06 - T_accuracy: 1.0000 - R_accuracy: 0.1296 - val_loss: 1.0505 - val_T_loss: 1.0505 - val_R_loss: 4.2689e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.1538\n",
            "Epoch 19/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 0.0021 - T_loss: 0.0021 - R_loss: 4.0593e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2874 - val_loss: 1.0400 - val_T_loss: 1.0400 - val_R_loss: 4.2228e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.0769\n",
            "Epoch 20/50\n",
            "247/247 [==============================] - 2s 8ms/sample - loss: 0.0015 - T_loss: 0.0015 - R_loss: 4.0467e-06 - T_accuracy: 1.0000 - R_accuracy: 0.1215 - val_loss: 1.0395 - val_T_loss: 1.0395 - val_R_loss: 4.2521e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.1538\n",
            "Epoch 21/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 0.0013 - T_loss: 0.0013 - R_loss: 4.0807e-06 - T_accuracy: 1.0000 - R_accuracy: 0.1660 - val_loss: 1.0470 - val_T_loss: 1.0470 - val_R_loss: 4.1361e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.4615\n",
            "Epoch 22/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 0.0013 - T_loss: 0.0013 - R_loss: 4.1136e-06 - T_accuracy: 1.0000 - R_accuracy: 0.3360 - val_loss: 1.0433 - val_T_loss: 1.0433 - val_R_loss: 4.1951e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.2308\n",
            "Epoch 23/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 0.0011 - T_loss: 0.0011 - R_loss: 4.0558e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2591 - val_loss: 1.0414 - val_T_loss: 1.0414 - val_R_loss: 4.1586e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.0769\n",
            "Epoch 24/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 9.1904e-04 - T_loss: 9.1495e-04 - R_loss: 4.0920e-06 - T_accuracy: 1.0000 - R_accuracy: 0.1215 - val_loss: 1.0416 - val_T_loss: 1.0416 - val_R_loss: 4.2972e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.1538\n",
            "Epoch 25/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 8.2690e-04 - T_loss: 8.2279e-04 - R_loss: 4.1062e-06 - T_accuracy: 1.0000 - R_accuracy: 0.3401 - val_loss: 1.0423 - val_T_loss: 1.0423 - val_R_loss: 4.0460e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.5385\n",
            "Epoch 26/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 7.5588e-04 - T_loss: 7.5178e-04 - R_loss: 4.0947e-06 - T_accuracy: 1.0000 - R_accuracy: 0.1781 - val_loss: 1.0350 - val_T_loss: 1.0350 - val_R_loss: 4.2972e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.0769\n",
            "Epoch 27/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 6.8206e-04 - T_loss: 6.7803e-04 - R_loss: 4.0240e-06 - T_accuracy: 1.0000 - R_accuracy: 0.1984 - val_loss: 1.0348 - val_T_loss: 1.0348 - val_R_loss: 4.0717e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.5385\n",
            "Epoch 28/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 6.3630e-04 - T_loss: 6.3224e-04 - R_loss: 4.0631e-06 - T_accuracy: 1.0000 - R_accuracy: 0.3725 - val_loss: 1.0381 - val_T_loss: 1.0381 - val_R_loss: 4.2126e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.0769\n",
            "Epoch 29/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 5.9573e-04 - T_loss: 5.9169e-04 - R_loss: 4.0430e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2186 - val_loss: 1.0355 - val_T_loss: 1.0355 - val_R_loss: 4.1810e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.2308\n",
            "Epoch 30/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 5.5479e-04 - T_loss: 5.5076e-04 - R_loss: 4.0315e-06 - T_accuracy: 1.0000 - R_accuracy: 0.1862 - val_loss: 1.0349 - val_T_loss: 1.0349 - val_R_loss: 4.0562e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.5385\n",
            "Epoch 31/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 5.2310e-04 - T_loss: 5.1904e-04 - R_loss: 4.0576e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2955 - val_loss: 1.0362 - val_T_loss: 1.0362 - val_R_loss: 4.2269e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.0769\n",
            "Epoch 32/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 5.0865e-04 - T_loss: 5.0459e-04 - R_loss: 4.0620e-06 - T_accuracy: 1.0000 - R_accuracy: 0.1781 - val_loss: 1.0360 - val_T_loss: 1.0360 - val_R_loss: 4.1002e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.2308\n",
            "Epoch 33/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 4.8717e-04 - T_loss: 4.8315e-04 - R_loss: 4.0237e-06 - T_accuracy: 1.0000 - R_accuracy: 0.3239 - val_loss: 1.0358 - val_T_loss: 1.0358 - val_R_loss: 4.0783e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.5385\n",
            "Epoch 34/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 4.6486e-04 - T_loss: 4.6080e-04 - R_loss: 4.0633e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2794 - val_loss: 1.0361 - val_T_loss: 1.0361 - val_R_loss: 4.1293e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.1538\n",
            "Epoch 35/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 4.5821e-04 - T_loss: 4.5417e-04 - R_loss: 4.0373e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2672 - val_loss: 1.0362 - val_T_loss: 1.0362 - val_R_loss: 4.0621e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.5385\n",
            "Epoch 36/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 4.2422e-04 - T_loss: 4.2017e-04 - R_loss: 4.0468e-06 - T_accuracy: 1.0000 - R_accuracy: 0.3117 - val_loss: 1.0365 - val_T_loss: 1.0365 - val_R_loss: 4.1754e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.2308\n",
            "Epoch 37/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 4.0712e-04 - T_loss: 4.0307e-04 - R_loss: 4.0432e-06 - T_accuracy: 1.0000 - R_accuracy: 0.1984 - val_loss: 1.0365 - val_T_loss: 1.0365 - val_R_loss: 4.0729e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.1538\n",
            "Epoch 38/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 4.1575e-04 - T_loss: 4.1170e-04 - R_loss: 4.0504e-06 - T_accuracy: 1.0000 - R_accuracy: 0.1498 - val_loss: 1.0361 - val_T_loss: 1.0361 - val_R_loss: 4.2024e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.2308\n",
            "Epoch 39/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 3.7775e-04 - T_loss: 3.7373e-04 - R_loss: 4.0255e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2713 - val_loss: 1.0363 - val_T_loss: 1.0363 - val_R_loss: 4.0374e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.1538\n",
            "Epoch 40/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 3.5480e-04 - T_loss: 3.5070e-04 - R_loss: 4.0930e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2348 - val_loss: 1.0362 - val_T_loss: 1.0361 - val_R_loss: 4.1982e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.2308\n",
            "Epoch 41/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 3.8845e-04 - T_loss: 3.8442e-04 - R_loss: 4.0330e-06 - T_accuracy: 1.0000 - R_accuracy: 0.3522 - val_loss: 1.0359 - val_T_loss: 1.0359 - val_R_loss: 4.0091e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.5385\n",
            "Epoch 42/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 3.5468e-04 - T_loss: 3.5066e-04 - R_loss: 4.0193e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2065 - val_loss: 1.0361 - val_T_loss: 1.0361 - val_R_loss: 4.2917e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.0769\n",
            "Epoch 43/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 3.4941e-04 - T_loss: 3.4536e-04 - R_loss: 4.0569e-06 - T_accuracy: 1.0000 - R_accuracy: 0.1336 - val_loss: 1.0363 - val_T_loss: 1.0363 - val_R_loss: 4.0963e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.1538\n",
            "Epoch 44/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 3.4361e-04 - T_loss: 3.3956e-04 - R_loss: 4.0481e-06 - T_accuracy: 1.0000 - R_accuracy: 0.3158 - val_loss: 1.0361 - val_T_loss: 1.0361 - val_R_loss: 4.1430e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.2308\n",
            "Epoch 45/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 3.1903e-04 - T_loss: 3.1499e-04 - R_loss: 4.0382e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2794 - val_loss: 1.0363 - val_T_loss: 1.0363 - val_R_loss: 4.0902e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.2308\n",
            "Epoch 46/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 3.1263e-04 - T_loss: 3.0861e-04 - R_loss: 4.0225e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2146 - val_loss: 1.0363 - val_T_loss: 1.0363 - val_R_loss: 4.1778e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.0769\n",
            "Epoch 47/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 3.0184e-04 - T_loss: 2.9781e-04 - R_loss: 4.0328e-06 - T_accuracy: 1.0000 - R_accuracy: 0.1943 - val_loss: 1.0359 - val_T_loss: 1.0359 - val_R_loss: 4.0436e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.4615\n",
            "Epoch 48/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 2.9468e-04 - T_loss: 2.9061e-04 - R_loss: 4.0714e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2308 - val_loss: 1.0363 - val_T_loss: 1.0363 - val_R_loss: 4.2442e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.2308\n",
            "Epoch 49/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 2.8772e-04 - T_loss: 2.8367e-04 - R_loss: 4.0513e-06 - T_accuracy: 1.0000 - R_accuracy: 0.3036 - val_loss: 1.0363 - val_T_loss: 1.0363 - val_R_loss: 3.9948e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.5385\n",
            "Epoch 50/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 2.7850e-04 - T_loss: 2.7438e-04 - R_loss: 4.1188e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2915 - val_loss: 1.0364 - val_T_loss: 1.0364 - val_R_loss: 4.3494e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.2308\n",
            "Train on 4303 samples, validate on 227 samples\n",
            "Epoch 1/50\n",
            "4303/4303 [==============================] - 37s 8ms/sample - loss: 4.5254 - T_loss: 4.5182 - R_loss: 0.0072 - T_accuracy: 0.7339 - R_accuracy: 0.2635 - val_loss: 2.1178 - val_T_loss: 2.1169 - val_R_loss: 9.2858e-04 - val_T_accuracy: 0.8150 - val_R_accuracy: 0.2467\n",
            "Epoch 2/50\n",
            "4303/4303 [==============================] - 37s 9ms/sample - loss: 1.1635 - T_loss: 1.1566 - R_loss: 0.0069 - T_accuracy: 0.8573 - R_accuracy: 0.2770 - val_loss: 1.5520 - val_T_loss: 1.5511 - val_R_loss: 8.8511e-04 - val_T_accuracy: 0.8634 - val_R_accuracy: 0.2511\n",
            "Epoch 3/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.4719 - T_loss: 0.4658 - R_loss: 0.0060 - T_accuracy: 0.9052 - R_accuracy: 0.2768 - val_loss: 1.3180 - val_T_loss: 1.3171 - val_R_loss: 9.1291e-04 - val_T_accuracy: 0.8987 - val_R_accuracy: 0.2775\n",
            "Epoch 4/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.2133 - T_loss: 0.2081 - R_loss: 0.0053 - T_accuracy: 0.9252 - R_accuracy: 0.3075 - val_loss: 0.9943 - val_T_loss: 0.9934 - val_R_loss: 8.9612e-04 - val_T_accuracy: 0.9075 - val_R_accuracy: 0.2731\n",
            "Epoch 5/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.1245 - T_loss: 0.1200 - R_loss: 0.0046 - T_accuracy: 0.9463 - R_accuracy: 0.3091 - val_loss: 0.9728 - val_T_loss: 0.9717 - val_R_loss: 0.0011 - val_T_accuracy: 0.9207 - val_R_accuracy: 0.3172\n",
            "Epoch 6/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0728 - T_loss: 0.0688 - R_loss: 0.0040 - T_accuracy: 0.9507 - R_accuracy: 0.3379 - val_loss: 0.9620 - val_T_loss: 0.9609 - val_R_loss: 0.0011 - val_T_accuracy: 0.9207 - val_R_accuracy: 0.3084\n",
            "Epoch 7/50\n",
            "4303/4303 [==============================] - 37s 8ms/sample - loss: 0.0406 - T_loss: 0.0371 - R_loss: 0.0035 - T_accuracy: 0.9626 - R_accuracy: 0.3395 - val_loss: 0.9693 - val_T_loss: 0.9685 - val_R_loss: 8.1535e-04 - val_T_accuracy: 0.9339 - val_R_accuracy: 0.3172\n",
            "Epoch 8/50\n",
            "4303/4303 [==============================] - 37s 8ms/sample - loss: 0.0253 - T_loss: 0.0222 - R_loss: 0.0030 - T_accuracy: 0.9661 - R_accuracy: 0.3395 - val_loss: 0.9077 - val_T_loss: 0.9064 - val_R_loss: 0.0013 - val_T_accuracy: 0.9295 - val_R_accuracy: 0.3084\n",
            "Epoch 9/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0190 - T_loss: 0.0165 - R_loss: 0.0025 - T_accuracy: 0.9723 - R_accuracy: 0.3479 - val_loss: 0.9521 - val_T_loss: 0.9509 - val_R_loss: 0.0011 - val_T_accuracy: 0.9207 - val_R_accuracy: 0.3304\n",
            "Epoch 10/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0185 - T_loss: 0.0164 - R_loss: 0.0021 - T_accuracy: 0.9728 - R_accuracy: 0.3491 - val_loss: 0.9361 - val_T_loss: 0.9351 - val_R_loss: 0.0010 - val_T_accuracy: 0.9163 - val_R_accuracy: 0.2996\n",
            "Epoch 11/50\n",
            "4303/4303 [==============================] - 37s 8ms/sample - loss: 0.0182 - T_loss: 0.0163 - R_loss: 0.0019 - T_accuracy: 0.9770 - R_accuracy: 0.3495 - val_loss: 0.9250 - val_T_loss: 0.9243 - val_R_loss: 7.1787e-04 - val_T_accuracy: 0.9295 - val_R_accuracy: 0.3304\n",
            "Epoch 12/50\n",
            "4303/4303 [==============================] - 37s 8ms/sample - loss: 0.0188 - T_loss: 0.0171 - R_loss: 0.0017 - T_accuracy: 0.9763 - R_accuracy: 0.3586 - val_loss: 0.9145 - val_T_loss: 0.9137 - val_R_loss: 8.2599e-04 - val_T_accuracy: 0.9207 - val_R_accuracy: 0.3436\n",
            "Epoch 13/50\n",
            "4303/4303 [==============================] - 37s 8ms/sample - loss: 0.0252 - T_loss: 0.0236 - R_loss: 0.0016 - T_accuracy: 0.9775 - R_accuracy: 0.3528 - val_loss: 0.9644 - val_T_loss: 0.9634 - val_R_loss: 9.6588e-04 - val_T_accuracy: 0.9163 - val_R_accuracy: 0.3304\n",
            "Epoch 14/50\n",
            "4303/4303 [==============================] - 37s 8ms/sample - loss: 0.0298 - T_loss: 0.0282 - R_loss: 0.0015 - T_accuracy: 0.9751 - R_accuracy: 0.3567 - val_loss: 0.9235 - val_T_loss: 0.9227 - val_R_loss: 7.9676e-04 - val_T_accuracy: 0.9295 - val_R_accuracy: 0.3392\n",
            "Epoch 15/50\n",
            "4303/4303 [==============================] - 37s 8ms/sample - loss: 0.0325 - T_loss: 0.0310 - R_loss: 0.0015 - T_accuracy: 0.9784 - R_accuracy: 0.3525 - val_loss: 0.9157 - val_T_loss: 0.9149 - val_R_loss: 8.2372e-04 - val_T_accuracy: 0.9207 - val_R_accuracy: 0.3216\n",
            "Epoch 16/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0349 - T_loss: 0.0334 - R_loss: 0.0015 - T_accuracy: 0.9733 - R_accuracy: 0.3516 - val_loss: 0.9913 - val_T_loss: 0.9905 - val_R_loss: 7.9363e-04 - val_T_accuracy: 0.9427 - val_R_accuracy: 0.3172\n",
            "Epoch 17/50\n",
            "4303/4303 [==============================] - 37s 8ms/sample - loss: 0.0391 - T_loss: 0.0376 - R_loss: 0.0015 - T_accuracy: 0.9770 - R_accuracy: 0.3611 - val_loss: 1.0012 - val_T_loss: 1.0003 - val_R_loss: 8.6903e-04 - val_T_accuracy: 0.9251 - val_R_accuracy: 0.3172\n",
            "Epoch 18/50\n",
            "4303/4303 [==============================] - 37s 8ms/sample - loss: 0.0569 - T_loss: 0.0554 - R_loss: 0.0015 - T_accuracy: 0.9647 - R_accuracy: 0.3742 - val_loss: 0.9446 - val_T_loss: 0.9440 - val_R_loss: 6.0946e-04 - val_T_accuracy: 0.9207 - val_R_accuracy: 0.3392\n",
            "Epoch 19/50\n",
            "4303/4303 [==============================] - 37s 9ms/sample - loss: 0.0705 - T_loss: 0.0690 - R_loss: 0.0015 - T_accuracy: 0.9672 - R_accuracy: 0.3549 - val_loss: 1.0042 - val_T_loss: 1.0035 - val_R_loss: 7.0992e-04 - val_T_accuracy: 0.9251 - val_R_accuracy: 0.3524\n",
            "Epoch 20/50\n",
            "4303/4303 [==============================] - 37s 8ms/sample - loss: 0.0685 - T_loss: 0.0669 - R_loss: 0.0015 - T_accuracy: 0.9668 - R_accuracy: 0.3621 - val_loss: 0.9282 - val_T_loss: 0.9273 - val_R_loss: 9.1111e-04 - val_T_accuracy: 0.9075 - val_R_accuracy: 0.3436\n",
            "Epoch 21/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0570 - T_loss: 0.0556 - R_loss: 0.0014 - T_accuracy: 0.9714 - R_accuracy: 0.3611 - val_loss: 0.8941 - val_T_loss: 0.8933 - val_R_loss: 8.1300e-04 - val_T_accuracy: 0.9295 - val_R_accuracy: 0.3128\n",
            "Epoch 22/50\n",
            "4303/4303 [==============================] - 37s 8ms/sample - loss: 0.0420 - T_loss: 0.0407 - R_loss: 0.0013 - T_accuracy: 0.9758 - R_accuracy: 0.3646 - val_loss: 0.8936 - val_T_loss: 0.8928 - val_R_loss: 8.0620e-04 - val_T_accuracy: 0.9295 - val_R_accuracy: 0.3216\n",
            "Epoch 23/50\n",
            "4303/4303 [==============================] - 37s 8ms/sample - loss: 0.0308 - T_loss: 0.0296 - R_loss: 0.0012 - T_accuracy: 0.9784 - R_accuracy: 0.3725 - val_loss: 0.8932 - val_T_loss: 0.8926 - val_R_loss: 6.0888e-04 - val_T_accuracy: 0.9251 - val_R_accuracy: 0.3436\n",
            "Epoch 24/50\n",
            "4303/4303 [==============================] - 37s 8ms/sample - loss: 0.0310 - T_loss: 0.0298 - R_loss: 0.0011 - T_accuracy: 0.9791 - R_accuracy: 0.3716 - val_loss: 0.9033 - val_T_loss: 0.9028 - val_R_loss: 5.5681e-04 - val_T_accuracy: 0.9207 - val_R_accuracy: 0.3172\n",
            "Epoch 25/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0326 - T_loss: 0.0315 - R_loss: 0.0011 - T_accuracy: 0.9779 - R_accuracy: 0.3721 - val_loss: 0.8749 - val_T_loss: 0.8741 - val_R_loss: 7.2775e-04 - val_T_accuracy: 0.9251 - val_R_accuracy: 0.3040\n",
            "Epoch 26/50\n",
            "4303/4303 [==============================] - 37s 8ms/sample - loss: 0.0341 - T_loss: 0.0331 - R_loss: 9.4171e-04 - T_accuracy: 0.9779 - R_accuracy: 0.3683 - val_loss: 0.9040 - val_T_loss: 0.9034 - val_R_loss: 5.8334e-04 - val_T_accuracy: 0.9295 - val_R_accuracy: 0.3304\n",
            "Epoch 27/50\n",
            "4303/4303 [==============================] - 37s 9ms/sample - loss: 0.0344 - T_loss: 0.0335 - R_loss: 9.3754e-04 - T_accuracy: 0.9791 - R_accuracy: 0.3756 - val_loss: 0.9300 - val_T_loss: 0.9291 - val_R_loss: 9.3311e-04 - val_T_accuracy: 0.9119 - val_R_accuracy: 0.3216\n",
            "Epoch 28/50\n",
            "4303/4303 [==============================] - 37s 9ms/sample - loss: 0.0377 - T_loss: 0.0369 - R_loss: 7.9306e-04 - T_accuracy: 0.9737 - R_accuracy: 0.3762 - val_loss: 0.9664 - val_T_loss: 0.9657 - val_R_loss: 6.1888e-04 - val_T_accuracy: 0.9295 - val_R_accuracy: 0.3172\n",
            "Epoch 29/50\n",
            "4303/4303 [==============================] - 37s 8ms/sample - loss: 0.0410 - T_loss: 0.0403 - R_loss: 6.4174e-04 - T_accuracy: 0.9770 - R_accuracy: 0.3774 - val_loss: 0.9044 - val_T_loss: 0.9034 - val_R_loss: 9.2925e-04 - val_T_accuracy: 0.9163 - val_R_accuracy: 0.3260\n",
            "Epoch 30/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0540 - T_loss: 0.0534 - R_loss: 6.5089e-04 - T_accuracy: 0.9710 - R_accuracy: 0.3751 - val_loss: 0.9336 - val_T_loss: 0.9330 - val_R_loss: 6.5048e-04 - val_T_accuracy: 0.9251 - val_R_accuracy: 0.3348\n",
            "Epoch 31/50\n",
            "4303/4303 [==============================] - 37s 8ms/sample - loss: 0.0509 - T_loss: 0.0504 - R_loss: 4.9328e-04 - T_accuracy: 0.9707 - R_accuracy: 0.3695 - val_loss: 0.9424 - val_T_loss: 0.9415 - val_R_loss: 8.8828e-04 - val_T_accuracy: 0.9207 - val_R_accuracy: 0.3084\n",
            "Epoch 32/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0526 - T_loss: 0.0522 - R_loss: 4.2151e-04 - T_accuracy: 0.9730 - R_accuracy: 0.3758 - val_loss: 0.9208 - val_T_loss: 0.9200 - val_R_loss: 7.0867e-04 - val_T_accuracy: 0.9119 - val_R_accuracy: 0.3172\n",
            "Epoch 33/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0498 - T_loss: 0.0494 - R_loss: 3.5157e-04 - T_accuracy: 0.9703 - R_accuracy: 0.3809 - val_loss: 0.9128 - val_T_loss: 0.9117 - val_R_loss: 0.0011 - val_T_accuracy: 0.9295 - val_R_accuracy: 0.3040\n",
            "Epoch 34/50\n",
            "4303/4303 [==============================] - 37s 9ms/sample - loss: 0.0544 - T_loss: 0.0540 - R_loss: 3.3351e-04 - T_accuracy: 0.9668 - R_accuracy: 0.3618 - val_loss: 0.9483 - val_T_loss: 0.9476 - val_R_loss: 7.4082e-04 - val_T_accuracy: 0.9295 - val_R_accuracy: 0.3040\n",
            "Epoch 35/50\n",
            "4303/4303 [==============================] - 37s 9ms/sample - loss: 0.0421 - T_loss: 0.0418 - R_loss: 2.9451e-04 - T_accuracy: 0.9728 - R_accuracy: 0.3783 - val_loss: 0.8873 - val_T_loss: 0.8867 - val_R_loss: 6.0112e-04 - val_T_accuracy: 0.9339 - val_R_accuracy: 0.3216\n",
            "Epoch 36/50\n",
            "4303/4303 [==============================] - 37s 9ms/sample - loss: 0.0368 - T_loss: 0.0365 - R_loss: 2.7199e-04 - T_accuracy: 0.9770 - R_accuracy: 0.3918 - val_loss: 0.9486 - val_T_loss: 0.9479 - val_R_loss: 6.5426e-04 - val_T_accuracy: 0.9427 - val_R_accuracy: 0.3172\n",
            "Epoch 37/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0392 - T_loss: 0.0389 - R_loss: 3.1851e-04 - T_accuracy: 0.9775 - R_accuracy: 0.3758 - val_loss: 0.8826 - val_T_loss: 0.8820 - val_R_loss: 6.2876e-04 - val_T_accuracy: 0.9207 - val_R_accuracy: 0.3216\n",
            "Epoch 38/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0320 - T_loss: 0.0317 - R_loss: 2.9240e-04 - T_accuracy: 0.9789 - R_accuracy: 0.3900 - val_loss: 0.9141 - val_T_loss: 0.9135 - val_R_loss: 6.2981e-04 - val_T_accuracy: 0.9339 - val_R_accuracy: 0.3480\n",
            "Epoch 39/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0313 - T_loss: 0.0311 - R_loss: 2.1326e-04 - T_accuracy: 0.9779 - R_accuracy: 0.3793 - val_loss: 0.9736 - val_T_loss: 0.9725 - val_R_loss: 0.0011 - val_T_accuracy: 0.9251 - val_R_accuracy: 0.3128\n",
            "Epoch 40/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0358 - T_loss: 0.0356 - R_loss: 2.3513e-04 - T_accuracy: 0.9765 - R_accuracy: 0.3865 - val_loss: 0.8634 - val_T_loss: 0.8629 - val_R_loss: 5.1567e-04 - val_T_accuracy: 0.9295 - val_R_accuracy: 0.3128\n",
            "Epoch 41/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0308 - T_loss: 0.0306 - R_loss: 2.1904e-04 - T_accuracy: 0.9798 - R_accuracy: 0.3830 - val_loss: 0.8851 - val_T_loss: 0.8845 - val_R_loss: 5.7461e-04 - val_T_accuracy: 0.9383 - val_R_accuracy: 0.3260\n",
            "Epoch 42/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0291 - T_loss: 0.0289 - R_loss: 1.9734e-04 - T_accuracy: 0.9756 - R_accuracy: 0.4009 - val_loss: 0.9135 - val_T_loss: 0.9127 - val_R_loss: 7.2873e-04 - val_T_accuracy: 0.9251 - val_R_accuracy: 0.3216\n",
            "Epoch 43/50\n",
            "4303/4303 [==============================] - 37s 8ms/sample - loss: 0.0278 - T_loss: 0.0276 - R_loss: 2.0146e-04 - T_accuracy: 0.9779 - R_accuracy: 0.3916 - val_loss: 0.8981 - val_T_loss: 0.8974 - val_R_loss: 7.2506e-04 - val_T_accuracy: 0.9207 - val_R_accuracy: 0.3128\n",
            "Epoch 44/50\n",
            "4303/4303 [==============================] - 37s 9ms/sample - loss: 0.0269 - T_loss: 0.0267 - R_loss: 2.3068e-04 - T_accuracy: 0.9816 - R_accuracy: 0.3793 - val_loss: 0.9174 - val_T_loss: 0.9168 - val_R_loss: 6.0051e-04 - val_T_accuracy: 0.9383 - val_R_accuracy: 0.3040\n",
            "Epoch 45/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0291 - T_loss: 0.0289 - R_loss: 2.3241e-04 - T_accuracy: 0.9789 - R_accuracy: 0.3979 - val_loss: 0.9162 - val_T_loss: 0.9157 - val_R_loss: 5.0541e-04 - val_T_accuracy: 0.9207 - val_R_accuracy: 0.3568\n",
            "Epoch 46/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0351 - T_loss: 0.0349 - R_loss: 2.2965e-04 - T_accuracy: 0.9763 - R_accuracy: 0.3832 - val_loss: 0.9053 - val_T_loss: 0.9047 - val_R_loss: 6.1201e-04 - val_T_accuracy: 0.9295 - val_R_accuracy: 0.3348\n",
            "Epoch 47/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0376 - T_loss: 0.0373 - R_loss: 2.4497e-04 - T_accuracy: 0.9756 - R_accuracy: 0.4009 - val_loss: 0.8573 - val_T_loss: 0.8566 - val_R_loss: 6.5806e-04 - val_T_accuracy: 0.9251 - val_R_accuracy: 0.3304\n",
            "Epoch 48/50\n",
            "4303/4303 [==============================] - 36s 8ms/sample - loss: 0.0385 - T_loss: 0.0383 - R_loss: 2.1053e-04 - T_accuracy: 0.9712 - R_accuracy: 0.3976 - val_loss: 0.9067 - val_T_loss: 0.9060 - val_R_loss: 6.6888e-04 - val_T_accuracy: 0.9207 - val_R_accuracy: 0.3260\n",
            "Epoch 49/50\n",
            "4303/4303 [==============================] - 37s 8ms/sample - loss: 0.0571 - T_loss: 0.0569 - R_loss: 2.5880e-04 - T_accuracy: 0.9714 - R_accuracy: 0.3911 - val_loss: 0.9042 - val_T_loss: 0.9037 - val_R_loss: 5.0994e-04 - val_T_accuracy: 0.9251 - val_R_accuracy: 0.3260\n",
            "Epoch 50/50\n",
            "4303/4303 [==============================] - 37s 8ms/sample - loss: 0.0561 - T_loss: 0.0558 - R_loss: 2.3905e-04 - T_accuracy: 0.9728 - R_accuracy: 0.3941 - val_loss: 0.8976 - val_T_loss: 0.8971 - val_R_loss: 5.7805e-04 - val_T_accuracy: 0.9207 - val_R_accuracy: 0.3216\n",
            "Train on 1035 samples, validate on 55 samples\n",
            "Epoch 1/50\n",
            "1035/1035 [==============================] - 9s 9ms/sample - loss: 32.1206 - T_loss: 32.1152 - R_loss: 0.0054 - T_accuracy: 0.8493 - R_accuracy: 0.2609 - val_loss: 20.2855 - val_T_loss: 20.2850 - val_R_loss: 5.0826e-04 - val_T_accuracy: 0.8727 - val_R_accuracy: 0.2727\n",
            "Epoch 2/50\n",
            "1035/1035 [==============================] - 9s 9ms/sample - loss: 11.4922 - T_loss: 11.4871 - R_loss: 0.0051 - T_accuracy: 0.9536 - R_accuracy: 0.2937 - val_loss: 7.4334 - val_T_loss: 7.4323 - val_R_loss: 0.0011 - val_T_accuracy: 0.9818 - val_R_accuracy: 0.3636\n",
            "Epoch 3/50\n",
            "1035/1035 [==============================] - 9s 9ms/sample - loss: 6.2113 - T_loss: 6.2062 - R_loss: 0.0051 - T_accuracy: 0.9662 - R_accuracy: 0.2841 - val_loss: 5.1293 - val_T_loss: 5.1291 - val_R_loss: 2.0501e-04 - val_T_accuracy: 0.9818 - val_R_accuracy: 0.3455\n",
            "Epoch 4/50\n",
            "1035/1035 [==============================] - 9s 9ms/sample - loss: 3.1550 - T_loss: 3.1500 - R_loss: 0.0050 - T_accuracy: 0.9749 - R_accuracy: 0.3382 - val_loss: 4.8507 - val_T_loss: 4.8504 - val_R_loss: 2.3250e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.3273\n",
            "Epoch 5/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 1.8947 - T_loss: 1.8898 - R_loss: 0.0049 - T_accuracy: 0.9855 - R_accuracy: 0.2986 - val_loss: 3.2171 - val_T_loss: 3.2168 - val_R_loss: 2.2454e-04 - val_T_accuracy: 0.9818 - val_R_accuracy: 0.3818\n",
            "Epoch 6/50\n",
            "1035/1035 [==============================] - 9s 9ms/sample - loss: 1.1238 - T_loss: 1.1188 - R_loss: 0.0049 - T_accuracy: 0.9826 - R_accuracy: 0.2908 - val_loss: 4.7975 - val_T_loss: 4.7974 - val_R_loss: 1.5291e-04 - val_T_accuracy: 0.9818 - val_R_accuracy: 0.3818\n",
            "Epoch 7/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.7143 - T_loss: 0.7094 - R_loss: 0.0049 - T_accuracy: 0.9903 - R_accuracy: 0.3700 - val_loss: 3.4051 - val_T_loss: 3.4048 - val_R_loss: 2.4209e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.4364\n",
            "Epoch 8/50\n",
            "1035/1035 [==============================] - 9s 9ms/sample - loss: 0.4628 - T_loss: 0.4578 - R_loss: 0.0049 - T_accuracy: 0.9903 - R_accuracy: 0.3459 - val_loss: 3.6648 - val_T_loss: 3.6646 - val_R_loss: 2.0935e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.4182\n",
            "Epoch 9/50\n",
            "1035/1035 [==============================] - 9s 9ms/sample - loss: 0.2532 - T_loss: 0.2483 - R_loss: 0.0049 - T_accuracy: 0.9913 - R_accuracy: 0.3063 - val_loss: 3.4817 - val_T_loss: 3.4816 - val_R_loss: 1.5791e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.3818\n",
            "Epoch 10/50\n",
            "1035/1035 [==============================] - 9s 9ms/sample - loss: 0.1395 - T_loss: 0.1347 - R_loss: 0.0049 - T_accuracy: 0.9981 - R_accuracy: 0.3952 - val_loss: 3.5288 - val_T_loss: 3.5286 - val_R_loss: 1.5594e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.3636\n",
            "Epoch 11/50\n",
            "1035/1035 [==============================] - 9s 9ms/sample - loss: 0.1179 - T_loss: 0.1131 - R_loss: 0.0048 - T_accuracy: 0.9942 - R_accuracy: 0.4271 - val_loss: 3.3747 - val_T_loss: 3.3745 - val_R_loss: 1.6968e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.4182\n",
            "Epoch 12/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0901 - T_loss: 0.0854 - R_loss: 0.0048 - T_accuracy: 0.9971 - R_accuracy: 0.3836 - val_loss: 3.2437 - val_T_loss: 3.2435 - val_R_loss: 2.1178e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.4000\n",
            "Epoch 13/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0535 - T_loss: 0.0488 - R_loss: 0.0047 - T_accuracy: 0.9961 - R_accuracy: 0.3507 - val_loss: 3.2109 - val_T_loss: 3.2107 - val_R_loss: 2.0021e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.3818\n",
            "Epoch 14/50\n",
            "1035/1035 [==============================] - 9s 9ms/sample - loss: 0.0442 - T_loss: 0.0395 - R_loss: 0.0047 - T_accuracy: 0.9981 - R_accuracy: 0.3556 - val_loss: 3.3629 - val_T_loss: 3.3627 - val_R_loss: 2.8717e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.3455\n",
            "Epoch 15/50\n",
            "1035/1035 [==============================] - 9s 9ms/sample - loss: 0.0336 - T_loss: 0.0290 - R_loss: 0.0046 - T_accuracy: 0.9981 - R_accuracy: 0.3372 - val_loss: 3.3298 - val_T_loss: 3.3295 - val_R_loss: 2.6796e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.3636\n",
            "Epoch 16/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0316 - T_loss: 0.0271 - R_loss: 0.0046 - T_accuracy: 0.9990 - R_accuracy: 0.3546 - val_loss: 3.2543 - val_T_loss: 3.2541 - val_R_loss: 2.2608e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.4000\n",
            "Epoch 17/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0265 - T_loss: 0.0219 - R_loss: 0.0045 - T_accuracy: 0.9981 - R_accuracy: 0.3536 - val_loss: 3.3448 - val_T_loss: 3.3446 - val_R_loss: 2.5288e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.4182\n",
            "Epoch 18/50\n",
            "1035/1035 [==============================] - 9s 9ms/sample - loss: 0.0250 - T_loss: 0.0205 - R_loss: 0.0045 - T_accuracy: 0.9981 - R_accuracy: 0.3739 - val_loss: 3.2166 - val_T_loss: 3.2164 - val_R_loss: 2.1716e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.4182\n",
            "Epoch 19/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0240 - T_loss: 0.0196 - R_loss: 0.0045 - T_accuracy: 1.0000 - R_accuracy: 0.3575 - val_loss: 3.2781 - val_T_loss: 3.2778 - val_R_loss: 2.3363e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.5091\n",
            "Epoch 20/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0234 - T_loss: 0.0189 - R_loss: 0.0044 - T_accuracy: 1.0000 - R_accuracy: 0.3594 - val_loss: 3.1904 - val_T_loss: 3.1901 - val_R_loss: 3.0777e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.3818\n",
            "Epoch 21/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0187 - T_loss: 0.0143 - R_loss: 0.0044 - T_accuracy: 0.9981 - R_accuracy: 0.3362 - val_loss: 3.2915 - val_T_loss: 3.2911 - val_R_loss: 3.0712e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.4727\n",
            "Epoch 22/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0156 - T_loss: 0.0112 - R_loss: 0.0044 - T_accuracy: 1.0000 - R_accuracy: 0.3362 - val_loss: 3.2321 - val_T_loss: 3.2319 - val_R_loss: 2.6461e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.4000\n",
            "Epoch 23/50\n",
            "1035/1035 [==============================] - 9s 9ms/sample - loss: 0.0149 - T_loss: 0.0105 - R_loss: 0.0044 - T_accuracy: 0.9971 - R_accuracy: 0.3362 - val_loss: 3.2632 - val_T_loss: 3.2628 - val_R_loss: 3.7435e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.3455\n",
            "Epoch 24/50\n",
            "1035/1035 [==============================] - 9s 9ms/sample - loss: 0.0141 - T_loss: 0.0098 - R_loss: 0.0043 - T_accuracy: 0.9981 - R_accuracy: 0.3498 - val_loss: 3.3415 - val_T_loss: 3.3411 - val_R_loss: 3.3585e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.3818\n",
            "Epoch 25/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0138 - T_loss: 0.0095 - R_loss: 0.0043 - T_accuracy: 1.0000 - R_accuracy: 0.3343 - val_loss: 3.2525 - val_T_loss: 3.2522 - val_R_loss: 3.7376e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.4000\n",
            "Epoch 26/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0141 - T_loss: 0.0098 - R_loss: 0.0043 - T_accuracy: 0.9990 - R_accuracy: 0.3604 - val_loss: 3.2584 - val_T_loss: 3.2581 - val_R_loss: 3.0142e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.4182\n",
            "Epoch 27/50\n",
            "1035/1035 [==============================] - 9s 9ms/sample - loss: 0.0164 - T_loss: 0.0121 - R_loss: 0.0043 - T_accuracy: 0.9990 - R_accuracy: 0.3391 - val_loss: 3.2324 - val_T_loss: 3.2320 - val_R_loss: 4.5469e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.4182\n",
            "Epoch 28/50\n",
            "1035/1035 [==============================] - 9s 9ms/sample - loss: 0.0173 - T_loss: 0.0130 - R_loss: 0.0042 - T_accuracy: 0.9981 - R_accuracy: 0.3401 - val_loss: 3.1836 - val_T_loss: 3.1833 - val_R_loss: 3.6000e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.4364\n",
            "Epoch 29/50\n",
            "1035/1035 [==============================] - 9s 9ms/sample - loss: 0.0223 - T_loss: 0.0180 - R_loss: 0.0042 - T_accuracy: 1.0000 - R_accuracy: 0.3469 - val_loss: 3.2514 - val_T_loss: 3.2510 - val_R_loss: 4.0818e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.3455\n",
            "Epoch 30/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0230 - T_loss: 0.0187 - R_loss: 0.0043 - T_accuracy: 0.9990 - R_accuracy: 0.3401 - val_loss: 3.3514 - val_T_loss: 3.3510 - val_R_loss: 4.4498e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.4000\n",
            "Epoch 31/50\n",
            "1035/1035 [==============================] - 9s 9ms/sample - loss: 0.0240 - T_loss: 0.0198 - R_loss: 0.0042 - T_accuracy: 0.9990 - R_accuracy: 0.3440 - val_loss: 3.2808 - val_T_loss: 3.2804 - val_R_loss: 4.1324e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.3455\n",
            "Epoch 32/50\n",
            "1035/1035 [==============================] - 9s 9ms/sample - loss: 0.0288 - T_loss: 0.0247 - R_loss: 0.0041 - T_accuracy: 1.0000 - R_accuracy: 0.3527 - val_loss: 3.1847 - val_T_loss: 3.1842 - val_R_loss: 4.5747e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.3455\n",
            "Epoch 33/50\n",
            "1035/1035 [==============================] - 9s 9ms/sample - loss: 0.0370 - T_loss: 0.0329 - R_loss: 0.0041 - T_accuracy: 0.9990 - R_accuracy: 0.3604 - val_loss: 3.2186 - val_T_loss: 3.2181 - val_R_loss: 4.6591e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.4000\n",
            "Epoch 34/50\n",
            "1035/1035 [==============================] - 9s 9ms/sample - loss: 0.0494 - T_loss: 0.0453 - R_loss: 0.0041 - T_accuracy: 0.9990 - R_accuracy: 0.3643 - val_loss: 3.2132 - val_T_loss: 3.2127 - val_R_loss: 4.1912e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.3636\n",
            "Epoch 35/50\n",
            "1035/1035 [==============================] - 9s 9ms/sample - loss: 0.0668 - T_loss: 0.0627 - R_loss: 0.0041 - T_accuracy: 0.9990 - R_accuracy: 0.3449 - val_loss: 3.1668 - val_T_loss: 3.1664 - val_R_loss: 4.2511e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.3636\n",
            "Epoch 36/50\n",
            "1035/1035 [==============================] - 9s 9ms/sample - loss: 0.0682 - T_loss: 0.0641 - R_loss: 0.0040 - T_accuracy: 0.9981 - R_accuracy: 0.3556 - val_loss: 3.3175 - val_T_loss: 3.3169 - val_R_loss: 5.3778e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.3455\n",
            "Epoch 37/50\n",
            "1035/1035 [==============================] - 9s 9ms/sample - loss: 0.0655 - T_loss: 0.0614 - R_loss: 0.0040 - T_accuracy: 0.9961 - R_accuracy: 0.3807 - val_loss: 3.2970 - val_T_loss: 3.2965 - val_R_loss: 5.5639e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.3636\n",
            "Epoch 38/50\n",
            "1035/1035 [==============================] - 9s 9ms/sample - loss: 0.0496 - T_loss: 0.0456 - R_loss: 0.0040 - T_accuracy: 1.0000 - R_accuracy: 0.3662 - val_loss: 3.1289 - val_T_loss: 3.1284 - val_R_loss: 4.8360e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.3636\n",
            "Epoch 39/50\n",
            "1035/1035 [==============================] - 9s 9ms/sample - loss: 0.0447 - T_loss: 0.0408 - R_loss: 0.0040 - T_accuracy: 0.9971 - R_accuracy: 0.3517 - val_loss: 3.2377 - val_T_loss: 3.2373 - val_R_loss: 4.4243e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.4909\n",
            "Epoch 40/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0433 - T_loss: 0.0393 - R_loss: 0.0039 - T_accuracy: 0.9990 - R_accuracy: 0.3720 - val_loss: 3.2130 - val_T_loss: 3.2125 - val_R_loss: 4.9664e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.3636\n",
            "Epoch 41/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0490 - T_loss: 0.0451 - R_loss: 0.0040 - T_accuracy: 0.9961 - R_accuracy: 0.3691 - val_loss: 3.1691 - val_T_loss: 3.1685 - val_R_loss: 5.6865e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.4727\n",
            "Epoch 42/50\n",
            "1035/1035 [==============================] - 9s 9ms/sample - loss: 0.0436 - T_loss: 0.0397 - R_loss: 0.0039 - T_accuracy: 0.9981 - R_accuracy: 0.3942 - val_loss: 3.3874 - val_T_loss: 3.3869 - val_R_loss: 4.7883e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.3091\n",
            "Epoch 43/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0452 - T_loss: 0.0413 - R_loss: 0.0039 - T_accuracy: 0.9981 - R_accuracy: 0.3227 - val_loss: 3.1720 - val_T_loss: 3.1715 - val_R_loss: 5.5228e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.4000\n",
            "Epoch 44/50\n",
            "1035/1035 [==============================] - 9s 9ms/sample - loss: 0.0377 - T_loss: 0.0339 - R_loss: 0.0039 - T_accuracy: 0.9981 - R_accuracy: 0.3430 - val_loss: 3.2996 - val_T_loss: 3.2990 - val_R_loss: 6.3648e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.3636\n",
            "Epoch 45/50\n",
            "1035/1035 [==============================] - 9s 9ms/sample - loss: 0.0358 - T_loss: 0.0320 - R_loss: 0.0038 - T_accuracy: 0.9971 - R_accuracy: 0.3768 - val_loss: 3.2762 - val_T_loss: 3.2756 - val_R_loss: 5.9948e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.4364\n",
            "Epoch 46/50\n",
            "1035/1035 [==============================] - 9s 9ms/sample - loss: 0.0490 - T_loss: 0.0452 - R_loss: 0.0038 - T_accuracy: 0.9990 - R_accuracy: 0.3556 - val_loss: 3.3203 - val_T_loss: 3.3198 - val_R_loss: 5.1554e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.3636\n",
            "Epoch 47/50\n",
            "1035/1035 [==============================] - 9s 9ms/sample - loss: 0.0578 - T_loss: 0.0541 - R_loss: 0.0038 - T_accuracy: 0.9961 - R_accuracy: 0.3720 - val_loss: 3.1819 - val_T_loss: 3.1813 - val_R_loss: 6.6204e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.2909\n",
            "Epoch 48/50\n",
            "1035/1035 [==============================] - 9s 8ms/sample - loss: 0.0672 - T_loss: 0.0634 - R_loss: 0.0038 - T_accuracy: 0.9971 - R_accuracy: 0.3517 - val_loss: 3.1302 - val_T_loss: 3.1296 - val_R_loss: 6.2355e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.4545\n",
            "Epoch 49/50\n",
            "1035/1035 [==============================] - 9s 9ms/sample - loss: 0.0831 - T_loss: 0.0793 - R_loss: 0.0038 - T_accuracy: 0.9971 - R_accuracy: 0.3585 - val_loss: 3.0926 - val_T_loss: 3.0920 - val_R_loss: 6.3529e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.4545\n",
            "Epoch 50/50\n",
            "1035/1035 [==============================] - 9s 9ms/sample - loss: 0.0921 - T_loss: 0.0884 - R_loss: 0.0037 - T_accuracy: 0.9971 - R_accuracy: 0.3923 - val_loss: 3.2813 - val_T_loss: 3.2805 - val_R_loss: 7.5543e-04 - val_T_accuracy: 0.9636 - val_R_accuracy: 0.3818\n",
            "Train on 4417 samples, validate on 233 samples\n",
            "Epoch 1/50\n",
            "4417/4417 [==============================] - 38s 8ms/sample - loss: 5.7153 - T_loss: 5.7098 - R_loss: 0.0055 - T_accuracy: 0.8012 - R_accuracy: 0.2719 - val_loss: 2.6295 - val_T_loss: 2.6195 - val_R_loss: 0.0100 - val_T_accuracy: 0.8326 - val_R_accuracy: 0.3562\n",
            "Epoch 2/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.8114 - T_loss: 0.8066 - R_loss: 0.0048 - T_accuracy: 0.9439 - R_accuracy: 0.3326 - val_loss: 1.7870 - val_T_loss: 1.7780 - val_R_loss: 0.0090 - val_T_accuracy: 0.9356 - val_R_accuracy: 0.3991\n",
            "Epoch 3/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.2550 - T_loss: 0.2507 - R_loss: 0.0043 - T_accuracy: 0.9647 - R_accuracy: 0.3550 - val_loss: 1.7330 - val_T_loss: 1.7246 - val_R_loss: 0.0084 - val_T_accuracy: 0.9270 - val_R_accuracy: 0.4077\n",
            "Epoch 4/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.1186 - T_loss: 0.1146 - R_loss: 0.0040 - T_accuracy: 0.9731 - R_accuracy: 0.3928 - val_loss: 1.7021 - val_T_loss: 1.6940 - val_R_loss: 0.0080 - val_T_accuracy: 0.9270 - val_R_accuracy: 0.3648\n",
            "Epoch 5/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0618 - T_loss: 0.0582 - R_loss: 0.0036 - T_accuracy: 0.9830 - R_accuracy: 0.3869 - val_loss: 1.7382 - val_T_loss: 1.7295 - val_R_loss: 0.0087 - val_T_accuracy: 0.9442 - val_R_accuracy: 0.4292\n",
            "Epoch 6/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0377 - T_loss: 0.0344 - R_loss: 0.0033 - T_accuracy: 0.9862 - R_accuracy: 0.4066 - val_loss: 1.6792 - val_T_loss: 1.6724 - val_R_loss: 0.0068 - val_T_accuracy: 0.9399 - val_R_accuracy: 0.3863\n",
            "Epoch 7/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0307 - T_loss: 0.0282 - R_loss: 0.0026 - T_accuracy: 0.9889 - R_accuracy: 0.4062 - val_loss: 1.6852 - val_T_loss: 1.6796 - val_R_loss: 0.0056 - val_T_accuracy: 0.9399 - val_R_accuracy: 0.3433\n",
            "Epoch 8/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0242 - T_loss: 0.0225 - R_loss: 0.0017 - T_accuracy: 0.9900 - R_accuracy: 0.4191 - val_loss: 1.7109 - val_T_loss: 1.7071 - val_R_loss: 0.0038 - val_T_accuracy: 0.9356 - val_R_accuracy: 0.3906\n",
            "Epoch 9/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0281 - T_loss: 0.0270 - R_loss: 0.0011 - T_accuracy: 0.9894 - R_accuracy: 0.4107 - val_loss: 1.6320 - val_T_loss: 1.6290 - val_R_loss: 0.0030 - val_T_accuracy: 0.9356 - val_R_accuracy: 0.3734\n",
            "Epoch 10/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0271 - T_loss: 0.0265 - R_loss: 6.6517e-04 - T_accuracy: 0.9914 - R_accuracy: 0.4141 - val_loss: 1.6887 - val_T_loss: 1.6863 - val_R_loss: 0.0024 - val_T_accuracy: 0.9356 - val_R_accuracy: 0.3648\n",
            "Epoch 11/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0283 - T_loss: 0.0278 - R_loss: 4.7591e-04 - T_accuracy: 0.9896 - R_accuracy: 0.4320 - val_loss: 1.6918 - val_T_loss: 1.6895 - val_R_loss: 0.0023 - val_T_accuracy: 0.9313 - val_R_accuracy: 0.3906\n",
            "Epoch 12/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0262 - T_loss: 0.0259 - R_loss: 3.7760e-04 - T_accuracy: 0.9925 - R_accuracy: 0.4331 - val_loss: 1.6560 - val_T_loss: 1.6537 - val_R_loss: 0.0023 - val_T_accuracy: 0.9356 - val_R_accuracy: 0.3906\n",
            "Epoch 13/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0270 - T_loss: 0.0267 - R_loss: 3.1556e-04 - T_accuracy: 0.9928 - R_accuracy: 0.4501 - val_loss: 1.6918 - val_T_loss: 1.6898 - val_R_loss: 0.0020 - val_T_accuracy: 0.9313 - val_R_accuracy: 0.3948\n",
            "Epoch 14/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0293 - T_loss: 0.0290 - R_loss: 2.5593e-04 - T_accuracy: 0.9914 - R_accuracy: 0.4528 - val_loss: 1.6957 - val_T_loss: 1.6937 - val_R_loss: 0.0019 - val_T_accuracy: 0.9313 - val_R_accuracy: 0.3906\n",
            "Epoch 15/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0531 - T_loss: 0.0529 - R_loss: 2.6694e-04 - T_accuracy: 0.9912 - R_accuracy: 0.4467 - val_loss: 1.7275 - val_T_loss: 1.7258 - val_R_loss: 0.0016 - val_T_accuracy: 0.9185 - val_R_accuracy: 0.3948\n",
            "Epoch 16/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0826 - T_loss: 0.0823 - R_loss: 2.5027e-04 - T_accuracy: 0.9903 - R_accuracy: 0.4483 - val_loss: 1.6084 - val_T_loss: 1.6066 - val_R_loss: 0.0018 - val_T_accuracy: 0.9270 - val_R_accuracy: 0.4077\n",
            "Epoch 17/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0906 - T_loss: 0.0903 - R_loss: 2.4905e-04 - T_accuracy: 0.9878 - R_accuracy: 0.4453 - val_loss: 1.6464 - val_T_loss: 1.6443 - val_R_loss: 0.0021 - val_T_accuracy: 0.9270 - val_R_accuracy: 0.4077\n",
            "Epoch 18/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0734 - T_loss: 0.0731 - R_loss: 2.5358e-04 - T_accuracy: 0.9864 - R_accuracy: 0.4596 - val_loss: 1.6139 - val_T_loss: 1.6122 - val_R_loss: 0.0017 - val_T_accuracy: 0.9356 - val_R_accuracy: 0.3991\n",
            "Epoch 19/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0565 - T_loss: 0.0563 - R_loss: 2.1066e-04 - T_accuracy: 0.9882 - R_accuracy: 0.4569 - val_loss: 1.6449 - val_T_loss: 1.6432 - val_R_loss: 0.0017 - val_T_accuracy: 0.9270 - val_R_accuracy: 0.4464\n",
            "Epoch 20/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0452 - T_loss: 0.0450 - R_loss: 2.1122e-04 - T_accuracy: 0.9912 - R_accuracy: 0.4616 - val_loss: 1.6162 - val_T_loss: 1.6142 - val_R_loss: 0.0020 - val_T_accuracy: 0.9270 - val_R_accuracy: 0.4464\n",
            "Epoch 21/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0393 - T_loss: 0.0391 - R_loss: 1.8045e-04 - T_accuracy: 0.9905 - R_accuracy: 0.4542 - val_loss: 1.6961 - val_T_loss: 1.6942 - val_R_loss: 0.0018 - val_T_accuracy: 0.9270 - val_R_accuracy: 0.4163\n",
            "Epoch 22/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0372 - T_loss: 0.0370 - R_loss: 1.7383e-04 - T_accuracy: 0.9925 - R_accuracy: 0.4695 - val_loss: 1.6649 - val_T_loss: 1.6630 - val_R_loss: 0.0020 - val_T_accuracy: 0.9313 - val_R_accuracy: 0.4506\n",
            "Epoch 23/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0365 - T_loss: 0.0363 - R_loss: 1.7893e-04 - T_accuracy: 0.9925 - R_accuracy: 0.4752 - val_loss: 1.6778 - val_T_loss: 1.6762 - val_R_loss: 0.0017 - val_T_accuracy: 0.9313 - val_R_accuracy: 0.4163\n",
            "Epoch 24/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0391 - T_loss: 0.0389 - R_loss: 1.9214e-04 - T_accuracy: 0.9907 - R_accuracy: 0.4743 - val_loss: 1.6351 - val_T_loss: 1.6334 - val_R_loss: 0.0017 - val_T_accuracy: 0.9442 - val_R_accuracy: 0.3820\n",
            "Epoch 25/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0398 - T_loss: 0.0397 - R_loss: 1.6225e-04 - T_accuracy: 0.9914 - R_accuracy: 0.4666 - val_loss: 1.6681 - val_T_loss: 1.6660 - val_R_loss: 0.0020 - val_T_accuracy: 0.9356 - val_R_accuracy: 0.4077\n",
            "Epoch 26/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0414 - T_loss: 0.0412 - R_loss: 1.5555e-04 - T_accuracy: 0.9925 - R_accuracy: 0.4691 - val_loss: 1.6490 - val_T_loss: 1.6470 - val_R_loss: 0.0020 - val_T_accuracy: 0.9313 - val_R_accuracy: 0.4979\n",
            "Epoch 27/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0533 - T_loss: 0.0531 - R_loss: 1.5527e-04 - T_accuracy: 0.9916 - R_accuracy: 0.4752 - val_loss: 1.6103 - val_T_loss: 1.6085 - val_R_loss: 0.0018 - val_T_accuracy: 0.9227 - val_R_accuracy: 0.4506\n",
            "Epoch 28/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0663 - T_loss: 0.0661 - R_loss: 1.8373e-04 - T_accuracy: 0.9909 - R_accuracy: 0.4677 - val_loss: 1.6771 - val_T_loss: 1.6753 - val_R_loss: 0.0018 - val_T_accuracy: 0.9313 - val_R_accuracy: 0.4378\n",
            "Epoch 29/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0731 - T_loss: 0.0728 - R_loss: 2.5072e-04 - T_accuracy: 0.9887 - R_accuracy: 0.4759 - val_loss: 1.5943 - val_T_loss: 1.5924 - val_R_loss: 0.0019 - val_T_accuracy: 0.9313 - val_R_accuracy: 0.4721\n",
            "Epoch 30/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0690 - T_loss: 0.0688 - R_loss: 1.8118e-04 - T_accuracy: 0.9866 - R_accuracy: 0.4666 - val_loss: 1.7137 - val_T_loss: 1.7120 - val_R_loss: 0.0017 - val_T_accuracy: 0.9313 - val_R_accuracy: 0.4421\n",
            "Epoch 31/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0687 - T_loss: 0.0685 - R_loss: 1.6832e-04 - T_accuracy: 0.9896 - R_accuracy: 0.4748 - val_loss: 1.6407 - val_T_loss: 1.6380 - val_R_loss: 0.0027 - val_T_accuracy: 0.9227 - val_R_accuracy: 0.4206\n",
            "Epoch 32/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0649 - T_loss: 0.0647 - R_loss: 1.9028e-04 - T_accuracy: 0.9866 - R_accuracy: 0.4709 - val_loss: 1.5916 - val_T_loss: 1.5895 - val_R_loss: 0.0021 - val_T_accuracy: 0.9356 - val_R_accuracy: 0.4678\n",
            "Epoch 33/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0753 - T_loss: 0.0751 - R_loss: 1.9010e-04 - T_accuracy: 0.9894 - R_accuracy: 0.4827 - val_loss: 1.6248 - val_T_loss: 1.6222 - val_R_loss: 0.0025 - val_T_accuracy: 0.9270 - val_R_accuracy: 0.4249\n",
            "Epoch 34/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0613 - T_loss: 0.0612 - R_loss: 1.5199e-04 - T_accuracy: 0.9880 - R_accuracy: 0.4714 - val_loss: 1.6125 - val_T_loss: 1.6103 - val_R_loss: 0.0021 - val_T_accuracy: 0.9270 - val_R_accuracy: 0.4421\n",
            "Epoch 35/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0639 - T_loss: 0.0637 - R_loss: 1.5321e-04 - T_accuracy: 0.9905 - R_accuracy: 0.4806 - val_loss: 1.5937 - val_T_loss: 1.5910 - val_R_loss: 0.0027 - val_T_accuracy: 0.9313 - val_R_accuracy: 0.4721\n",
            "Epoch 36/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0489 - T_loss: 0.0488 - R_loss: 1.6077e-04 - T_accuracy: 0.9921 - R_accuracy: 0.4845 - val_loss: 1.6886 - val_T_loss: 1.6863 - val_R_loss: 0.0024 - val_T_accuracy: 0.9356 - val_R_accuracy: 0.4678\n",
            "Epoch 37/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0471 - T_loss: 0.0469 - R_loss: 1.5077e-04 - T_accuracy: 0.9914 - R_accuracy: 0.4892 - val_loss: 1.6124 - val_T_loss: 1.6101 - val_R_loss: 0.0024 - val_T_accuracy: 0.9270 - val_R_accuracy: 0.4549\n",
            "Epoch 38/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0441 - T_loss: 0.0440 - R_loss: 1.5913e-04 - T_accuracy: 0.9921 - R_accuracy: 0.4967 - val_loss: 1.6214 - val_T_loss: 1.6191 - val_R_loss: 0.0024 - val_T_accuracy: 0.9270 - val_R_accuracy: 0.4721\n",
            "Epoch 39/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0415 - T_loss: 0.0414 - R_loss: 1.2792e-04 - T_accuracy: 0.9923 - R_accuracy: 0.5001 - val_loss: 1.5297 - val_T_loss: 1.5276 - val_R_loss: 0.0021 - val_T_accuracy: 0.9227 - val_R_accuracy: 0.4206\n",
            "Epoch 40/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0419 - T_loss: 0.0417 - R_loss: 1.3996e-04 - T_accuracy: 0.9921 - R_accuracy: 0.4954 - val_loss: 1.5940 - val_T_loss: 1.5922 - val_R_loss: 0.0019 - val_T_accuracy: 0.9270 - val_R_accuracy: 0.4206\n",
            "Epoch 41/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0439 - T_loss: 0.0438 - R_loss: 1.2931e-04 - T_accuracy: 0.9914 - R_accuracy: 0.5076 - val_loss: 1.6039 - val_T_loss: 1.6019 - val_R_loss: 0.0020 - val_T_accuracy: 0.9270 - val_R_accuracy: 0.5064\n",
            "Epoch 42/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0411 - T_loss: 0.0410 - R_loss: 1.2535e-04 - T_accuracy: 0.9914 - R_accuracy: 0.5024 - val_loss: 1.6447 - val_T_loss: 1.6422 - val_R_loss: 0.0025 - val_T_accuracy: 0.9313 - val_R_accuracy: 0.4464\n",
            "Epoch 43/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0447 - T_loss: 0.0446 - R_loss: 1.2150e-04 - T_accuracy: 0.9921 - R_accuracy: 0.4974 - val_loss: 1.5647 - val_T_loss: 1.5625 - val_R_loss: 0.0022 - val_T_accuracy: 0.9313 - val_R_accuracy: 0.4549\n",
            "Epoch 44/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0490 - T_loss: 0.0489 - R_loss: 1.2041e-04 - T_accuracy: 0.9900 - R_accuracy: 0.5074 - val_loss: 1.5515 - val_T_loss: 1.5494 - val_R_loss: 0.0021 - val_T_accuracy: 0.9313 - val_R_accuracy: 0.4506\n",
            "Epoch 45/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0423 - T_loss: 0.0422 - R_loss: 1.3172e-04 - T_accuracy: 0.9905 - R_accuracy: 0.4988 - val_loss: 1.6014 - val_T_loss: 1.5988 - val_R_loss: 0.0026 - val_T_accuracy: 0.9313 - val_R_accuracy: 0.4635\n",
            "Epoch 46/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0463 - T_loss: 0.0461 - R_loss: 1.5838e-04 - T_accuracy: 0.9914 - R_accuracy: 0.5042 - val_loss: 1.5572 - val_T_loss: 1.5553 - val_R_loss: 0.0019 - val_T_accuracy: 0.9356 - val_R_accuracy: 0.4421\n",
            "Epoch 47/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0466 - T_loss: 0.0465 - R_loss: 1.5948e-04 - T_accuracy: 0.9905 - R_accuracy: 0.5022 - val_loss: 1.4941 - val_T_loss: 1.4923 - val_R_loss: 0.0018 - val_T_accuracy: 0.9356 - val_R_accuracy: 0.5064\n",
            "Epoch 48/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0700 - T_loss: 0.0699 - R_loss: 1.4751e-04 - T_accuracy: 0.9907 - R_accuracy: 0.5083 - val_loss: 1.5130 - val_T_loss: 1.5106 - val_R_loss: 0.0023 - val_T_accuracy: 0.9313 - val_R_accuracy: 0.4936\n",
            "Epoch 49/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0632 - T_loss: 0.0630 - R_loss: 1.3734e-04 - T_accuracy: 0.9871 - R_accuracy: 0.5071 - val_loss: 1.5446 - val_T_loss: 1.5428 - val_R_loss: 0.0018 - val_T_accuracy: 0.9270 - val_R_accuracy: 0.4378\n",
            "Epoch 50/50\n",
            "4417/4417 [==============================] - 38s 9ms/sample - loss: 0.0527 - T_loss: 0.0526 - R_loss: 1.7569e-04 - T_accuracy: 0.9903 - R_accuracy: 0.5051 - val_loss: 1.5518 - val_T_loss: 1.5502 - val_R_loss: 0.0016 - val_T_accuracy: 0.9485 - val_R_accuracy: 0.4506\n",
            "Train on 750 samples, validate on 40 samples\n",
            "Epoch 1/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 1.0283 - T_loss: 1.0279 - R_loss: 3.7634e-04 - T_accuracy: 0.9200 - R_accuracy: 0.3827 - val_loss: 0.5593 - val_T_loss: 0.5590 - val_R_loss: 3.0333e-04 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.2750\n",
            "Epoch 2/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 0.2682 - T_loss: 0.2680 - R_loss: 1.8813e-04 - T_accuracy: 0.9667 - R_accuracy: 0.4547 - val_loss: 0.4538 - val_T_loss: 0.4537 - val_R_loss: 1.1070e-04 - val_T_accuracy: 0.9750 - val_R_accuracy: 0.5250\n",
            "Epoch 3/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 0.1582 - T_loss: 0.1580 - R_loss: 1.2961e-04 - T_accuracy: 0.9760 - R_accuracy: 0.5280 - val_loss: 0.2988 - val_T_loss: 0.2988 - val_R_loss: 5.2006e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.5000\n",
            "Epoch 4/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 0.0650 - T_loss: 0.0649 - R_loss: 9.6948e-05 - T_accuracy: 0.9693 - R_accuracy: 0.5453 - val_loss: 0.3550 - val_T_loss: 0.3550 - val_R_loss: 5.7097e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.4250\n",
            "Epoch 5/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 0.0328 - T_loss: 0.0328 - R_loss: 7.8243e-05 - T_accuracy: 0.9867 - R_accuracy: 0.5653 - val_loss: 0.3194 - val_T_loss: 0.3194 - val_R_loss: 4.6351e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.4250\n",
            "Epoch 6/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 0.0180 - T_loss: 0.0179 - R_loss: 6.6787e-05 - T_accuracy: 0.9880 - R_accuracy: 0.5827 - val_loss: 0.3252 - val_T_loss: 0.3251 - val_R_loss: 4.2304e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.4750\n",
            "Epoch 7/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 0.0115 - T_loss: 0.0114 - R_loss: 5.8453e-05 - T_accuracy: 0.9867 - R_accuracy: 0.5987 - val_loss: 0.3123 - val_T_loss: 0.3123 - val_R_loss: 4.9835e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.5250\n",
            "Epoch 8/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 0.0071 - T_loss: 0.0070 - R_loss: 5.3882e-05 - T_accuracy: 0.9893 - R_accuracy: 0.6053 - val_loss: 0.3170 - val_T_loss: 0.3169 - val_R_loss: 4.6171e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.4500\n",
            "Epoch 9/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 0.0051 - T_loss: 0.0051 - R_loss: 5.1163e-05 - T_accuracy: 0.9907 - R_accuracy: 0.6200 - val_loss: 0.3158 - val_T_loss: 0.3158 - val_R_loss: 4.1771e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.4500\n",
            "Epoch 10/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 0.0038 - T_loss: 0.0038 - R_loss: 4.6141e-05 - T_accuracy: 0.9907 - R_accuracy: 0.6333 - val_loss: 0.3181 - val_T_loss: 0.3181 - val_R_loss: 4.4609e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.5250\n",
            "Epoch 11/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 0.0029 - T_loss: 0.0028 - R_loss: 4.3573e-05 - T_accuracy: 0.9907 - R_accuracy: 0.6453 - val_loss: 0.3115 - val_T_loss: 0.3115 - val_R_loss: 4.2600e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.5250\n",
            "Epoch 12/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 0.0021 - T_loss: 0.0021 - R_loss: 4.2536e-05 - T_accuracy: 0.9933 - R_accuracy: 0.6293 - val_loss: 0.3153 - val_T_loss: 0.3153 - val_R_loss: 4.2953e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.4750\n",
            "Epoch 13/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 0.0015 - T_loss: 0.0015 - R_loss: 4.0315e-05 - T_accuracy: 0.9920 - R_accuracy: 0.6520 - val_loss: 0.3154 - val_T_loss: 0.3153 - val_R_loss: 4.2858e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.5000\n",
            "Epoch 14/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 0.0011 - T_loss: 0.0011 - R_loss: 3.6909e-05 - T_accuracy: 0.9920 - R_accuracy: 0.6560 - val_loss: 0.3143 - val_T_loss: 0.3143 - val_R_loss: 4.2471e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.5000\n",
            "Epoch 15/50\n",
            "750/750 [==============================] - 7s 9ms/sample - loss: 8.8147e-04 - T_loss: 8.4593e-04 - R_loss: 3.5543e-05 - T_accuracy: 0.9960 - R_accuracy: 0.6587 - val_loss: 0.3123 - val_T_loss: 0.3123 - val_R_loss: 4.5444e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.4500\n",
            "Epoch 16/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 6.8683e-04 - T_loss: 6.5197e-04 - R_loss: 3.4867e-05 - T_accuracy: 0.9973 - R_accuracy: 0.6693 - val_loss: 0.3128 - val_T_loss: 0.3128 - val_R_loss: 4.8498e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.5000\n",
            "Epoch 17/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 5.8107e-04 - T_loss: 5.4732e-04 - R_loss: 3.3756e-05 - T_accuracy: 0.9987 - R_accuracy: 0.6680 - val_loss: 0.3140 - val_T_loss: 0.3140 - val_R_loss: 4.4729e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.5250\n",
            "Epoch 18/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 5.0738e-04 - T_loss: 4.7473e-04 - R_loss: 3.2657e-05 - T_accuracy: 0.9987 - R_accuracy: 0.6587 - val_loss: 0.3142 - val_T_loss: 0.3142 - val_R_loss: 4.0758e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.5000\n",
            "Epoch 19/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 4.4817e-04 - T_loss: 4.1663e-04 - R_loss: 3.1537e-05 - T_accuracy: 0.9987 - R_accuracy: 0.6640 - val_loss: 0.3145 - val_T_loss: 0.3144 - val_R_loss: 4.8592e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.4000\n",
            "Epoch 20/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 4.0855e-04 - T_loss: 3.7786e-04 - R_loss: 3.0694e-05 - T_accuracy: 0.9987 - R_accuracy: 0.6640 - val_loss: 0.3135 - val_T_loss: 0.3135 - val_R_loss: 4.9784e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.5000\n",
            "Epoch 21/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 3.6847e-04 - T_loss: 3.3759e-04 - R_loss: 3.0883e-05 - T_accuracy: 0.9987 - R_accuracy: 0.6533 - val_loss: 0.3137 - val_T_loss: 0.3137 - val_R_loss: 4.7159e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.4250\n",
            "Epoch 22/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 3.5447e-04 - T_loss: 3.2407e-04 - R_loss: 3.0401e-05 - T_accuracy: 0.9987 - R_accuracy: 0.6707 - val_loss: 0.3133 - val_T_loss: 0.3133 - val_R_loss: 4.9191e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.5500\n",
            "Epoch 23/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 3.0293e-04 - T_loss: 2.7506e-04 - R_loss: 2.7872e-05 - T_accuracy: 0.9987 - R_accuracy: 0.6853 - val_loss: 0.3134 - val_T_loss: 0.3133 - val_R_loss: 4.5178e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.5250\n",
            "Epoch 24/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 2.7086e-04 - T_loss: 2.4430e-04 - R_loss: 2.6566e-05 - T_accuracy: 0.9987 - R_accuracy: 0.6680 - val_loss: 0.3133 - val_T_loss: 0.3133 - val_R_loss: 4.7166e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.4500\n",
            "Epoch 25/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 2.4762e-04 - T_loss: 2.2154e-04 - R_loss: 2.6081e-05 - T_accuracy: 0.9987 - R_accuracy: 0.6840 - val_loss: 0.3140 - val_T_loss: 0.3139 - val_R_loss: 4.4279e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.5500\n",
            "Epoch 26/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 2.4719e-04 - T_loss: 2.2282e-04 - R_loss: 2.4377e-05 - T_accuracy: 0.9987 - R_accuracy: 0.6867 - val_loss: 0.3134 - val_T_loss: 0.3134 - val_R_loss: 4.6507e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.4250\n",
            "Epoch 27/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 2.2653e-04 - T_loss: 2.0228e-04 - R_loss: 2.4248e-05 - T_accuracy: 0.9987 - R_accuracy: 0.6733 - val_loss: 0.3131 - val_T_loss: 0.3131 - val_R_loss: 4.8268e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.5250\n",
            "Epoch 28/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 2.0882e-04 - T_loss: 1.8453e-04 - R_loss: 2.4284e-05 - T_accuracy: 0.9987 - R_accuracy: 0.6760 - val_loss: 0.3133 - val_T_loss: 0.3132 - val_R_loss: 4.9381e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.4500\n",
            "Epoch 29/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 1.9393e-04 - T_loss: 1.7008e-04 - R_loss: 2.3857e-05 - T_accuracy: 0.9987 - R_accuracy: 0.7000 - val_loss: 0.3128 - val_T_loss: 0.3128 - val_R_loss: 4.5162e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.3750\n",
            "Epoch 30/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 1.8943e-04 - T_loss: 1.6689e-04 - R_loss: 2.2546e-05 - T_accuracy: 0.9987 - R_accuracy: 0.6867 - val_loss: 0.3140 - val_T_loss: 0.3140 - val_R_loss: 4.4543e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.5750\n",
            "Epoch 31/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 1.8790e-04 - T_loss: 1.6594e-04 - R_loss: 2.1954e-05 - T_accuracy: 0.9987 - R_accuracy: 0.6880 - val_loss: 0.3130 - val_T_loss: 0.3129 - val_R_loss: 4.6127e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.4250\n",
            "Epoch 32/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 1.7455e-04 - T_loss: 1.5264e-04 - R_loss: 2.1907e-05 - T_accuracy: 0.9987 - R_accuracy: 0.6867 - val_loss: 0.3129 - val_T_loss: 0.3128 - val_R_loss: 4.3796e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.5750\n",
            "Epoch 33/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 1.6744e-04 - T_loss: 1.4564e-04 - R_loss: 2.1795e-05 - T_accuracy: 0.9987 - R_accuracy: 0.6787 - val_loss: 0.3134 - val_T_loss: 0.3134 - val_R_loss: 4.7309e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.3750\n",
            "Epoch 34/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 1.5868e-04 - T_loss: 1.3770e-04 - R_loss: 2.0982e-05 - T_accuracy: 0.9987 - R_accuracy: 0.6907 - val_loss: 0.3140 - val_T_loss: 0.3140 - val_R_loss: 4.5994e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.5250\n",
            "Epoch 35/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 1.4868e-04 - T_loss: 1.2833e-04 - R_loss: 2.0343e-05 - T_accuracy: 0.9987 - R_accuracy: 0.6973 - val_loss: 0.3128 - val_T_loss: 0.3128 - val_R_loss: 4.7128e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.5000\n",
            "Epoch 36/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 1.4324e-04 - T_loss: 1.2311e-04 - R_loss: 2.0130e-05 - T_accuracy: 0.9987 - R_accuracy: 0.7013 - val_loss: 0.3138 - val_T_loss: 0.3138 - val_R_loss: 4.2328e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.4500\n",
            "Epoch 37/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 1.3882e-04 - T_loss: 1.1870e-04 - R_loss: 2.0112e-05 - T_accuracy: 0.9987 - R_accuracy: 0.7000 - val_loss: 0.3133 - val_T_loss: 0.3132 - val_R_loss: 4.5251e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.5500\n",
            "Epoch 38/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 1.3074e-04 - T_loss: 1.1086e-04 - R_loss: 1.9879e-05 - T_accuracy: 0.9987 - R_accuracy: 0.6960 - val_loss: 0.3141 - val_T_loss: 0.3140 - val_R_loss: 4.4613e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.4500\n",
            "Epoch 39/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 1.2500e-04 - T_loss: 1.0572e-04 - R_loss: 1.9279e-05 - T_accuracy: 0.9987 - R_accuracy: 0.7053 - val_loss: 0.3134 - val_T_loss: 0.3134 - val_R_loss: 4.3936e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.5250\n",
            "Epoch 40/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 1.2045e-04 - T_loss: 1.0163e-04 - R_loss: 1.8827e-05 - T_accuracy: 1.0000 - R_accuracy: 0.6813 - val_loss: 0.3148 - val_T_loss: 0.3147 - val_R_loss: 4.3896e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.5750\n",
            "Epoch 41/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 1.2038e-04 - T_loss: 1.0089e-04 - R_loss: 1.9489e-05 - T_accuracy: 1.0000 - R_accuracy: 0.7000 - val_loss: 0.3131 - val_T_loss: 0.3130 - val_R_loss: 4.4628e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.5000\n",
            "Epoch 42/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 1.2903e-04 - T_loss: 1.0935e-04 - R_loss: 1.9683e-05 - T_accuracy: 0.9987 - R_accuracy: 0.6800 - val_loss: 0.3143 - val_T_loss: 0.3143 - val_R_loss: 4.3247e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.4250\n",
            "Epoch 43/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 1.2482e-04 - T_loss: 1.0585e-04 - R_loss: 1.8969e-05 - T_accuracy: 1.0000 - R_accuracy: 0.6867 - val_loss: 0.3125 - val_T_loss: 0.3125 - val_R_loss: 4.5590e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.6250\n",
            "Epoch 44/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 1.2126e-04 - T_loss: 1.0266e-04 - R_loss: 1.8597e-05 - T_accuracy: 0.9987 - R_accuracy: 0.7067 - val_loss: 0.3148 - val_T_loss: 0.3148 - val_R_loss: 4.2394e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.4500\n",
            "Epoch 45/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 1.3968e-04 - T_loss: 1.2201e-04 - R_loss: 1.7668e-05 - T_accuracy: 1.0000 - R_accuracy: 0.7027 - val_loss: 0.3122 - val_T_loss: 0.3121 - val_R_loss: 4.4666e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.5500\n",
            "Epoch 46/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 1.9519e-04 - T_loss: 1.7713e-04 - R_loss: 1.8061e-05 - T_accuracy: 0.9987 - R_accuracy: 0.6960 - val_loss: 0.3158 - val_T_loss: 0.3158 - val_R_loss: 4.0923e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.4500\n",
            "Epoch 47/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 2.3143e-04 - T_loss: 2.1396e-04 - R_loss: 1.7472e-05 - T_accuracy: 1.0000 - R_accuracy: 0.6973 - val_loss: 0.3136 - val_T_loss: 0.3136 - val_R_loss: 4.4797e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.5250\n",
            "Epoch 48/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 2.0532e-04 - T_loss: 1.8774e-04 - R_loss: 1.7572e-05 - T_accuracy: 0.9987 - R_accuracy: 0.7067 - val_loss: 0.3143 - val_T_loss: 0.3143 - val_R_loss: 4.0961e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.6000\n",
            "Epoch 49/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 1.8224e-04 - T_loss: 1.6477e-04 - R_loss: 1.7462e-05 - T_accuracy: 1.0000 - R_accuracy: 0.7080 - val_loss: 0.3151 - val_T_loss: 0.3151 - val_R_loss: 4.5979e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.4000\n",
            "Epoch 50/50\n",
            "750/750 [==============================] - 6s 9ms/sample - loss: 1.9388e-04 - T_loss: 1.7683e-04 - R_loss: 1.7046e-05 - T_accuracy: 1.0000 - R_accuracy: 0.7147 - val_loss: 0.3137 - val_T_loss: 0.3136 - val_R_loss: 4.3509e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.4000\n",
            "Train on 247 samples, validate on 13 samples\n",
            "Epoch 1/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 6.9862 - T_loss: 6.9861 - R_loss: 9.7378e-05 - T_accuracy: 0.9028 - R_accuracy: 0.1943 - val_loss: 4.5809 - val_T_loss: 4.5809 - val_R_loss: 2.0045e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.1538\n",
            "Epoch 2/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 1.7335 - T_loss: 1.7335 - R_loss: 3.2223e-05 - T_accuracy: 0.9960 - R_accuracy: 0.1700 - val_loss: 0.9758 - val_T_loss: 0.9757 - val_R_loss: 4.6763e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.2308\n",
            "Epoch 3/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 0.6997 - T_loss: 0.6996 - R_loss: 4.0053e-05 - T_accuracy: 1.0000 - R_accuracy: 0.1781 - val_loss: 2.0672 - val_T_loss: 2.0672 - val_R_loss: 2.2685e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.0769\n",
            "Epoch 4/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 0.3965 - T_loss: 0.3965 - R_loss: 1.5290e-05 - T_accuracy: 1.0000 - R_accuracy: 0.2672 - val_loss: 1.3450 - val_T_loss: 1.3450 - val_R_loss: 1.3697e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.1538\n",
            "Epoch 5/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 0.1801 - T_loss: 0.1801 - R_loss: 1.6163e-05 - T_accuracy: 1.0000 - R_accuracy: 0.1700 - val_loss: 1.0782 - val_T_loss: 1.0782 - val_R_loss: 1.0055e-05 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.1538\n",
            "Epoch 6/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 0.0980 - T_loss: 0.0979 - R_loss: 1.8129e-05 - T_accuracy: 1.0000 - R_accuracy: 0.2227 - val_loss: 1.3838 - val_T_loss: 1.3838 - val_R_loss: 9.2871e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 0.0484 - T_loss: 0.0484 - R_loss: 1.5458e-05 - T_accuracy: 1.0000 - R_accuracy: 0.1457 - val_loss: 1.2182 - val_T_loss: 1.2182 - val_R_loss: 6.7562e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.1538\n",
            "Epoch 8/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 0.0287 - T_loss: 0.0287 - R_loss: 9.5586e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2510 - val_loss: 1.2023 - val_T_loss: 1.2023 - val_R_loss: 5.6507e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.3846\n",
            "Epoch 9/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 0.0212 - T_loss: 0.0212 - R_loss: 8.6558e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2065 - val_loss: 1.3349 - val_T_loss: 1.3349 - val_R_loss: 6.5654e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.0769\n",
            "Epoch 10/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 0.0140 - T_loss: 0.0140 - R_loss: 7.9723e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2186 - val_loss: 1.3313 - val_T_loss: 1.3312 - val_R_loss: 5.5824e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.1538\n",
            "Epoch 11/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 0.0166 - T_loss: 0.0166 - R_loss: 7.3824e-06 - T_accuracy: 1.0000 - R_accuracy: 0.1943 - val_loss: 1.2454 - val_T_loss: 1.2454 - val_R_loss: 5.5774e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.0769\n",
            "Epoch 12/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 0.0102 - T_loss: 0.0102 - R_loss: 6.9632e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2146 - val_loss: 1.1866 - val_T_loss: 1.1866 - val_R_loss: 5.4998e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.0769\n",
            "Epoch 13/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 0.0102 - T_loss: 0.0102 - R_loss: 6.8298e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2146 - val_loss: 1.2050 - val_T_loss: 1.2050 - val_R_loss: 5.0882e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.2308\n",
            "Epoch 14/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 0.0056 - T_loss: 0.0055 - R_loss: 6.6741e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2146 - val_loss: 1.2625 - val_T_loss: 1.2625 - val_R_loss: 5.0586e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.0769\n",
            "Epoch 15/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 0.0050 - T_loss: 0.0050 - R_loss: 6.5583e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2551 - val_loss: 1.2635 - val_T_loss: 1.2635 - val_R_loss: 5.3468e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.0769\n",
            "Epoch 16/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 0.0029 - T_loss: 0.0029 - R_loss: 6.2982e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2227 - val_loss: 1.2283 - val_T_loss: 1.2282 - val_R_loss: 4.7598e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.3846\n",
            "Epoch 17/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 0.0025 - T_loss: 0.0025 - R_loss: 6.2456e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2713 - val_loss: 1.2298 - val_T_loss: 1.2298 - val_R_loss: 5.6621e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.0769\n",
            "Epoch 18/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 0.0021 - T_loss: 0.0021 - R_loss: 6.3574e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2227 - val_loss: 1.2468 - val_T_loss: 1.2468 - val_R_loss: 4.8123e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.1538\n",
            "Epoch 19/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 0.0017 - T_loss: 0.0017 - R_loss: 6.1643e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2510 - val_loss: 1.2292 - val_T_loss: 1.2292 - val_R_loss: 4.7567e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.2308\n",
            "Epoch 20/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 0.0015 - T_loss: 0.0015 - R_loss: 6.0052e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2632 - val_loss: 1.2355 - val_T_loss: 1.2355 - val_R_loss: 5.3889e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.0769\n",
            "Epoch 21/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 0.0014 - T_loss: 0.0014 - R_loss: 5.8922e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2348 - val_loss: 1.2250 - val_T_loss: 1.2250 - val_R_loss: 4.6454e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.0769\n",
            "Epoch 22/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 0.0012 - T_loss: 0.0012 - R_loss: 5.6668e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2308 - val_loss: 1.2291 - val_T_loss: 1.2291 - val_R_loss: 4.5586e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.0769\n",
            "Epoch 23/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 0.0011 - T_loss: 0.0011 - R_loss: 5.6324e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2348 - val_loss: 1.2415 - val_T_loss: 1.2415 - val_R_loss: 4.5463e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.2308\n",
            "Epoch 24/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 0.0011 - T_loss: 0.0011 - R_loss: 5.6150e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2753 - val_loss: 1.2321 - val_T_loss: 1.2321 - val_R_loss: 4.4350e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.0769\n",
            "Epoch 25/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 9.8057e-04 - T_loss: 9.7513e-04 - R_loss: 5.4341e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2227 - val_loss: 1.2316 - val_T_loss: 1.2316 - val_R_loss: 4.4675e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.0769\n",
            "Epoch 26/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 9.0762e-04 - T_loss: 9.0231e-04 - R_loss: 5.3097e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2632 - val_loss: 1.2347 - val_T_loss: 1.2347 - val_R_loss: 4.6177e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.0769\n",
            "Epoch 27/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 8.7549e-04 - T_loss: 8.7010e-04 - R_loss: 5.3843e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2227 - val_loss: 1.2394 - val_T_loss: 1.2394 - val_R_loss: 4.4446e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.1538\n",
            "Epoch 28/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 8.3142e-04 - T_loss: 8.2608e-04 - R_loss: 5.3397e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2955 - val_loss: 1.2263 - val_T_loss: 1.2263 - val_R_loss: 4.7462e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.0769\n",
            "Epoch 29/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 8.0606e-04 - T_loss: 8.0087e-04 - R_loss: 5.1894e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2227 - val_loss: 1.2322 - val_T_loss: 1.2322 - val_R_loss: 4.2880e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.2308\n",
            "Epoch 30/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 7.8234e-04 - T_loss: 7.7702e-04 - R_loss: 5.3208e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2874 - val_loss: 1.2365 - val_T_loss: 1.2365 - val_R_loss: 4.4934e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.0769\n",
            "Epoch 31/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 7.1165e-04 - T_loss: 7.0656e-04 - R_loss: 5.0930e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2551 - val_loss: 1.2325 - val_T_loss: 1.2325 - val_R_loss: 4.1845e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.1538\n",
            "Epoch 32/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 6.8453e-04 - T_loss: 6.7944e-04 - R_loss: 5.0813e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2470 - val_loss: 1.2351 - val_T_loss: 1.2351 - val_R_loss: 4.3306e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.0769\n",
            "Epoch 33/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 6.4814e-04 - T_loss: 6.4311e-04 - R_loss: 5.0300e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2632 - val_loss: 1.2375 - val_T_loss: 1.2375 - val_R_loss: 4.3700e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.0769\n",
            "Epoch 34/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 6.2529e-04 - T_loss: 6.2033e-04 - R_loss: 4.9625e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2267 - val_loss: 1.2328 - val_T_loss: 1.2328 - val_R_loss: 4.1069e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.1538\n",
            "Epoch 35/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 6.0738e-04 - T_loss: 6.0242e-04 - R_loss: 4.9583e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2348 - val_loss: 1.2330 - val_T_loss: 1.2330 - val_R_loss: 4.1184e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.0769\n",
            "Epoch 36/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 5.8996e-04 - T_loss: 5.8505e-04 - R_loss: 4.9104e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2267 - val_loss: 1.2352 - val_T_loss: 1.2352 - val_R_loss: 4.2704e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.0769\n",
            "Epoch 37/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 5.4702e-04 - T_loss: 5.4216e-04 - R_loss: 4.8599e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2591 - val_loss: 1.2338 - val_T_loss: 1.2338 - val_R_loss: 4.4546e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.1538\n",
            "Epoch 38/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 5.4342e-04 - T_loss: 5.3851e-04 - R_loss: 4.9025e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2348 - val_loss: 1.2314 - val_T_loss: 1.2314 - val_R_loss: 4.1693e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.0769\n",
            "Epoch 39/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 5.1279e-04 - T_loss: 5.0795e-04 - R_loss: 4.8374e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2672 - val_loss: 1.2336 - val_T_loss: 1.2336 - val_R_loss: 4.0216e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.1538\n",
            "Epoch 40/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 5.2765e-04 - T_loss: 5.2282e-04 - R_loss: 4.8272e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2591 - val_loss: 1.2333 - val_T_loss: 1.2333 - val_R_loss: 4.4117e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.1538\n",
            "Epoch 41/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 5.0489e-04 - T_loss: 5.0015e-04 - R_loss: 4.7368e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2510 - val_loss: 1.2331 - val_T_loss: 1.2331 - val_R_loss: 4.1043e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.0769\n",
            "Epoch 42/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 4.8757e-04 - T_loss: 4.8288e-04 - R_loss: 4.6942e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2470 - val_loss: 1.2320 - val_T_loss: 1.2320 - val_R_loss: 4.0894e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.1538\n",
            "Epoch 43/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 4.6525e-04 - T_loss: 4.6057e-04 - R_loss: 4.6886e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2348 - val_loss: 1.2322 - val_T_loss: 1.2322 - val_R_loss: 4.1481e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.0769\n",
            "Epoch 44/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 4.3458e-04 - T_loss: 4.2993e-04 - R_loss: 4.6445e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2591 - val_loss: 1.2319 - val_T_loss: 1.2319 - val_R_loss: 4.1779e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.1538\n",
            "Epoch 45/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 4.1361e-04 - T_loss: 4.0893e-04 - R_loss: 4.6792e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2470 - val_loss: 1.2312 - val_T_loss: 1.2312 - val_R_loss: 4.0259e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.3077\n",
            "Epoch 46/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 4.1504e-04 - T_loss: 4.1047e-04 - R_loss: 4.5760e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2713 - val_loss: 1.2320 - val_T_loss: 1.2320 - val_R_loss: 4.1005e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.0769\n",
            "Epoch 47/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 3.9589e-04 - T_loss: 3.9128e-04 - R_loss: 4.6066e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2470 - val_loss: 1.2316 - val_T_loss: 1.2316 - val_R_loss: 3.9336e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.3846\n",
            "Epoch 48/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 3.8604e-04 - T_loss: 3.8144e-04 - R_loss: 4.5978e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2713 - val_loss: 1.2313 - val_T_loss: 1.2313 - val_R_loss: 4.4495e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.0769\n",
            "Epoch 49/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 3.6958e-04 - T_loss: 3.6486e-04 - R_loss: 4.7233e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2632 - val_loss: 1.2310 - val_T_loss: 1.2310 - val_R_loss: 3.9396e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.2308\n",
            "Epoch 50/50\n",
            "247/247 [==============================] - 2s 9ms/sample - loss: 3.6606e-04 - T_loss: 3.6152e-04 - R_loss: 4.5429e-06 - T_accuracy: 1.0000 - R_accuracy: 0.2470 - val_loss: 1.2308 - val_T_loss: 1.2308 - val_R_loss: 3.9557e-06 - val_T_accuracy: 1.0000 - val_R_accuracy: 0.3846\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Rl3RhSe1_oI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_strides_BN.save(path+'model_stride_data0-4_50x8epoch.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmRxj8suMLtG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPmYqpI51cvG",
        "colab_type": "code",
        "outputId": "73aca34c-0833-4ce2-ae3d-0158a05fa031",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "model1=create_vgg()\n",
        "model1.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 188, 620, 2) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 186, 618, 64) 1216        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2 (Conv2D)                  (None, 184, 616, 64) 36928       conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "pooling1 (MaxPooling2D)         (None, 92, 308, 64)  0           conv2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv3 (Conv2D)                  (None, 90, 306, 128) 73856       pooling1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv4 (Conv2D)                  (None, 88, 304, 128) 147584      conv3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "pooling2 (MaxPooling2D)         (None, 44, 152, 128) 0           conv4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv5 (Conv2D)                  (None, 42, 150, 256) 295168      pooling2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv6 (Conv2D)                  (None, 40, 148, 256) 590080      conv5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv7 (Conv2D)                  (None, 38, 146, 256) 590080      conv6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "pooling3 (MaxPooling2D)         (None, 19, 73, 256)  0           conv7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv8 (Conv2D)                  (None, 17, 71, 512)  1180160     pooling3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv9 (Conv2D)                  (None, 15, 69, 512)  2359808     conv8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv10 (Conv2D)                 (None, 13, 67, 512)  2359808     conv9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "pooling4 (MaxPooling2D)         (None, 6, 33, 512)   0           conv10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 101376)       0           pooling4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense1 (Dense)                  (None, 512)          51905024    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "T (Dense)                       (None, 3)            1539        dense1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "R (Dense)                       (None, 9)            4617        dense1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 59,545,868\n",
            "Trainable params: 59,545,868\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjoCDjLS1XVX",
        "colab_type": "code",
        "outputId": "b6315bf5-c7a9-4315-f44a-dae9f2a0e5f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        }
      },
      "source": [
        "for k in [0,1,2,3,4]*2:\n",
        "  epoch = 5\n",
        "  history2 = model1.fit(x = data_full[k], \n",
        "              y=[T_liste[k], R_liste[k]], \n",
        "              batch_size = 32,\n",
        "              epochs = epoch,\n",
        "              validation_split=0.05 )\n",
        "              # batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4303 samples, validate on 227 samples\n",
            "Epoch 1/5\n",
            "1632/4303 [==========>...................] - ETA: 2:47 - loss: 9.5452 - T_loss: 9.4719 - R_loss: 0.0733 - T_accuracy: 0.3456 - R_accuracy: 0.0760"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-1c44ce099a79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m               \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m               \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m               validation_split=0.05 )\n\u001b[0m\u001b[1;32m      8\u001b[0m               \u001b[0;31m# batch_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    871\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3215\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3216\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3217\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3218\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n\u001b[1;32m   3219\u001b[0m                                  [x.numpy() for x in outputs])\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    556\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m    557\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m--> 558\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    413\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    414\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 415\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    416\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     59\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wY38TYYw2cLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1.save(path+'model_vgg_data0-4_50x8epoch.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJD9ZFTARpDI",
        "colab_type": "code",
        "outputId": "82299e2c-d72f-4ce7-cb29-8d00e6379784",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_acc'], label='test')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-924f39268d3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jeFesO-zSvR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oykPdL3yxJt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a,b = model.predict(data[k][1:2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QzayFP8hyQA",
        "colab_type": "code",
        "outputId": "6741afbf-b332-4ccd-d5bd-4d994e0a8946",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 20.673983 ,   1.0413561, -14.305507 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gsh_A-ohz_L",
        "colab_type": "code",
        "outputId": "37637ebe-3447-4d6b-c72e-e46201f99cb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "b"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.01197565, -0.00304699, -0.00222986, -0.01545902, -0.00976726,\n",
              "         0.0477588 , -0.0059408 , -0.02251862, -0.04212624]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMZE9hZah3rH",
        "colab_type": "code",
        "outputId": "f3f184e3-5c77-42e5-dcd7-6088a7838130",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "T_liste[0][1:2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([ 21.364  ,   1.06675, -14.704  ])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ew-ogmY4iA3g",
        "colab_type": "code",
        "outputId": "95b0aad2-9adc-475c-ce0e-3a1f570ca59a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "R_liste[0][1:2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([ 0.0022405 , -0.00393113,  0.0013777 , -0.00133445, -0.0001784 ,\n",
              "         0.00364295, -0.0015824 ,  0.00086015,  0.0024215 ])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHIOfjsMRftH",
        "colab_type": "text"
      },
      "source": [
        "# Improvements\n",
        "## data augmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mcw789I_Rmye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define data preparation\n",
        "datagen = ImageDataGenerator(rotation_range=30,width_shift_range=0.1, height_shift_range=0.1 , zoom_range = 0.2)\n",
        "# fit parameters from data\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lN1chQ_M1fSb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aI1NxeTJ1lxT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "R_train[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zQfeEJgt5BV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4hmqXbPuJTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.shape([R_train, T_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9tUO_3HuQCQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "now = datetime.datetime.now()\n",
        "print ()\n",
        "model.save(path+'model_'+now.strftime(\"%Y-%m-%d_%H:%M:%S\")+'.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mibs69IewGHX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['accuracy'], label='train')\n",
        "plt.plot(history.history['val_accuracy'], label='test')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.imsave(path+'graph.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lI-HEMRTNc5G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oi9fITCmIjWT",
        "colab_type": "text"
      },
      "source": [
        "# Traznsfer learning \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEKGwiIWIl9D",
        "colab_type": "code",
        "outputId": "481445e8-2f74-4672-ea75-77d85ddbbfb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "source": [
        "from keras.applications import MobileNet\n",
        "\n",
        "\n",
        "base_model=MobileNet(input_tensor=(620,188,2),weights='imagenet',include_top=False) #imports the mobilenet model and discards the last 1000 neuron layer.\n",
        "\n",
        "# input_shape = Input( (620,188,2) )\n",
        "x=base_model.output\n",
        "x=GlobalAveragePooling2D()(x)\n",
        "x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
        "x=Dense(1024,activation='relu')(x) #dense layer 2\n",
        "x=Dense(512,activation='relu')(x) #dense layer 3\n",
        "\n",
        "\n",
        "T_network = Dense(3 , name='T')(x)\n",
        "R_network = Dense(9 , name='R')(x)\n",
        "\n",
        "model = Model(base_model.input, [T_network, R_network])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  warnings.warn('`input_shape` is undefined or non-square, '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-d7eb2f33a241>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mbase_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMobileNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m620\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m188\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#imports the mobilenet model and discards the last 1000 neuron layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# input_shape = Input( (620,188,2) )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/applications/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'utils'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbase_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/applications/mobilenet.py\u001b[0m in \u001b[0;36mMobileNet\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mkeras_modules_injection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mMobileNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmobilenet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMobileNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_applications/mobilenet.py\u001b[0m in \u001b[0;36mMobileNet\u001b[0;34m(input_shape, alpha, depth_multiplier, dropout, include_top, weights, input_tensor, pooling, classes, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mimg_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m             \u001b[0mimg_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    496\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         raise ValueError('Unexpectedly found an instance of type `' +\n\u001b[0;32m--> 498\u001b[0;31m                          \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m                          'Expected a symbolic tensor instance.')\n\u001b[1;32m    500\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_history'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unexpectedly found an instance of type `<class 'tuple'>`. Expected a symbolic tensor instance."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "133LW7OoVQIm",
        "colab_type": "text"
      },
      "source": [
        "# TRASH"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvyqyDdYVTMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load data, to do : print number of loads / total \n",
        "from tqdm import tqdm\n",
        "def load_data_folder_cv(folder):\n",
        "  data=[]\n",
        "  liste=index_list_list[int(folder[1])]\n",
        "  length0 = len(liste )\n",
        "  pbar = tqdm(total=length0)\n",
        "  mem=0\n",
        "\n",
        "  for k,l in liste:\n",
        "    try:\n",
        "      data.append ( [ np.dstack( ( img_to_array( cv2.imread(path+folder+'/image_0/{:06}.png'.format(k*2), 0) )/255,\n",
        "                                      img_to_array (cv2.imread(path+folder+'/image_0/{:06}.png'.format(l*2), 0) )/255 ) ) ]  )\n",
        "      if k%100==0:\n",
        "        \n",
        "        # printProgressBar(k, length0, prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
        "        pbar.update(100)\n",
        "        pass\n",
        "    except:\n",
        "      # print (k)\n",
        "      mem=mem+1\n",
        "      \n",
        "  \n",
        "  print(folder+\"dataset loaded successfully yeah\")\n",
        "  pbar.close()\n",
        "  data_reshaped = np.reshape(data, (len(data), 188,620,2 ) )\n",
        "  return reshaped"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}